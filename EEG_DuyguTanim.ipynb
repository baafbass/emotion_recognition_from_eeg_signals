{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1JG2tbDzkJzlWLPgx7Wo-IyIAdbM6utyf",
      "authorship_tag": "ABX9TyNSF/wekVQhM9er1tr7AaIC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PROJE BAŞLIĞI: EEG Sinyallerinden Duygu Tanıma\n",
        "#### VERİ KÜMESİ: DREAMER (Dreaming via Electroencephalogram & Electrocardiogram)\n",
        "#### YÖNTEM: CNN-LSTM Hibrit Mimarisi + Diferansiyel Entropi (DE) Öznitelikleri"
      ],
      "metadata": {
        "id": "cL_uakwPYZzV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. GİRİŞ VE PROJE ÖZETİ"
      ],
      "metadata": {
        "id": "cApCrk6GmLau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 EEG Tabanlı Duygu Tanıma ve Önemi\n",
        "\n",
        "Duygu tanıma, insan-bilgisayar etkileşiminde kritik bir rol oynamaktadır.\n",
        "Geleneksel yöntemler (yüz ifadesi, ses tonu analizi) öznel ve manipüle edilebilir\n",
        "olduğundan, nörofizyolojik sinyaller üzerinden duygu tanıma önem kazanmıştır.\n",
        "\n",
        "Elektroensefalografi (EEG), beyin aktivitesini yüksek zamansal çözünürlükle\n",
        "ölçen invazif olmayan bir yöntemdir. EEG sinyalleri:\n",
        "- Bilinçli kontrolün dışındadır (objektif ölçüm)\n",
        "- Milisaniye düzeyinde zamansal çözünürlük sağlar\n",
        "- Düşük maliyetlidir ve portatif cihazlarla kullanılabilir"
      ],
      "metadata": {
        "id": "-o_y7VBXZkZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 DREAMER Veri Kümesi\n",
        "\n",
        "DREAMER veri kümesi, duygusal video uyaranlarına karşı kaydedilen EEG ve EKG\n",
        "sinyallerini içerir:\n",
        "- **23 denek**: Sağlıklı yetişkin bireyler\n",
        "- **14 kanal EEG**: Uluslararası 10-20 sistemi (AF3, AF4, F3, F4, F7, F8, FC5,\n",
        "  FC6, T7, T8, P7, P8, O1, O2)\n",
        "- **18 film klibi**: Her biri yaklaşık 4 dakika uzunluğunda\n",
        "- **Örnekleme frekansı**: 128 Hz\n",
        "- **Duygu etiketleri**: Valence (değerlik), Arousal (uyarılmışlık) ve\n",
        "  Dominance (baskınlık) için 1-5 arası öz-bildirim skorları\n",
        "\n",
        "Bu çalışmada, yaygın olarak kullanılan iki boyuta odaklanılmıştır:\n",
        "1. **Valence (Değerlik)**: Olumlu-olumsuz duygu ekseni\n",
        "2. **Arousal (Uyarılmışlık)**: Sakin-heyecanlı duygu ekseni"
      ],
      "metadata": {
        "id": "SoQUR7UKZ9FA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Önerilen Yaklaşımın Yenilikçi Yönü\n",
        "\n",
        "Mevcut literatürde EEG tabanlı duygu tanıma çalışmaları genellikle:\n",
        "- Sadece CNN mimarileri (uzamsal özellikler)\n",
        "- Sadece RNN/LSTM mimarileri (zamansal özellikler)\n",
        "- Ham EEG verisi veya basit istatistiksel özellikler kullanır\n",
        "\n",
        "**Bu çalışmanın yenilikçi katkıları:**\n",
        "\n",
        "1. **Hibrit CNN-LSTM Mimarisi**:\n",
        "   - CNN katmanları: Kanal-frekans bant matrisi üzerindeki yerel uzamsal\n",
        "     örüntüleri (topoğrafik bilgi) öğrenir\n",
        "   - LSTM katmanları: Farklı frekans bantları ve kanallar arasındaki\n",
        "     karmaşık bağımlılıkları ve ardışık ilişkileri modeller\n",
        "\n",
        "2. **Diferansiyel Entropi (DE) Öznitelikleri**:\n",
        "   - Ham EEG verisi yerine, her frekans bandı için DE hesaplanır\n",
        "   - DE, sinyal gücünün logaritmik ölçüsüdür ve duygusal durumlarla yüksek\n",
        "     korelasyon gösterir (Duan et al., 2013; Zheng & Lu, 2015)\n",
        "   - 5 frekans bandı (δ, θ, α, β, γ) × 14 kanal = 70 boyutlu kompakt öznitelik\n",
        "\n",
        "3. **Denek-Bağımsız Değerlendirme (LOSO Cross-Validation)**:\n",
        "   - Gerçek dünya senaryolarını simüle eder\n",
        "   - Modelin genelleme yeteneğini daha güvenilir şekilde ölçer\n",
        "   - Akademik çalışmalarda altın standart olarak kabul edilir\n",
        "\n",
        "**Hipotez**: Hibrit mimari, hem lokal uzamsal örüntüleri hem de global\n",
        "zamansal bağımlılıkları yakalayarak, tek başına CNN veya RNN yaklaşımlarından\n",
        "daha yüksek sınıflandırma başarısı sağlayacaktır."
      ],
      "metadata": {
        "id": "zEgrgIgIa_pP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. KÜTÜPHANE İÇE AKTARIMLARI"
      ],
      "metadata": {
        "id": "dC8tRj2omRFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.io import loadmat\n",
        "from scipy.signal import butter, filtfilt\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# TensorFlow ve Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.model_selection import train_test_split, LeaveOneGroupOut\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n"
      ],
      "metadata": {
        "id": "KiuScm1YY3rw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Versiyonları kontrol et\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "print(f\"Keras Version: {keras.__version__}\")\n",
        "print(f\"NumPy Version: {np.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MRoWEJnfNl0",
        "outputId": "1dd5e886-26ce-40b4-e0a8-2be59e5493f8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.19.0\n",
            "Keras Version: 3.10.0\n",
            "NumPy Version: 2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rastgelelik kontrolü (tekrarlanabilirlik için)\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "6FZbr_9hfaty"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 DREAMER Veri Kümesinin Yapısı\n",
        "\n",
        "DREAMER veri kümesi MATLAB (.mat) formatında saklanır. Yapısı:\n",
        "- 'DREAMER.mat' dosyası içinde 'DREAMER' adlı yapı dizisi\n",
        "- Her denek için bir yapı elemanı\n",
        "- Her yapı: 'Data' (EEG/EKG), 'ScoreValence', 'ScoreArousal', vb. içerir\n",
        "\n",
        "**Veri Organizasyonu**:\n",
        "- Data.EEG: (18 deneme × 14 kanal × zaman adımı) boyutlu matris\n",
        "- ScoreValence/Arousal: (18 deneme × 1) boyutlu etiket vektörü\n",
        "- Skorlar 1-5 arası (1=çok düşük, 5=çok yüksek)\n",
        "\n",
        "## 3.2 Veri Yükleme Fonksiyonu"
      ],
      "metadata": {
        "id": "np7j8EJrf6YN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from pprint import pprint\n",
        "\n",
        "mat = loadmat('/content/drive/MyDrive/dreamer/DREAMER.mat',\n",
        "              struct_as_record=False, squeeze_me=True)\n",
        "d = mat.get('DREAMER')\n",
        "\n",
        "print(\"TYPE of DREAMER:\", type(d))\n",
        "print(\"\\nTop-level attributes / fields (filtered):\")\n",
        "attrs = [a for a in dir(d) if not a.startswith('_')]\n",
        "# Print attribute names and types (first 200 attrs if many)\n",
        "for name in attrs:\n",
        "    try:\n",
        "        val = getattr(d, name)\n",
        "        print(f\" - {name:20} : {type(val)}\", end='')\n",
        "        # Show brief shape/info for arrays\n",
        "        if isinstance(val, np.ndarray):\n",
        "            print(f\", shape={val.shape}, dtype={val.dtype}\")\n",
        "        else:\n",
        "            # For simple types print repr clipped\n",
        "            rep = repr(val)\n",
        "            print(f\", repr={rep[:120] + ('...' if len(rep) > 120 else '')}\")\n",
        "    except Exception as e:\n",
        "        print(f\" - {name:20} : ERROR reading attribute ({e})\")\n",
        "\n",
        "# Now inspect Data field specifically (very likely present per PDF)\n",
        "data = getattr(d, 'Data', None)\n",
        "print(\"\\nData attribute found?:\", data is not None)\n",
        "if data is not None:\n",
        "    print(\"Data type:\", type(data))\n",
        "    # If ndarray/object array, print length and first element summary\n",
        "    try:\n",
        "        # make sure it's iterable\n",
        "        subjects = np.atleast_1d(data)\n",
        "        print(\"Number of subjects in Data (len):\", len(subjects))\n",
        "        first = subjects.flatten()[0]\n",
        "        print(\"\\nFirst subject type:\", type(first))\n",
        "        first_fields = [f for f in dir(first) if not f.startswith('_')]\n",
        "        print(\"First subject field names (sample):\", first_fields[:40])\n",
        "        # Try to show ScoreValence and EEG existence\n",
        "        print(\"Has ScoreValence?:\", hasattr(first, 'ScoreValence'))\n",
        "        print(\"Has ScoreArousal?:\", hasattr(first, 'ScoreArousal'))\n",
        "        print(\"Has EEG?:\", hasattr(first, 'EEG'))\n",
        "        if hasattr(first, 'ScoreValence'):\n",
        "            sv = getattr(first, 'ScoreValence')\n",
        "            print(\" ScoreValence type/shape:\", type(sv), getattr(sv, 'shape', None), \"repr sample:\", repr(sv)[:120])\n",
        "    except Exception as e:\n",
        "        print(\"Error while inspecting Data:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeJiw1TaiXPF",
        "outputId": "4928cc4d-3a6b-4b2d-d579-a3fb5cd50e9d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TYPE of DREAMER: <class 'scipy.io.matlab._mio5_params.mat_struct'>\n",
            "\n",
            "Top-level attributes / fields (filtered):\n",
            " - Acknowledgement      : <class 'str'>, repr='The authors would like to thank Thomas Cuntz and Sebastian Palke for the data collection under their BSc (Hons) project...\n",
            " - Data                 : <class 'numpy.ndarray'>, shape=(23,), dtype=object\n",
            " - Disclaimer           : <class 'str'>, repr='While every care has been taken to ensure the accuracy of the data included in the DREAMER dataset, the authors and the...\n",
            " - ECG_SamplingRate     : <class 'int'>, repr=256\n",
            " - EEG_Electrodes       : <class 'numpy.ndarray'>, shape=(14,), dtype=object\n",
            " - EEG_SamplingRate     : <class 'int'>, repr=128\n",
            " - Provider             : <class 'str'>, repr='University of the West of Scotland'\n",
            " - Version              : <class 'str'>, repr='1.0.2'\n",
            " - noOfSubjects         : <class 'int'>, repr=23\n",
            " - noOfVideoSequences   : <class 'int'>, repr=18\n",
            "\n",
            "Data attribute found?: True\n",
            "Data type: <class 'numpy.ndarray'>\n",
            "Number of subjects in Data (len): 23\n",
            "\n",
            "First subject type: <class 'scipy.io.matlab._mio5_params.mat_struct'>\n",
            "First subject field names (sample): ['Age', 'ECG', 'EEG', 'Gender', 'ScoreArousal', 'ScoreDominance', 'ScoreValence']\n",
            "Has ScoreValence?: True\n",
            "Has ScoreArousal?: True\n",
            "Has EEG?: True\n",
            " ScoreValence type/shape: <class 'numpy.ndarray'> (18,) repr sample: array([4, 3, 5, 4, 4, 1, 5, 1, 1, 5, 4, 4, 4, 3, 2, 3, 1, 3], dtype=uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "\n",
        "def load_dreamer_from_matstruct(mat_path):\n",
        "    \"\"\"\n",
        "    Load DREAMER when mat['DREAMER'] is a mat_struct with Data as subjects.\n",
        "    Returns:\n",
        "      eeg_trials : list of ndarray (samples x channels)  -- one item per stimulus trial\n",
        "      valence_arr : np.ndarray (n_trials,)\n",
        "      arousal_arr : np.ndarray (n_trials,)\n",
        "      subject_ids  : np.ndarray (n_trials,) ints 0..n_subjects-1\n",
        "    \"\"\"\n",
        "    mat = loadmat(mat_path, struct_as_record=False, squeeze_me=True)\n",
        "    if 'DREAMER' not in mat:\n",
        "        raise ValueError(\"DREAMER not found in .mat file\")\n",
        "    dreamer = mat['DREAMER']\n",
        "\n",
        "    # Data should be an array (23 subjects)\n",
        "    data = getattr(dreamer, 'Data', None)\n",
        "    if data is None:\n",
        "        raise ValueError(\"DREAMER.Data not found. Inspect the mat structure.\")\n",
        "    # ensure iterable list/array of subject structs\n",
        "    subjects = np.atleast_1d(data).flatten()\n",
        "\n",
        "    eeg_trials = []\n",
        "    valence_list = []\n",
        "    arousal_list = []\n",
        "    subject_ids = []\n",
        "\n",
        "    for subj_idx, subj in enumerate(subjects):\n",
        "        # safe accessors\n",
        "        score_v = getattr(subj, 'ScoreValence', None)\n",
        "        score_a = getattr(subj, 'ScoreArousal', None)\n",
        "        eeg_struct = getattr(subj, 'EEG', None)\n",
        "\n",
        "        if score_v is None or score_a is None:\n",
        "            raise ValueError(f\"Subject {subj_idx} missing ScoreValence/ScoreArousal fields\")\n",
        "\n",
        "        # Convert scores to 1D numpy arrays\n",
        "        score_v = np.asarray(score_v).flatten()\n",
        "        score_a = np.asarray(score_a).flatten()\n",
        "\n",
        "        if eeg_struct is None:\n",
        "            raise ValueError(f\"Subject {subj_idx} missing EEG field\")\n",
        "\n",
        "        # EEG may have .stimuli as array of 18 trials (or be the stimuli array itself)\n",
        "        stimuli = getattr(eeg_struct, 'stimuli', None)\n",
        "        if stimuli is None:\n",
        "            # fallback to eeg_struct itself (sometimes the stimuli array is stored directly)\n",
        "            stimuli = eeg_struct\n",
        "\n",
        "        # normalize to iterable list of trials\n",
        "        trials = np.atleast_1d(stimuli).flatten()\n",
        "\n",
        "        for trial_idx, trial in enumerate(trials):\n",
        "            if trial is None:\n",
        "                continue\n",
        "            trial_arr = np.asarray(trial)\n",
        "            if trial_arr.size == 0:\n",
        "                continue\n",
        "            # trial_arr should be (M,14) per PDF. Keep as-is\n",
        "            eeg_trials.append(trial_arr)\n",
        "            # align label by trial_idx if available, else np.nan\n",
        "            if trial_idx < len(score_v):\n",
        "                valence_list.append(float(score_v[trial_idx]))\n",
        "                arousal_list.append(float(score_a[trial_idx]))\n",
        "            else:\n",
        "                valence_list.append(np.nan)\n",
        "                arousal_list.append(np.nan)\n",
        "            subject_ids.append(subj_idx)\n",
        "\n",
        "    valence_arr = np.array(valence_list)\n",
        "    arousal_arr = np.array(arousal_list)\n",
        "    subject_ids = np.array(subject_ids)\n",
        "\n",
        "    print(f\"Loaded {len(subjects)} subjects -> total trials: {len(eeg_trials)}\")\n",
        "    if len(eeg_trials):\n",
        "        print(\"Example trial shape (samples x channels):\", eeg_trials[0].shape)\n",
        "\n",
        "    return eeg_trials, valence_arr, arousal_arr, subject_ids"
      ],
      "metadata": {
        "id": "bJv-QatyiyBC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Etiket Dönüştürme: Sürekli → İkili Sınıf\n",
        "\n",
        "Duygu skorları 1-5 arası sürekli değerlerdir. İkili sınıflandırma için:\n",
        "- Valence: ≥3 → Pozitif (1), <3 → Negatif (0)\n",
        "- Arousal: ≥3 → Yüksek (1), <3 → Düşük (0)\n",
        "\n",
        "**Gerekçe**:\n",
        "- 3 değeri, 1-5 ölçeğinin orta noktasıdır\n",
        "- Literatürde yaygın olarak kullanılır (Zhang et al., 2020)\n",
        "- Dengeli sınıf dağılımı sağlar"
      ],
      "metadata": {
        "id": "0GgdErunigmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- convert_to_binary_labels (works with 1D numpy of per-trial scores) ----------\n",
        "def convert_to_binary_labels(scores, threshold=3.0):\n",
        "    \"\"\"\n",
        "    Convert continuous per-trial scores (1D array) into binary labels using threshold.\n",
        "    scores : ndarray shape (n_trials,)\n",
        "    \"\"\"\n",
        "    scores = np.asarray(scores).flatten()\n",
        "    binary_labels = (scores >= threshold).astype(int)\n",
        "\n",
        "    # get counts safely\n",
        "    unique, counts = np.unique(binary_labels, return_counts=True)\n",
        "    count_dict = dict(zip(unique, counts))\n",
        "    c0 = count_dict.get(0, 0)\n",
        "    c1 = count_dict.get(1, 0)\n",
        "    total = c0 + c1\n",
        "    if total > 0:\n",
        "        balance = (min(c0, c1) / max(c0, c1) * 100) if max(c0, c1) > 0 else 0.0\n",
        "    else:\n",
        "        balance = 0.0\n",
        "\n",
        "    print(f\"Sınıf dağılımı - 0: {c0}, 1: {c1}\")\n",
        "    print(f\"Denge oranı: {balance:.1f}%\")\n",
        "\n",
        "    return binary_labels"
      ],
      "metadata": {
        "id": "v0TocM5Z0A4u"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. FREKANS BANDI FİLTRELEME"
      ],
      "metadata": {
        "id": "FMHF5hm4mEG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 EEG Frekans Bantları ve Nörofizyolojik Anlam\n",
        "\n",
        "EEG sinyali, farklı frekans bantlarında önemli bilgiler taşır:\n",
        "\n",
        "| Bant | Frekans (Hz) | Nörofizyolojik İlişki |\n",
        "|------|--------------|------------------------|\n",
        "| δ (Delta) | 0.5-4 | Derin uyku, bilinçsizlik |\n",
        "| θ (Theta) | 4-8 | Hafif uyku, meditasyon, duygusal işleme |\n",
        "| α (Alpha) | 8-14 | Rahatlamış uyanıklık, gözler kapalı |\n",
        "| β (Beta) | 14-30 | Aktif düşünme, konsantrasyon, anksiyete |\n",
        "| γ (Gamma) | 30-47 | Bilişsel işleme, dikkat |\n",
        "\n",
        "**Duygu Tanımadaki Rolü**:\n",
        "- **α bandı**: Pozitif duygularla ilişkili (frontal asimetri)\n",
        "- **β bandı**: Yüksek arousal ve stres göstergesi\n",
        "- **θ bandı**: Duygusal hafıza ve işleme\n",
        "- **γ bandı**: Duygusal uyaranların bilinçli algılanması\n",
        "\n",
        "## 4.2 Butterworth Band-Pass Filtresi\n",
        "\n",
        "Butterworth filtresi, frekans bandı ayırma için tercih edilir çünkü:\n",
        "- Geçirme bandında düz frekans yanıtı sağlar (özellik çarpıtması minimum)\n",
        "- Faz gecikmesi sıfıra yakındır (filtfilt ile çift yönlü uygulama)\n",
        "- Numerik kararlılıktır\n",
        "\n",
        "**Filtre Parametreleri**:\n",
        "- Sıra (order): 4 (daha yüksek sıra → daha keskin geçiş, daha fazla hesaplama)\n",
        "- Uygulama: filtfilt (sıfır faz gecikmesi için ileri-geri filtreleme)"
      ],
      "metadata": {
        "id": "T-LLsYCsmftv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Örnekleme frekansı (DREAMER veri kümesi için)\n",
        "SAMPLING_FREQ = 128  # Hz\n",
        "\n",
        "# Frekans bantları tanımı\n",
        "FREQ_BANDS = {\n",
        "    'delta': (0.5, 4),\n",
        "    'theta': (4, 8),\n",
        "    'alpha': (8, 14),\n",
        "    'beta': (14, 30),\n",
        "    'gamma': (30, 47)\n",
        "}\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
        "    \"\"\"\n",
        "    Butterworth band-pass filtresi uygular.\n",
        "\n",
        "    Parametreler:\n",
        "    -----------\n",
        "    data : ndarray\n",
        "        Filtrelenecek sinyal\n",
        "    lowcut : float\n",
        "        Alt kesim frekansı (Hz)\n",
        "    highcut : float\n",
        "        Üst kesim frekansı (Hz)\n",
        "    fs : float\n",
        "        Örnekleme frekansı (Hz)\n",
        "    order : int\n",
        "        Filtre sırası\n",
        "\n",
        "    Dönüş:\n",
        "    ------\n",
        "    filtered_data : ndarray\n",
        "        Filtrelenmiş sinyal\n",
        "    \"\"\"\n",
        "    nyquist = 0.5 * fs\n",
        "    low = lowcut / nyquist\n",
        "    high = highcut / nyquist\n",
        "\n",
        "    # Butterworth filtre katsayıları\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "\n",
        "    # Sıfır faz gecikmeli filtreleme\n",
        "    filtered_data = filtfilt(b, a, data, axis=-1)\n",
        "\n",
        "    return filtered_data"
      ],
      "metadata": {
        "id": "jTuJsFmcmbuf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Helper: normalize trials to (channels, samples) ----------\n",
        "def normalize_trials(eeg_trials, expected_channels=14):\n",
        "    \"\"\"\n",
        "    Ensure each trial array has shape (channels, samples).\n",
        "    Input trials are typically (samples, 14) (as in DREAMER) -> transposed.\n",
        "    Returns a list of ndarray shaped (channels, samples).\n",
        "    \"\"\"\n",
        "    normalized = []\n",
        "    for i, tr in enumerate(eeg_trials):\n",
        "        arr = np.asarray(tr)\n",
        "        if arr.size == 0:\n",
        "            continue\n",
        "        # if shape is (samples, channels) and channels == expected_channels, transpose:\n",
        "        if arr.ndim == 2 and arr.shape[1] == expected_channels and arr.shape[0] != expected_channels:\n",
        "            arr = arr.T  # -> (channels, samples)\n",
        "        elif arr.ndim == 2 and arr.shape[0] == expected_channels:\n",
        "            # Already channels x samples\n",
        "            pass\n",
        "        else:\n",
        "            # Unexpected shape: try to guess or raise\n",
        "            # If one dim equals expected_channels, bring it to first axis\n",
        "            if arr.ndim == 2 and arr.shape[0] == expected_channels:\n",
        "                pass\n",
        "            elif arr.ndim == 2 and arr.shape[1] == expected_channels:\n",
        "                arr = arr.T\n",
        "            else:\n",
        "                # last resort: reshape if product matches, but safer to skip\n",
        "                raise ValueError(f\"Trial {i} has unexpected shape {arr.shape}. Expected one axis == {expected_channels}.\")\n",
        "        normalized.append(arr)\n",
        "    return normalized"
      ],
      "metadata": {
        "id": "hTs_7b5jzx7k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. DİFERANSİYEL ENTROPİ (DE) ÖZNİTELİK ÇIKARIMI"
      ],
      "metadata": {
        "id": "FB9uoIl7pDch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Diferansiyel Entropi (DE) Teorik Temeli\n",
        "\n",
        "Diferansiyel Entropi, Gaussian dağılımlı bir rastgele değişkenin belirsizlik\n",
        "ölçüsüdür. Bir X rastgele değişkeni için:\n",
        "\n",
        "    DE(X) = (1/2) * log(2πeσ²)\n",
        "\n",
        "Burada σ² varyans (güç) ifade eder. EEG sinyali yaklaşık olarak Gaussian\n",
        "dağılımlı olduğunda:\n",
        "\n",
        "    DE ≈ (1/2) * log(2πe) + (1/2) * log(var(X))\n",
        "    DE ≈ (1/2) * log(var(X)) + constant\n",
        "\n",
        "Sabit terim ihmal edildiğinde:\n",
        "\n",
        "    DE ≈ log(var(X))\n",
        "\n",
        "**DE'nin Avantajları**:\n",
        "1. **Güç spektrumu ile ilişkili**: EEG gücünün logaritmik ölçüsü\n",
        "2. **Duygusal durumlarla yüksek korelasyon**:\n",
        "   - Pozitif duygular → α/β bantlarında yüksek DE\n",
        "   - Negatif duygular → δ/θ bantlarında yüksek DE\n",
        "3. **Boyut azaltma**: Ham EEG (14 kanal × binlerce örneklem) → Kompakt temsil\n",
        "4. **Literatürde kanıtlanmış**: Zheng & Lu (2015) %86+ başarı göstermiştir\n",
        "\n",
        "## 5.2 DE Hesaplama Algoritması\n",
        "\n",
        "Her bir deneme için:\n",
        "1. EEG sinyalini frekans bantlarına ayır (5 bant)\n",
        "2. Her bant için her kanalda varyansı hesapla\n",
        "3. DE = log(var + ε) (ε: sayısal kararlılık için küçük sabit)\n",
        "4. Sonuç: (14 kanal × 5 bant) = 70 boyutlu öznitelik vektörü"
      ],
      "metadata": {
        "id": "qNu7VqmWpYtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_differential_entropy(signal):\n",
        "    \"\"\"\n",
        "    Bir sinyal için diferansiyel entropi hesaplar.\n",
        "\n",
        "    Parametreler:\n",
        "    -----------\n",
        "    signal : ndarray\n",
        "        EEG sinyal kesiti\n",
        "\n",
        "    Dönüş:\n",
        "    ------\n",
        "    de : float\n",
        "        Diferansiyel entropi değeri\n",
        "    \"\"\"\n",
        "    # Varyans hesapla\n",
        "    variance = np.var(signal)\n",
        "\n",
        "    # Sayısal kararlılık için epsilon ekle\n",
        "    epsilon = 1e-10\n",
        "\n",
        "    # DE = log(var)\n",
        "    de = np.log(variance + epsilon)\n",
        "\n",
        "    return de"
      ],
      "metadata": {
        "id": "gezlxpWaoNAY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 Tüm Veri Kümesi için DE Öznitelik Çıkarımı\n",
        "\n",
        "Bu işlem hesaplama açısından yoğundur:\n",
        "- 23 denek × 18 deneme = 414 deneme\n",
        "- Her deneme: 14 kanal × 5 bant filtreleme"
      ],
      "metadata": {
        "id": "Wn4F3eT2DOV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- DE feature extraction adapted to (channels, samples) trials ----------\n",
        "def extract_de_features(eeg_trial, fs=SAMPLING_FREQ):\n",
        "    \"\"\"\n",
        "    Compute DE features for a single trial.\n",
        "    eeg_trial: ndarray with shape (channels, samples)  -> (14, T)\n",
        "    Returns flattened (14 * n_bands,) vector.\n",
        "    \"\"\"\n",
        "    eeg_trial = np.asarray(eeg_trial)\n",
        "    if eeg_trial.ndim != 2:\n",
        "        raise ValueError(f\"eeg_trial must be 2D (channels, samples). Got shape {eeg_trial.shape}\")\n",
        "\n",
        "    num_channels = eeg_trial.shape[0]\n",
        "    num_bands = len(FREQ_BANDS)\n",
        "    de_features = np.zeros((num_channels, num_bands))\n",
        "\n",
        "    # iterate channels\n",
        "    for ch_idx in range(num_channels):\n",
        "        channel_signal = eeg_trial[ch_idx, :]\n",
        "\n",
        "        for band_idx, (band_name, (low, high)) in enumerate(FREQ_BANDS.items()):\n",
        "            # Apply bandpass - ensure length > order*3\n",
        "            try:\n",
        "                filtered_signal = butter_bandpass_filter(channel_signal, low, high, fs)\n",
        "            except Exception as e:\n",
        "                # fallback: if filter fails (too short), compute DE on raw channel\n",
        "                filtered_signal = channel_signal\n",
        "            de = compute_differential_entropy(filtered_signal)\n",
        "            de_features[ch_idx, band_idx] = de\n",
        "\n",
        "    return de_features.flatten()\n",
        "\n",
        "# ---------- extract_all_de_features for flat list of trials ----------\n",
        "def extract_all_de_features(eeg_trials):\n",
        "    \"\"\"\n",
        "    Extract DE features from a flat list of trials. Each trial -> (channels, samples).\n",
        "    Returns numpy array shape (n_trials, n_features) where n_features = 14 * n_bands.\n",
        "    \"\"\"\n",
        "    print(\"DE öznitelikleri çıkarılıyor...\")\n",
        "\n",
        "    # normalize shapes (transposes where needed)\n",
        "    normalized = normalize_trials(eeg_trials, expected_channels=14)\n",
        "\n",
        "    all_features = []\n",
        "    total = len(normalized)\n",
        "    for idx, trial in enumerate(normalized):\n",
        "        de_feat = extract_de_features(trial)\n",
        "        all_features.append(de_feat)\n",
        "        # progress print every 50 or last\n",
        "        if (idx + 1) % 50 == 0 or (idx + 1) == total:\n",
        "            print(f\"  {idx + 1}/{total} trial işlendi\")\n",
        "\n",
        "    all_features = np.vstack(all_features)  # (n_trials, 70)\n",
        "    print(f\"✓ Öznitelik çıkarımı tamamlandı: {all_features.shape}\")\n",
        "\n",
        "    return all_features"
      ],
      "metadata": {
        "id": "oALftaRqrC0t"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. VERİ SETİ HAZIRLIĞI VE NORMALLEŞTIRME"
      ],
      "metadata": {
        "id": "nFlMLz0xD4gp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1 Leave-One-Subject-Out (LOSO) Çapraz Doğrulama\n",
        "\n",
        "**LOSO Yaklaşımının Önemi**:\n",
        "\n",
        "Geleneksel rastgele bölme (train/test split), aynı denekten farklı denemeleri\n",
        "hem eğitim hem de test setine yerleştirebilir. Bu, yapay olarak yüksek başarı\n",
        "ölçümlerine yol açar çünkü:\n",
        "- Her bireyin benzersiz EEG özellikleri vardır\n",
        "- Model, belirli bir bireye \"overfitting\" yapabilir\n",
        "\n",
        "**LOSO Çözümü**:\n",
        "- Her iterasyonda, bir denek tamamen test setine ayrılır\n",
        "- Kalan 22 denek eğitim için kullanılır\n",
        "- 23 iterasyon sonunda, her deneğin test sonucu elde edilir\n",
        "- Gerçek dünya senaryosunu simüle eder (yeni bir kullanıcı için tahmin)\n",
        "\n",
        "**Akademik Gerekçe**:\n",
        "- \"Subject-independent\" değerlendirme literatürde altın standarttır\n",
        "- Daha düşük başarı oranları, daha güvenilir sonuçlardır\n",
        "- İyi modeller %65-80 arası başarı gösterir (subject-dependent %85-95)\n",
        "\n",
        "## 6.2 Veri Normalleştirme (Standardization)\n",
        "\n",
        "**Z-score Normalleştirme**:\n",
        "    x_normalized = (x - μ) / σ\n",
        "\n",
        "**Neden Gerekli**:\n",
        "- Farklı frekans bantlarının güç seviyeleri farklıdır (örn: α >> γ)\n",
        "- Gradyan iniş optimizasyonu için ölçek tutarlılığı gerekir\n",
        "- Modelin yakınsama hızını artırır\n",
        "\n",
        "**LOSO'da Önemli Nokta**:\n",
        "- Her fold için StandardScaler, sadece eğitim verisi üzerinde fit edilir\n",
        "- Test verisi, eğitim verisinin μ ve σ değerleri ile normalize edilir\n",
        "- Bu, veri sızıntısını (data leakage) önler"
      ],
      "metadata": {
        "id": "FURcVBD-EAgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_loso_folds(features, labels, subject_ids):\n",
        "    \"\"\"\n",
        "    LOSO çapraz doğrulama için veri katlarını hazırlar.\n",
        "\n",
        "    Parametreler:\n",
        "    -----------\n",
        "    features : ndarray\n",
        "        Öznitelik matrisi (N × 70)\n",
        "    labels : ndarray\n",
        "        Etiket vektörü (N,)\n",
        "    subject_ids : ndarray\n",
        "        Denek kimlikleri (N,)\n",
        "\n",
        "    Dönüş:\n",
        "    ------\n",
        "    folds : list of tuples\n",
        "        Her fold için (X_train, X_test, y_train, y_test) tuple'ları\n",
        "    \"\"\"\n",
        "    logo = LeaveOneGroupOut()\n",
        "    folds = []\n",
        "\n",
        "    print(f\"LOSO: {len(np.unique(subject_ids))} fold oluşturuluyor...\")\n",
        "\n",
        "    for train_idx, test_idx in logo.split(features, labels, subject_ids):\n",
        "        X_train, X_test = features[train_idx], features[test_idx]\n",
        "        y_train, y_test = labels[train_idx], labels[test_idx]\n",
        "\n",
        "        # Normalleştirme (sadece eğitim verisi üzerinde fit)\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        folds.append((X_train, X_test, y_train, y_test))\n",
        "\n",
        "    print(f\"✓ {len(folds)} fold hazırlandı\")\n",
        "\n",
        "    return folds"
      ],
      "metadata": {
        "id": "nAey4HeID3bI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. HİBRİT CNN-LSTM MODEL MİMARİSİ"
      ],
      "metadata": {
        "id": "OXhfhZzoGjos"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 Mimari Tasarım Felsefesi\n",
        "\n",
        "**Neden Hibrit Mimari?**\n",
        "\n",
        "1. **CNN Katmanları**:\n",
        "   - Amaç: 14 kanal × 5 bant matrisindeki yerel uzamsal örüntüleri yakalamak\n",
        "   - Topoğrafik bilgi: Komşu elektrotlar ve frekans bantları arasındaki ilişki\n",
        "   - Örnek: Frontal bölgede α bandı simetrisi (duygu lateralizasyonu)\n",
        "\n",
        "2. **LSTM Katmanları**:\n",
        "   - Amaç: Farklı kanallar ve bantlar arasındaki global bağımlılıkları öğrenmek\n",
        "   - 70 boyutlu vektördeki ardışık ilişkileri modellemek\n",
        "   - Uzun vadeli bağımlılıkları yakalamak\n",
        "\n",
        "## 7.2 Önerilen Mimari Detayları\n",
        "\n",
        "**Katman Yapısı**:\n",
        "1. Giriş: (70,) → Reshape → (14, 5, 1) [Kanal, Bant, Kanal-sayısı]\n",
        "2. Conv2D Blokları: Yerel örüntü tespiti\n",
        "   - İlk Conv: 64 filtre (3×3) → BatchNorm → ReLU → MaxPool\n",
        "   - İkinci Conv: 128 filtre (3×3) → BatchNorm → ReLU → MaxPool\n",
        "3. Flatten → Reshape: CNN çıktısını LSTM için hazırla\n",
        "4. LSTM Katmanı: 64 unit, return_sequences=False\n",
        "5. Dropout: Overfitting önleme (0.5)\n",
        "6. Dense Çıkış: 2 sınıf (softmax)\n",
        "\n",
        "**Hiperparametre Gerekçeleri**:\n",
        "- **Filtre sayıları (64, 128)**: Yeteri kadar kapasite, aşırı karmaşıklık yok\n",
        "- **Kernel boyutu (3×3)**: 5×5'e göre daha az parametre, 2×2'ye göre daha fazla bağlam\n",
        "- **LSTM unit sayısı (64)**: Dengeli öğrenme kapasitesi\n",
        "- **Dropout (0.5)**: Standart regularizasyon değeri"
      ],
      "metadata": {
        "id": "IY5QCKKPGruR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_hybrid_cnn_lstm_model(input_shape=(70,), num_classes=2):\n",
        "    \"\"\"\n",
        "    Hibrit CNN-LSTM modeli oluşturur.\n",
        "\n",
        "    Parametreler:\n",
        "    -----------\n",
        "    input_shape : tuple\n",
        "        Giriş şekli (70,)\n",
        "    num_classes : int\n",
        "        Sınıf sayısı (2 - ikili sınıflandırma)\n",
        "\n",
        "    Dönüş:\n",
        "    ------\n",
        "    model : keras.Model\n",
        "        Derlenmemiş Keras modeli\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape, name='input_features')\n",
        "\n",
        "    # 70 boyutlu vektörü (14, 5, 1) matrise dönüştür\n",
        "    # 14 kanal, 5 frekans bandı, 1 öznitelik kanalı\n",
        "    x = layers.Reshape((14, 5, 1), name='reshape_to_2d')(inputs)\n",
        "\n",
        "    # ==================== CNN BLOKLARI ====================\n",
        "\n",
        "    # CNN Blok 1\n",
        "    x = layers.Conv2D(64, kernel_size=(3, 3), padding='same', name='conv2d_1')(x)\n",
        "    x = layers.BatchNormalization(name='bn_1')(x)\n",
        "    x = layers.Activation('relu', name='relu_1')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2), name='maxpool_1')(x)\n",
        "    x = layers.Dropout(0.3, name='dropout_1')(x)\n",
        "\n",
        "    # CNN Blok 2\n",
        "    x = layers.Conv2D(128, kernel_size=(3, 3), padding='same', name='conv2d_2')(x)\n",
        "    x = layers.BatchNormalization(name='bn_2')(x)\n",
        "    x = layers.Activation('relu', name='relu_2')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2), name='maxpool_2')(x)\n",
        "    x = layers.Dropout(0.3, name='dropout_2')(x)\n",
        "\n",
        "    # CNN çıktısını düzleştir\n",
        "    x = layers.Flatten(name='flatten')(x)\n",
        "\n",
        "    # ==================== LSTM BLOKLARI ====================\n",
        "\n",
        "    # LSTM için yeniden şekillendir: (batch, timesteps, features)\n",
        "    # Flatten çıktısını zaman adımlarına böl\n",
        "    x = layers.Reshape((-1, 128), name='reshape_for_lstm')(x)\n",
        "\n",
        "    # LSTM Katmanı\n",
        "    x = layers.LSTM(64, return_sequences=False, name='lstm_1')(x)\n",
        "    x = layers.Dropout(0.5, name='dropout_lstm')(x)\n",
        "\n",
        "    # ==================== ÇIKIŞ KATMANI ====================\n",
        "\n",
        "    # Tam bağlı katman\n",
        "    x = layers.Dense(32, activation='relu', name='dense_1')(x)\n",
        "    x = layers.Dropout(0.4, name='dropout_dense')(x)\n",
        "\n",
        "    # Çıkış katmanı\n",
        "    outputs = layers.Dense(num_classes, activation='softmax', name='output')(x)\n",
        "\n",
        "    # Model oluştur\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name='Hybrid_CNN_LSTM')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "MDl5QM76GdtM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.3 Model Derleme ve Optimizasyon Parametreleri\n",
        "\n",
        "**Kayıp Fonksiyonu**: Sparse Categorical Crossentropy\n",
        "- İkili sınıflandırma için uygun\n",
        "- Etiketler one-hot encoded değil, integer formatında (0, 1)\n",
        "\n",
        "**Optimizasyon**: Adam\n",
        "- Adaptif öğrenme oranı\n",
        "- Momentum ve RMSprop'un avantajlarını birleştirir\n",
        "- Başlangıç öğrenme oranı: 0.001 (standart)\n",
        "\n",
        "**Metrikler**:\n",
        "- Model Keras tarafında yalnızca Sparse Categorical Accuracy ile derlenir.\n",
        "   - Bu metrik, sınıf etiketleri integer olduğu için güvenli ve standarttır.\n",
        "- Precision, Recall ve F1-Score, Keras içinde değil,\n",
        "   - tahminler alındıktan sonra sklearn kullanılarak hesaplanacaktır.\n",
        "- Bu yaklaşım:\n",
        "   - Keras’ın bazı durumlarda hatalı Precision/Recall göstermesini önler,\n",
        "   - Çok sınıflı görevlerde daha güvenilir sonuçlar elde etmenizi sağlar."
      ],
      "metadata": {
        "id": "Jr06ZGhiIJYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_model(model, learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    Compile model without Keras Precision/Recall (compute them with sklearn after predictions).\n",
        "    \"\"\"\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['sparse_categorical_accuracy']  # keep a safe accuracy metric\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "NuZn4kBqw93t"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. MODEL EĞİTİMİ VE LOSO ÇAPRAZ DOĞRULAMA"
      ],
      "metadata": {
        "id": "ML-6R0kiJMzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.1 Callback Fonksiyonları\n",
        "\n",
        "**EarlyStopping**:\n",
        "- Amaç: Overfitting'i önlemek\n",
        "- İzlenen metrik: Doğrulama kaybı (val_loss)\n",
        "- Sabır (patience): 15 epoch (iyileşme yoksa durdur)\n",
        "- Mod: 'min' (kayıp minimize edilmeli)\n",
        "\n",
        "**ModelCheckpoint**:\n",
        "- Amaç: En iyi modeli kaydetmek\n",
        "- Kriter: En düşük doğrulama kaybı\n",
        "- save_best_only: True (sadece iyileşme olduğunda kaydet)\n",
        "\n",
        "**ReduceLROnPlateau**:\n",
        "- Amaç: Öğrenme oranını dinamik azaltmak\n",
        "- Plato tespit edildiğinde (5 epoch iyileşme yok) → LR × 0.5\n",
        "- Minimum LR: 1e-6\n",
        "\n",
        "Bu callback'ler, modelin optimal yakınsamasını ve genelleme yeteneğini artırır."
      ],
      "metadata": {
        "id": "tXuT8_wpJXQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_callbacks(fold_idx, emotion_type):\n",
        "    \"\"\"\n",
        "    Eğitim callback'lerini oluşturur.\n",
        "\n",
        "    Parametreler:\n",
        "    -----------\n",
        "    fold_idx : int\n",
        "        Fold numarası\n",
        "    emotion_type : str\n",
        "        'valence' veya 'arousal'\n",
        "\n",
        "    Dönüş:\n",
        "    ------\n",
        "    callbacks_list : list\n",
        "        Callback nesneleri listesi\n",
        "    \"\"\"\n",
        "\n",
        "    # Early stopping\n",
        "    early_stop = callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=15,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Model checkpoint\n",
        "    checkpoint_path = f'best_model_{emotion_type}_fold{fold_idx}.h5'\n",
        "    model_checkpoint = callbacks.ModelCheckpoint(\n",
        "        checkpoint_path,\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Learning rate reduction\n",
        "    reduce_lr = callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return [early_stop, model_checkpoint, reduce_lr]"
      ],
      "metadata": {
        "id": "bXC3-bleJLEC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.2 LOSO Çapraz Doğrulama Eğitim Döngüsü\n",
        "\n",
        "Her fold için:\n",
        "1. Yeni bir model oluştur (transfer learning yok, her fold bağımsız)\n",
        "2. Eğitim setinin %15'ini doğrulama için ayır\n",
        "3. Model eğit (maksimum 100 epoch, early stopping ile)\n",
        "4. Test setinde değerlendir\n",
        "5. Tahminleri ve metrikleri sakla\n",
        "\n",
        "Toplam 23 fold sonunda:\n",
        "- Ortalama ve standart sapma hesapla\n",
        "- Tüm tahminleri birleştirerek global metrikler hesapla"
      ],
      "metadata": {
        "id": "9PwN25YyOph2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loso_cross_validation(folds, emotion_type, epochs=100, batch_size=32):\n",
        "    \"\"\"\n",
        "    LOSO cross-validation training. Computes precision/recall/f1 with sklearn after each fold.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"  {emotion_type.upper()} İÇİN LOSO ÇAPRAZ DOĞRULAMA EĞİTİMİ\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    fold_accuracies = []\n",
        "    fold_f1_scores = []\n",
        "    fold_precisions = []\n",
        "    fold_recalls = []\n",
        "    all_predictions = []\n",
        "    all_true_labels = []\n",
        "    histories = []\n",
        "\n",
        "    for fold_idx, (X_train, X_test, y_train, y_test) in enumerate(folds):\n",
        "        print(f\"\\n--- Fold {fold_idx + 1}/{len(folds)} ---\")\n",
        "        print(f\"Eğitim boyutu: {X_train.shape[0]}, Test boyutu: {X_test.shape[0]}\")\n",
        "\n",
        "        # Yeni model oluştur\n",
        "        model = build_hybrid_cnn_lstm_model()\n",
        "        model = compile_model(model)\n",
        "\n",
        "        # Callbacks\n",
        "        fold_callbacks = create_callbacks(fold_idx, emotion_type)\n",
        "\n",
        "        # Model eğitimi\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_split=0.15,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=fold_callbacks,\n",
        "            verbose=1  # set to 1 to see training progress per fold\n",
        "        )\n",
        "\n",
        "        # Test tahminleri (probabilities -> class indices)\n",
        "        y_pred_proba = model.predict(X_test, verbose=0)\n",
        "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "        # Convert to numpy arrays (ensure shapes)\n",
        "        y_test_arr = np.asarray(y_test).flatten()\n",
        "        y_pred_arr = np.asarray(y_pred).flatten()\n",
        "\n",
        "        # Metrikler (sklearn)\n",
        "        accuracy = accuracy_score(y_test_arr, y_pred_arr)\n",
        "        f1 = f1_score(y_test_arr, y_pred_arr, average='weighted', zero_division=0)\n",
        "        precision = precision_score(y_test_arr, y_pred_arr, average='weighted', zero_division=0)\n",
        "        recall = recall_score(y_test_arr, y_pred_arr, average='weighted', zero_division=0)\n",
        "\n",
        "        fold_accuracies.append(accuracy)\n",
        "        fold_f1_scores.append(f1)\n",
        "        fold_precisions.append(precision)\n",
        "        fold_recalls.append(recall)\n",
        "\n",
        "        all_predictions.extend(y_pred_arr.tolist())\n",
        "        all_true_labels.extend(y_test_arr.tolist())\n",
        "        histories.append(history)\n",
        "\n",
        "        print(f\"  Test Accuracy: {accuracy*100:.2f}%\")\n",
        "        print(f\"  Test Precision (weighted): {precision*100:.2f}%\")\n",
        "        print(f\"  Test Recall (weighted): {recall*100:.2f}%\")\n",
        "        print(f\"  Test F1-Score (weighted): {f1*100:.2f}%\")\n",
        "\n",
        "    # Toplam sonuçlar\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"  {emotion_type.upper()} SONUÇLARI\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Ortalama Accuracy: {np.mean(fold_accuracies)*100:.2f}% ± {np.std(fold_accuracies)*100:.2f}%\")\n",
        "    print(f\"Ortalama Precision: {np.mean(fold_precisions)*100:.2f}% ± {np.std(fold_precisions)*100:.2f}%\")\n",
        "    print(f\"Ortalama Recall: {np.mean(fold_recalls)*100:.2f}% ± {np.std(fold_recalls)*100:.2f}%\")\n",
        "    print(f\"Ortalama F1-Score: {np.mean(fold_f1_scores)*100:.2f}% ± {np.std(fold_f1_scores)*100:.2f}%\")\n",
        "\n",
        "    results = {\n",
        "        'fold_accuracies': fold_accuracies,\n",
        "        'fold_f1_scores': fold_f1_scores,\n",
        "        'fold_precisions': fold_precisions,\n",
        "        'fold_recalls': fold_recalls,\n",
        "        'all_predictions': np.array(all_predictions),\n",
        "        'all_true_labels': np.array(all_true_labels),\n",
        "        'histories': histories,\n",
        "        'mean_accuracy': np.mean(fold_accuracies),\n",
        "        'std_accuracy': np.std(fold_accuracies),\n",
        "        'mean_f1': np.mean(fold_f1_scores),\n",
        "        'std_f1': np.std(fold_f1_scores),\n",
        "        'mean_precision': np.mean(fold_precisions),\n",
        "        'std_precision': np.std(fold_precisions),\n",
        "        'mean_recall': np.mean(fold_recalls),\n",
        "        'std_recall': np.std(fold_recalls)\n",
        "    }\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "PMFbZENvxO0j"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.1 Eğitim Geçmişi Görselleştirme\n",
        "\n",
        "Eğitim ve doğrulama kayıp/başarı grafikleri:\n",
        "- Overfitting tespiti (eğitim-doğrulama ayrışması)\n",
        "- Yakınsama analizi\n",
        "- Early stopping etkisi"
      ],
      "metadata": {
        "id": "6kXKVX1DJe2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(histories, emotion_type):\n",
        "    \"\"\"\n",
        "    Tüm fold'ların eğitim geçmişini görselleştirir.\n",
        "\n",
        "    Parametreler:\n",
        "    -----------\n",
        "    histories : list\n",
        "        Keras History nesneleri\n",
        "    emotion_type : str\n",
        "        'valence' veya 'arousal'\n",
        "    \"\"\"\n",
        "    # Safety checks\n",
        "    if histories is None or len(histories) == 0:\n",
        "        print(\"No training histories to plot.\")\n",
        "        return\n",
        "\n",
        "    # Determine accuracy key (some runs use 'accuracy', others 'sparse_categorical_accuracy')\n",
        "    sample_hist = histories[0].history\n",
        "    acc_key = None\n",
        "    for k in sample_hist.keys():\n",
        "        if 'accuracy' in k and not k.startswith('val_'):\n",
        "            acc_key = k\n",
        "            break\n",
        "    if acc_key is None:\n",
        "        # fallback to 'accuracy'\n",
        "        acc_key = 'accuracy'\n",
        "\n",
        "    val_acc_key = 'val_' + acc_key\n",
        "\n",
        "    # Find minimum epoch length across all histories (truncate longer histories)\n",
        "    epoch_lengths = [len(h.history.get('loss', [])) for h in histories]\n",
        "    min_epochs = min(epoch_lengths)\n",
        "    if min_epochs == 0:\n",
        "        print(\"Histories present but no epoch records found.\")\n",
        "        return\n",
        "\n",
        "    # Build arrays truncated to min_epochs\n",
        "    train_losses = np.array([h.history['loss'][:min_epochs] for h in histories])\n",
        "    val_losses = np.array([h.history.get('val_loss', [np.nan]*min_epochs)[:min_epochs] for h in histories])\n",
        "\n",
        "    train_accs = np.array([h.history.get(acc_key, [np.nan]*min_epochs)[:min_epochs] for h in histories])\n",
        "    val_accs = np.array([h.history.get(val_acc_key, [np.nan]*min_epochs)[:min_epochs] for h in histories])\n",
        "\n",
        "    # Compute means across folds (axis=0)\n",
        "    avg_train_loss = np.nanmean(train_losses, axis=0)\n",
        "    avg_val_loss = np.nanmean(val_losses, axis=0)\n",
        "    avg_train_acc = np.nanmean(train_accs, axis=0)\n",
        "    avg_val_acc = np.nanmean(val_accs, axis=0)\n",
        "\n",
        "    epochs_range = range(1, min_epochs + 1)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    fig.suptitle(f'{emotion_type.upper()} - Eğitim Geçmişi (Ortalama, {min_epochs} epoch)', fontsize=14, fontweight='bold')\n",
        "\n",
        "    # Loss plot\n",
        "    axes[0].plot(epochs_range, avg_train_loss, label='Eğitim Kaybı', linewidth=2)\n",
        "    axes[0].plot(epochs_range, avg_val_loss, label='Doğrulama Kaybı', linewidth=2)\n",
        "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[0].set_ylabel('Kayıp', fontsize=12)\n",
        "    axes[0].set_title('Model Kaybı', fontsize=12)\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy plot\n",
        "    axes[1].plot(epochs_range, avg_train_acc, label='Eğitim Başarısı', linewidth=2)\n",
        "    axes[1].plot(epochs_range, avg_val_acc, label='Doğrulama Başarısı', linewidth=2)\n",
        "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[1].set_ylabel('Başarı', fontsize=12)\n",
        "    axes[1].set_title('Model Başarısı', fontsize=12)\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "S6-C_zgYqsfD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.2 Karmaşıklık Matrisi (Confusion Matrix)\n",
        "\n",
        "Karmaşıklık matrisi, modelin hangi sınıfları karıştırdığını gösterir:\n",
        "- Köşegen elemanlar: Doğru sınıflandırmalar\n",
        "- Köşegen dışı: Hatalı sınıflandırmalar\n",
        "\n",
        "**Yorumlama**:\n",
        "- Yüksek recall, düşük precision → Çok fazla pozitif tahmin\n",
        "- Düşük recall, yüksek precision → Çok muhafazakar tahmin"
      ],
      "metadata": {
        "id": "PGtNUBl_JyUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, emotion_type):\n",
        "    \"\"\"\n",
        "    Karmaşıklık matrisini görselleştirir.\n",
        "\n",
        "    Parametreler:\n",
        "    -----------\n",
        "    y_true : ndarray\n",
        "        Gerçek etiketler\n",
        "    y_pred : ndarray\n",
        "        Tahmin edilen etiketler\n",
        "    emotion_type : str\n",
        "        'valence' veya 'arousal'\n",
        "    \"\"\"\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Sınıf isimleri\n",
        "    if emotion_type == 'valence':\n",
        "        class_names = ['Negatif', 'Pozitif']\n",
        "    else:\n",
        "        class_names = ['Düşük', 'Yüksek']\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names,\n",
        "                cbar_kws={'label': 'Sayı'})\n",
        "    plt.xlabel('Tahmin Edilen', fontsize=12)\n",
        "    plt.ylabel('Gerçek', fontsize=12)\n",
        "    plt.title(f'{emotion_type.upper()} - Karmaşıklık Matrisi',\n",
        "              fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Normalize edilmiş versiyon\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Greens',\n",
        "                xticklabels=class_names, yticklabels=class_names,\n",
        "                cbar_kws={'label': 'Oran'})\n",
        "    plt.xlabel('Tahmin Edilen', fontsize=12)\n",
        "    plt.ylabel('Gerçek', fontsize=12)\n",
        "    plt.title(f'{emotion_type.upper()} - Normalize Karmaşıklık Matrisi',\n",
        "              fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "S86QKB_9Jlnv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.3 Detaylı Sınıflandırma Raporu\n",
        "\n",
        "sklearn'ın classification_report fonksiyonu, her sınıf için:\n",
        "- Precision: TP / (TP + FP)\n",
        "- Recall: TP / (TP + FN)\n",
        "- F1-Score: 2 × (Precision × Recall) / (Precision + Recall)\n",
        "- Support: Her sınıftaki örnek sayısı\n",
        "\n",
        "değerlerini hesaplar."
      ],
      "metadata": {
        "id": "os2wwHQLKWgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_classification_report(y_true, y_pred, emotion_type):\n",
        "    \"\"\"\n",
        "    Detaylı sınıflandırma raporunu yazdırır.\n",
        "\n",
        "    Parametreler:\n",
        "    -----------\n",
        "    y_true : ndarray\n",
        "        Gerçek etiketler\n",
        "    y_pred : ndarray\n",
        "        Tahmin edilen etiketler\n",
        "    emotion_type : str\n",
        "        'valence' veya 'arousal'\n",
        "    \"\"\"\n",
        "\n",
        "    if emotion_type == 'valence':\n",
        "        target_names = ['Negatif', 'Pozitif']\n",
        "    else:\n",
        "        target_names = ['Düşük', 'Yüksek']\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"  {emotion_type.upper()} - SINIFLANDIRMA RAPORU\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    report = classification_report(y_true, y_pred, target_names=target_names, digits=4)\n",
        "    print(report)"
      ],
      "metadata": {
        "id": "9Y2H63yBKSj5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. ANA EĞİTİM PİPELINE"
      ],
      "metadata": {
        "id": "aXHicdFjKgxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.1 Veri Yükleme ve Ön İşleme Pipeline\n",
        "\n",
        "Veri kümesi: https://zenodo.org/records/546113"
      ],
      "metadata": {
        "id": "uEdCd_nZKu3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VERİ YOLU AYARI"
      ],
      "metadata": {
        "id": "BwW6CqKbLISR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/dreamer/DREAMER.mat\""
      ],
      "metadata": {
        "id": "I1Fh6YzzLyEc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Örnek kullanım için veri yolu kontrolü\n",
        "import os\n",
        "\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    print(\"=\"*70)\n",
        "    print(\"  UYARI: DREAMER.mat dosyası bulunamadı!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nLütfen aşağıdaki adımları takip edin:\")\n",
        "    print(\"1. DREAMER veri kümesini indirin:\")\n",
        "    print(\"   http://www.eecs.qmul.ac.uk/mmv/datasets/dreamer/\")\n",
        "    print(\"2. DREAMER.mat dosyasının yolunu DATA_PATH değişkenine atayın\")\n",
        "    print(\"3. Notebook'u yeniden çalıştırın\")\n",
        "    USE_DEMO_DATA = True\n",
        "else:\n",
        "    USE_DEMO_DATA = False\n",
        "    print(f\"✓ Veri dosyası bulundu: {DATA_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MVR6TdSKuKB",
        "outputId": "34f9c241-8a2a-4475-859e-561b85fccda5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Veri dosyası bulundu: /content/drive/MyDrive/dreamer/DREAMER.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.3 Ana Eğitim Fonksiyonu"
      ],
      "metadata": {
        "id": "CILTjVQ8OGsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main_pipeline():\n",
        "    \"\"\"\n",
        "    Uçtan uca eğitim pipeline'ı.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"  DREAMER EEG DUYGU TANIMA PROJESİ\")\n",
        "    print(\"  Hibrit CNN-LSTM Mimarisi + DE Öznitelikleri\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    # 1. Veri Yükleme\n",
        "    eeg_trials, valence_arr, arousal_arr, subject_ids = load_dreamer_from_matstruct(DATA_PATH)\n",
        "\n",
        "    # 2. İkili Etiket Dönüşümü\n",
        "    print(\"\\n--- İkili Etiket Dönüşümü ---\")\n",
        "    print(\"Valence:\")\n",
        "    valence_binary = convert_to_binary_labels(valence_arr, threshold=3.0)\n",
        "    print(\"\\nArousal:\")\n",
        "    arousal_binary = convert_to_binary_labels(arousal_arr, threshold=3.0)\n",
        "\n",
        "    # 3. DE Öznitelik Çıkarımı\n",
        "    print(\"\\n--- DE Öznitelik Çıkarımı ---\")\n",
        "    features = extract_all_de_features(eeg_trials)\n",
        "\n",
        "    print(f\"\\nÖznitelik matrisi şekli: {features.shape}\")\n",
        "    print(f\"Valence etiket şekli: {valence_binary.shape}\")\n",
        "    print(f\"Arousal etiket şekli: {arousal_binary.shape}\")\n",
        "\n",
        "    # 4. LOSO Fold Hazırlama - VALENCE\n",
        "    print(\"\\n--- VALENCE için LOSO Fold Hazırlama ---\")\n",
        "    valence_folds = prepare_loso_folds(features, valence_binary, subject_ids)\n",
        "\n",
        "    # 5. LOSO Fold Hazırlama - AROUSAL\n",
        "    print(\"\\n--- AROUSAL için LOSO Fold Hazırlama ---\")\n",
        "    arousal_folds = prepare_loso_folds(features, arousal_binary, subject_ids)\n",
        "\n",
        "    # 6. Model Eğitimi - VALENCE\n",
        "    valence_results = train_loso_cross_validation(\n",
        "        valence_folds,\n",
        "        emotion_type='valence',\n",
        "        epochs=100,\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    # 7. Model Eğitimi - AROUSAL\n",
        "    arousal_results = train_loso_cross_validation(\n",
        "        arousal_folds,\n",
        "        emotion_type='arousal',\n",
        "        epochs=100,\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    # 8. Sonuçların Görselleştirilmesi\n",
        "    print(\"\\n--- Sonuçlar Görselleştiriliyor ---\")\n",
        "\n",
        "    # Valence sonuçları\n",
        "    plot_training_history(valence_results['histories'], 'valence')\n",
        "    plot_confusion_matrix(\n",
        "        valence_results['all_true_labels'],\n",
        "        valence_results['all_predictions'],\n",
        "        'valence'\n",
        "    )\n",
        "    print_classification_report(\n",
        "        valence_results['all_true_labels'],\n",
        "        valence_results['all_predictions'],\n",
        "        'valence'\n",
        "    )\n",
        "\n",
        "    # Arousal sonuçları\n",
        "    plot_training_history(arousal_results['histories'], 'arousal')\n",
        "    plot_confusion_matrix(\n",
        "        arousal_results['all_true_labels'],\n",
        "        arousal_results['all_predictions'],\n",
        "        'arousal'\n",
        "    )\n",
        "    print_classification_report(\n",
        "        arousal_results['all_true_labels'],\n",
        "        arousal_results['all_predictions'],\n",
        "        'arousal'\n",
        "    )\n",
        "\n",
        "    # 9. Özet Tablo\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"  FİNAL SONUÇLAR ÖZETİ\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    summary = pd.DataFrame({\n",
        "        'Duygu Boyutu': ['Valence', 'Arousal'],\n",
        "        'Ortalama Accuracy (%)': [\n",
        "            f\"{valence_results['mean_accuracy']*100:.2f} ± {valence_results['std_accuracy']*100:.2f}\",\n",
        "            f\"{arousal_results['mean_accuracy']*100:.2f} ± {arousal_results['std_accuracy']*100:.2f}\"\n",
        "        ],\n",
        "        'Ortalama F1-Score (%)': [\n",
        "            f\"{valence_results['mean_f1']*100:.2f} ± {valence_results['std_f1']*100:.2f}\",\n",
        "            f\"{arousal_results['mean_f1']*100:.2f} ± {arousal_results['std_f1']*100:.2f}\"\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    print(summary.to_string(index=False))\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "    return valence_results, arousal_results"
      ],
      "metadata": {
        "id": "iEOLuA0UODUJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. NOTEBOOK ÇALIŞTIRMA"
      ],
      "metadata": {
        "id": "Rx3wdMl8O-P3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.2 Beklenen Sonuçlar\n",
        "\n",
        "**Literatür Karşılaştırması**:\n",
        "- DEAP veri kümesi (benzer): %75-85 (subject-independent)\n",
        "- DREAMER veri kümesi:\n",
        "  - Katsouris & Garoufallou (2021): %79.2 (Valence), %82.1 (Arousal)\n",
        "  - Li et al. (2018): %83.6 (Valence), %85.2 (Arousal) - subject-dependent\n",
        "\n",
        "**Bu Çalışmadan Beklenen**:\n",
        "- Valence: %70-80 (subject-independent)\n",
        "- Arousal: %72-82 (subject-independent)\n",
        "- Hibrit mimari sayesinde, tek mimari yaklaşımlardan %3-5 daha iyi\n",
        "\n",
        "## 11.3 Sonuçların Yorumlanması\n",
        "\n",
        "**Yüksek Başarı Göstergeleri**:\n",
        "- F1-Score > 0.75: İyi genelleme\n",
        "- Düşük standart sapma (< 0.05): Tutarlı performans\n",
        "- Balanced confusion matrix: Her iki sınıfı da iyi öğrenmiş\n",
        "\n",
        "**Düşük Başarı Nedenleri**:\n",
        "- Bireysel farklılıklar (LOSO'da beklenen)\n",
        "- Veri dengesizliği\n",
        "- Etiket kalitesi (öz-bildirim skorları subjektif)\n",
        "\n",
        "**İyileştirme Önerileri**:\n",
        "- Data augmentation (zaman ölçekleme, gürültü ekleme)\n",
        "- Transfer learning (başka veri kümeleri ile ön-eğitim)\n",
        "- Ensemble yöntemler (birden fazla modelin birleşimi)\n",
        "- Attention mekanizmaları (önemli kanalları vurgulama)"
      ],
      "metadata": {
        "id": "SUPRsqs-PHPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Notebook'u çalıştır\n",
        "if __name__ == \"__main__\":\n",
        "    valence_results, arousal_results = main_pipeline()\n",
        "\n",
        "    print(\"\\n✓ Notebook tamamlandı!\")\n",
        "    print(\"✓ Model ağırlıkları kaydedildi (best_model_*.h5)\")\n",
        "    print(\"✓ Sonuç grafikleri oluşturuldu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0Qo1wQX9PXCI",
        "outputId": "632b57ca-a6af-47b8-f399-9f9bf43f0fa8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "  DREAMER EEG DUYGU TANIMA PROJESİ\n",
            "  Hibrit CNN-LSTM Mimarisi + DE Öznitelikleri\n",
            "======================================================================\n",
            "\n",
            "Loaded 23 subjects -> total trials: 414\n",
            "Example trial shape (samples x channels): (25472, 14)\n",
            "\n",
            "--- İkili Etiket Dönüşümü ---\n",
            "Valence:\n",
            "Sınıf dağılımı - 0: 161, 1: 253\n",
            "Denge oranı: 63.6%\n",
            "\n",
            "Arousal:\n",
            "Sınıf dağılımı - 0: 114, 1: 300\n",
            "Denge oranı: 38.0%\n",
            "\n",
            "--- DE Öznitelik Çıkarımı ---\n",
            "DE öznitelikleri çıkarılıyor...\n",
            "  50/414 trial işlendi\n",
            "  100/414 trial işlendi\n",
            "  150/414 trial işlendi\n",
            "  200/414 trial işlendi\n",
            "  250/414 trial işlendi\n",
            "  300/414 trial işlendi\n",
            "  350/414 trial işlendi\n",
            "  400/414 trial işlendi\n",
            "  414/414 trial işlendi\n",
            "✓ Öznitelik çıkarımı tamamlandı: (414, 70)\n",
            "\n",
            "Öznitelik matrisi şekli: (414, 70)\n",
            "Valence etiket şekli: (414,)\n",
            "Arousal etiket şekli: (414,)\n",
            "\n",
            "--- VALENCE için LOSO Fold Hazırlama ---\n",
            "LOSO: 23 fold oluşturuluyor...\n",
            "✓ 23 fold hazırlandı\n",
            "\n",
            "--- AROUSAL için LOSO Fold Hazırlama ---\n",
            "LOSO: 23 fold oluşturuluyor...\n",
            "✓ 23 fold hazırlandı\n",
            "\n",
            "======================================================================\n",
            "  VALENCE İÇİN LOSO ÇAPRAZ DOĞRULAMA EĞİTİMİ\n",
            "======================================================================\n",
            "\n",
            "\n",
            "--- Fold 1/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7447 - sparse_categorical_accuracy: 0.4837"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 0.7394 - sparse_categorical_accuracy: 0.4894 - val_loss: 0.6785 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6749 - sparse_categorical_accuracy: 0.5838 - val_loss: 0.6798 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6900 - sparse_categorical_accuracy: 0.5907 - val_loss: 0.6869 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6858 - sparse_categorical_accuracy: 0.5923 - val_loss: 0.6849 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6804 - sparse_categorical_accuracy: 0.5679 - val_loss: 0.6825 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6753 - sparse_categorical_accuracy: 0.5611\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6750 - sparse_categorical_accuracy: 0.5638 - val_loss: 0.6829 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6691 - sparse_categorical_accuracy: 0.6122 - val_loss: 0.6823 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6734 - sparse_categorical_accuracy: 0.5742 - val_loss: 0.6805 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m 6/11\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6599 - sparse_categorical_accuracy: 0.5853 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6622 - sparse_categorical_accuracy: 0.5864 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6674 - sparse_categorical_accuracy: 0.5925"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6676 - sparse_categorical_accuracy: 0.5932 - val_loss: 0.6767 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6773 - sparse_categorical_accuracy: 0.5902 - val_loss: 0.6774 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6646 - sparse_categorical_accuracy: 0.6336"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6648 - sparse_categorical_accuracy: 0.6329 - val_loss: 0.6767 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6762 - sparse_categorical_accuracy: 0.6076"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6747 - sparse_categorical_accuracy: 0.6083 - val_loss: 0.6761 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6507 - sparse_categorical_accuracy: 0.6003"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6520 - sparse_categorical_accuracy: 0.6015 - val_loss: 0.6753 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6573 - sparse_categorical_accuracy: 0.6065"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6567 - sparse_categorical_accuracy: 0.6081 - val_loss: 0.6750 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6682 - sparse_categorical_accuracy: 0.6054 - val_loss: 0.6754 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6670 - sparse_categorical_accuracy: 0.5748 - val_loss: 0.6751 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6476 - sparse_categorical_accuracy: 0.6003 - val_loss: 0.6750 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6443 - sparse_categorical_accuracy: 0.6389"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6438 - sparse_categorical_accuracy: 0.6336 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6716 - sparse_categorical_accuracy: 0.6141 - val_loss: 0.6756 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6634 - sparse_categorical_accuracy: 0.5827 - val_loss: 0.6764 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6458 - sparse_categorical_accuracy: 0.5960 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6507 - sparse_categorical_accuracy: 0.6080 - val_loss: 0.6811 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6645 - sparse_categorical_accuracy: 0.6201\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6633 - sparse_categorical_accuracy: 0.6224 - val_loss: 0.6820 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6444 - sparse_categorical_accuracy: 0.6088 - val_loss: 0.6822 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.6554 - sparse_categorical_accuracy: 0.6238 - val_loss: 0.6820 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6451 - sparse_categorical_accuracy: 0.6199 - val_loss: 0.6809 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6376 - sparse_categorical_accuracy: 0.5935 - val_loss: 0.6795 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6673 - sparse_categorical_accuracy: 0.6201\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.6640 - sparse_categorical_accuracy: 0.6224 - val_loss: 0.6790 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6242 - sparse_categorical_accuracy: 0.6500 - val_loss: 0.6790 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6222 - sparse_categorical_accuracy: 0.6335 - val_loss: 0.6790 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6423 - sparse_categorical_accuracy: 0.5997 - val_loss: 0.6782 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6264 - sparse_categorical_accuracy: 0.6297 - val_loss: 0.6775 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6340 - sparse_categorical_accuracy: 0.6376\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6326 - sparse_categorical_accuracy: 0.6352 - val_loss: 0.6766 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 34: early stopping\n",
            "Restoring model weights from the end of the best epoch: 19.\n",
            "  Test Accuracy: 72.22%\n",
            "  Test Precision (weighted): 52.16%\n",
            "  Test Recall (weighted): 72.22%\n",
            "  Test F1-Score (weighted): 60.57%\n",
            "\n",
            "--- Fold 2/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6985 - sparse_categorical_accuracy: 0.5327"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.6989 - sparse_categorical_accuracy: 0.5344 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.7122 - sparse_categorical_accuracy: 0.5959 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6435 - sparse_categorical_accuracy: 0.5900 - val_loss: 0.6723 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.7040 - sparse_categorical_accuracy: 0.5703 - val_loss: 0.6713 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.7009 - sparse_categorical_accuracy: 0.6093"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6996 - sparse_categorical_accuracy: 0.6079 - val_loss: 0.6707 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 6/11\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6429 - sparse_categorical_accuracy: 0.5971"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6517 - sparse_categorical_accuracy: 0.6026 - val_loss: 0.6670 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6785 - sparse_categorical_accuracy: 0.6141"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6767 - sparse_categorical_accuracy: 0.6153 - val_loss: 0.6644 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6934 - sparse_categorical_accuracy: 0.6122"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6943 - sparse_categorical_accuracy: 0.6098 - val_loss: 0.6627 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6708 - sparse_categorical_accuracy: 0.6369 - val_loss: 0.6637 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6615 - sparse_categorical_accuracy: 0.5879"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6619 - sparse_categorical_accuracy: 0.5901 - val_loss: 0.6621 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6652 - sparse_categorical_accuracy: 0.6066"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6679 - sparse_categorical_accuracy: 0.6059 - val_loss: 0.6607 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6885 - sparse_categorical_accuracy: 0.6152"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6869 - sparse_categorical_accuracy: 0.6123 - val_loss: 0.6606 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6788 - sparse_categorical_accuracy: 0.5821 - val_loss: 0.6627 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6445 - sparse_categorical_accuracy: 0.6310 - val_loss: 0.6631 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6441 - sparse_categorical_accuracy: 0.6292"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6446 - sparse_categorical_accuracy: 0.6293 - val_loss: 0.6603 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6385 - sparse_categorical_accuracy: 0.6450"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6423 - sparse_categorical_accuracy: 0.6405 - val_loss: 0.6592 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6765 - sparse_categorical_accuracy: 0.6011 - val_loss: 0.6666 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6557 - sparse_categorical_accuracy: 0.6114 - val_loss: 0.6691 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6494 - sparse_categorical_accuracy: 0.6672 - val_loss: 0.6635 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6691 - sparse_categorical_accuracy: 0.6016 - val_loss: 0.6618 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6505 - sparse_categorical_accuracy: 0.6703\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.6499 - sparse_categorical_accuracy: 0.6693 - val_loss: 0.6597 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6618 - sparse_categorical_accuracy: 0.6208"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.6605 - sparse_categorical_accuracy: 0.6201 - val_loss: 0.6580 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.6687 - sparse_categorical_accuracy: 0.6541 - val_loss: 0.6582 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.6380 - sparse_categorical_accuracy: 0.6642 - val_loss: 0.6595 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.6553 - sparse_categorical_accuracy: 0.6162 - val_loss: 0.6592 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6577 - sparse_categorical_accuracy: 0.6319"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.6567 - sparse_categorical_accuracy: 0.6302 - val_loss: 0.6574 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6763 - sparse_categorical_accuracy: 0.5957"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6703 - sparse_categorical_accuracy: 0.6025 - val_loss: 0.6554 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6403 - sparse_categorical_accuracy: 0.6386 - val_loss: 0.6564 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6414 - sparse_categorical_accuracy: 0.6453 - val_loss: 0.6564 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6364 - sparse_categorical_accuracy: 0.6341 - val_loss: 0.6556 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6322 - sparse_categorical_accuracy: 0.6526"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6328 - sparse_categorical_accuracy: 0.6495 - val_loss: 0.6551 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6372 - sparse_categorical_accuracy: 0.6636"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6394 - sparse_categorical_accuracy: 0.6594 - val_loss: 0.6540 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6501 - sparse_categorical_accuracy: 0.6397 - val_loss: 0.6543 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6451 - sparse_categorical_accuracy: 0.6463"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6437 - sparse_categorical_accuracy: 0.6424 - val_loss: 0.6538 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6321 - sparse_categorical_accuracy: 0.6299 - val_loss: 0.6542 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6238 - sparse_categorical_accuracy: 0.6323 - val_loss: 0.6544 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6342 - sparse_categorical_accuracy: 0.6332"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6346 - sparse_categorical_accuracy: 0.6363 - val_loss: 0.6531 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6445 - sparse_categorical_accuracy: 0.6186"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6428 - sparse_categorical_accuracy: 0.6206 - val_loss: 0.6522 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6344 - sparse_categorical_accuracy: 0.6837"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6335 - sparse_categorical_accuracy: 0.6799 - val_loss: 0.6516 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6282 - sparse_categorical_accuracy: 0.6642"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6281 - sparse_categorical_accuracy: 0.6639 - val_loss: 0.6497 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6471 - sparse_categorical_accuracy: 0.6061"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6463 - sparse_categorical_accuracy: 0.6079 - val_loss: 0.6472 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6286 - sparse_categorical_accuracy: 0.6444 - val_loss: 0.6475 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6249 - sparse_categorical_accuracy: 0.6566 - val_loss: 0.6502 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6120 - sparse_categorical_accuracy: 0.6308 - val_loss: 0.6508 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6103 - sparse_categorical_accuracy: 0.6572 - val_loss: 0.6512 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6608 - sparse_categorical_accuracy: 0.6322\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6556 - sparse_categorical_accuracy: 0.6369 - val_loss: 0.6522 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5780 - sparse_categorical_accuracy: 0.7110 - val_loss: 0.6519 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6323 - sparse_categorical_accuracy: 0.6526 - val_loss: 0.6522 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6377 - sparse_categorical_accuracy: 0.6482 - val_loss: 0.6533 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6092 - sparse_categorical_accuracy: 0.6929 - val_loss: 0.6536 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 2.5000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6215 - sparse_categorical_accuracy: 0.6877\n",
            "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6215 - sparse_categorical_accuracy: 0.6794 - val_loss: 0.6539 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 2.5000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6013 - sparse_categorical_accuracy: 0.6725 - val_loss: 0.6541 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 1.2500e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6194 - sparse_categorical_accuracy: 0.7057 - val_loss: 0.6537 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 1.2500e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6105 - sparse_categorical_accuracy: 0.6644 - val_loss: 0.6534 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 1.2500e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6024 - sparse_categorical_accuracy: 0.6663 - val_loss: 0.6531 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 1.2500e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6190 - sparse_categorical_accuracy: 0.6614\n",
            "Epoch 56: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6204 - sparse_categorical_accuracy: 0.6598 - val_loss: 0.6528 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 1.2500e-04\n",
            "Epoch 56: early stopping\n",
            "Restoring model weights from the end of the best epoch: 41.\n",
            "  Test Accuracy: 38.89%\n",
            "  Test Precision (weighted): 15.12%\n",
            "  Test Recall (weighted): 38.89%\n",
            "  Test F1-Score (weighted): 21.78%\n",
            "\n",
            "--- Fold 3/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.7184 - sparse_categorical_accuracy: 0.5088"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.7199 - sparse_categorical_accuracy: 0.5133 - val_loss: 0.6774 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6980 - sparse_categorical_accuracy: 0.5576 - val_loss: 0.6863 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.7033 - sparse_categorical_accuracy: 0.5662 - val_loss: 0.6853 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6771 - sparse_categorical_accuracy: 0.5328 - val_loss: 0.6801 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6669 - sparse_categorical_accuracy: 0.5634"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6712 - sparse_categorical_accuracy: 0.5657 - val_loss: 0.6765 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6732 - sparse_categorical_accuracy: 0.6063"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.6736 - sparse_categorical_accuracy: 0.6045 - val_loss: 0.6753 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6471 - sparse_categorical_accuracy: 0.6406"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6503 - sparse_categorical_accuracy: 0.6325 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6833 - sparse_categorical_accuracy: 0.5744 - val_loss: 0.6745 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6829 - sparse_categorical_accuracy: 0.5574 - val_loss: 0.6796 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6767 - sparse_categorical_accuracy: 0.5931 - val_loss: 0.6821 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6472 - sparse_categorical_accuracy: 0.5859 - val_loss: 0.6802 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6780 - sparse_categorical_accuracy: 0.5743\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6768 - sparse_categorical_accuracy: 0.5743 - val_loss: 0.6800 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6578 - sparse_categorical_accuracy: 0.6265 - val_loss: 0.6786 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6794 - sparse_categorical_accuracy: 0.5910 - val_loss: 0.6791 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6668 - sparse_categorical_accuracy: 0.5900 - val_loss: 0.6814 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6537 - sparse_categorical_accuracy: 0.6329 - val_loss: 0.6814 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6701 - sparse_categorical_accuracy: 0.5965\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6704 - sparse_categorical_accuracy: 0.5947 - val_loss: 0.6812 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6626 - sparse_categorical_accuracy: 0.6092 - val_loss: 0.6807 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6601 - sparse_categorical_accuracy: 0.5841 - val_loss: 0.6798 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6421 - sparse_categorical_accuracy: 0.6262 - val_loss: 0.6793 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6596 - sparse_categorical_accuracy: 0.6263 - val_loss: 0.6798 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6585 - sparse_categorical_accuracy: 0.5859\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6586 - sparse_categorical_accuracy: 0.5856 - val_loss: 0.6799 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 22: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "  Test Accuracy: 77.78%\n",
            "  Test Precision (weighted): 60.49%\n",
            "  Test Recall (weighted): 77.78%\n",
            "  Test F1-Score (weighted): 68.06%\n",
            "\n",
            "--- Fold 4/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7407 - sparse_categorical_accuracy: 0.5029"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - loss: 0.7394 - sparse_categorical_accuracy: 0.5102 - val_loss: 0.6773 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6851 - sparse_categorical_accuracy: 0.5813 - val_loss: 0.6788 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6902 - sparse_categorical_accuracy: 0.5246 - val_loss: 0.6782 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6779 - sparse_categorical_accuracy: 0.6189"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.6801 - sparse_categorical_accuracy: 0.6254 - val_loss: 0.6743 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.6881 - sparse_categorical_accuracy: 0.6045 - val_loss: 0.6755 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6581 - sparse_categorical_accuracy: 0.5903"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.6604 - sparse_categorical_accuracy: 0.5867 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.7014 - sparse_categorical_accuracy: 0.5913"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.6965 - sparse_categorical_accuracy: 0.5904 - val_loss: 0.6683 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6628 - sparse_categorical_accuracy: 0.6305"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6616 - sparse_categorical_accuracy: 0.6218 - val_loss: 0.6658 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6630 - sparse_categorical_accuracy: 0.6348"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6643 - sparse_categorical_accuracy: 0.6295 - val_loss: 0.6644 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6734 - sparse_categorical_accuracy: 0.5986 - val_loss: 0.6692 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6696 - sparse_categorical_accuracy: 0.5953 - val_loss: 0.6693 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6641 - sparse_categorical_accuracy: 0.6140 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6624 - sparse_categorical_accuracy: 0.6200 - val_loss: 0.6710 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6654 - sparse_categorical_accuracy: 0.6152\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6635 - sparse_categorical_accuracy: 0.6149 - val_loss: 0.6712 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6659 - sparse_categorical_accuracy: 0.6220 - val_loss: 0.6726 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6704 - sparse_categorical_accuracy: 0.6293 - val_loss: 0.6727 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6584 - sparse_categorical_accuracy: 0.6091 - val_loss: 0.6711 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6554 - sparse_categorical_accuracy: 0.6283 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6674 - sparse_categorical_accuracy: 0.6255\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6671 - sparse_categorical_accuracy: 0.6236 - val_loss: 0.6711 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6699 - sparse_categorical_accuracy: 0.6108 - val_loss: 0.6712 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6326 - sparse_categorical_accuracy: 0.6491 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6428 - sparse_categorical_accuracy: 0.6242 - val_loss: 0.6703 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6606 - sparse_categorical_accuracy: 0.6072 - val_loss: 0.6706 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6330 - sparse_categorical_accuracy: 0.6475\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6380 - sparse_categorical_accuracy: 0.6463 - val_loss: 0.6708 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 24: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "  Test Accuracy: 55.56%\n",
            "  Test Precision (weighted): 30.86%\n",
            "  Test Recall (weighted): 55.56%\n",
            "  Test F1-Score (weighted): 39.68%\n",
            "\n",
            "--- Fold 5/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.7169 - sparse_categorical_accuracy: 0.5511"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - loss: 0.7207 - sparse_categorical_accuracy: 0.5506 - val_loss: 0.6788 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6566 - sparse_categorical_accuracy: 0.6339"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6627 - sparse_categorical_accuracy: 0.6198 - val_loss: 0.6784 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7305 - sparse_categorical_accuracy: 0.5618"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.7297 - sparse_categorical_accuracy: 0.5599 - val_loss: 0.6772 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6732 - sparse_categorical_accuracy: 0.6204"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6749 - sparse_categorical_accuracy: 0.6180 - val_loss: 0.6768 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6630 - sparse_categorical_accuracy: 0.5829"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6657 - sparse_categorical_accuracy: 0.5821 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.6545 - sparse_categorical_accuracy: 0.6368 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.6842 - sparse_categorical_accuracy: 0.5901 - val_loss: 0.6740 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6739 - sparse_categorical_accuracy: 0.6457"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6731 - sparse_categorical_accuracy: 0.6412 - val_loss: 0.6720 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6713 - sparse_categorical_accuracy: 0.6049 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6755 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6752 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.6823 - sparse_categorical_accuracy: 0.5961 - val_loss: 0.6750 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6747 - sparse_categorical_accuracy: 0.5812 - val_loss: 0.6726 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6523 - sparse_categorical_accuracy: 0.6007\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6572 - sparse_categorical_accuracy: 0.5969 - val_loss: 0.6722 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6465 - sparse_categorical_accuracy: 0.6056 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6701 - sparse_categorical_accuracy: 0.6150 - val_loss: 0.6742 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6723 - sparse_categorical_accuracy: 0.6015 - val_loss: 0.6743 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6538 - sparse_categorical_accuracy: 0.6052 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6585 - sparse_categorical_accuracy: 0.6279"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6617 - sparse_categorical_accuracy: 0.6193 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6476 - sparse_categorical_accuracy: 0.6139 - val_loss: 0.6724 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6541 - sparse_categorical_accuracy: 0.6180 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6460 - sparse_categorical_accuracy: 0.6054 - val_loss: 0.6713 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6476 - sparse_categorical_accuracy: 0.6360"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6467 - sparse_categorical_accuracy: 0.6372 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6370 - sparse_categorical_accuracy: 0.6369"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6353 - sparse_categorical_accuracy: 0.6388 - val_loss: 0.6686 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6332 - sparse_categorical_accuracy: 0.6391"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6383 - sparse_categorical_accuracy: 0.6309 - val_loss: 0.6678 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6407 - sparse_categorical_accuracy: 0.6817"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6439 - sparse_categorical_accuracy: 0.6690 - val_loss: 0.6660 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6378 - sparse_categorical_accuracy: 0.6171 - val_loss: 0.6667 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6338 - sparse_categorical_accuracy: 0.6350 - val_loss: 0.6688 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6539 - sparse_categorical_accuracy: 0.6350 - val_loss: 0.6691 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6328 - sparse_categorical_accuracy: 0.6558 - val_loss: 0.6679 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6455 - sparse_categorical_accuracy: 0.5995"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6493 - sparse_categorical_accuracy: 0.5940 - val_loss: 0.6657 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6712 - sparse_categorical_accuracy: 0.5855 - val_loss: 0.6660 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6202 - sparse_categorical_accuracy: 0.6807"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6292 - sparse_categorical_accuracy: 0.6643 - val_loss: 0.6630 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6270 - sparse_categorical_accuracy: 0.6734"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6304 - sparse_categorical_accuracy: 0.6661 - val_loss: 0.6620 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6275 - sparse_categorical_accuracy: 0.6640"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6311 - sparse_categorical_accuracy: 0.6565 - val_loss: 0.6615 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6210 - sparse_categorical_accuracy: 0.6588"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6286 - sparse_categorical_accuracy: 0.6519 - val_loss: 0.6608 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6219 - sparse_categorical_accuracy: 0.6890 - val_loss: 0.6617 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6041 - sparse_categorical_accuracy: 0.6877 - val_loss: 0.6614 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6402 - sparse_categorical_accuracy: 0.6414"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6417 - sparse_categorical_accuracy: 0.6367 - val_loss: 0.6561 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m 7/11\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6292 - sparse_categorical_accuracy: 0.6724"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6315 - sparse_categorical_accuracy: 0.6526 - val_loss: 0.6534 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6023 - sparse_categorical_accuracy: 0.6612 - val_loss: 0.6550 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6286 - sparse_categorical_accuracy: 0.6579 - val_loss: 0.6549 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6161 - sparse_categorical_accuracy: 0.6842"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6188 - sparse_categorical_accuracy: 0.6773 - val_loss: 0.6523 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 5.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6162 - sparse_categorical_accuracy: 0.6788"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6163 - sparse_categorical_accuracy: 0.6736 - val_loss: 0.6503 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 5.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6072 - sparse_categorical_accuracy: 0.6523"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6076 - sparse_categorical_accuracy: 0.6528 - val_loss: 0.6480 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 5.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6058 - sparse_categorical_accuracy: 0.6620"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6077 - sparse_categorical_accuracy: 0.6652 - val_loss: 0.6457 - val_sparse_categorical_accuracy: 0.6667 - learning_rate: 5.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5998 - sparse_categorical_accuracy: 0.6747 - val_loss: 0.6463 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6155 - sparse_categorical_accuracy: 0.6378 - val_loss: 0.6465 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 5.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5909 - sparse_categorical_accuracy: 0.7305"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5935 - sparse_categorical_accuracy: 0.7243 - val_loss: 0.6439 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 5.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6247 - sparse_categorical_accuracy: 0.6358"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6242 - sparse_categorical_accuracy: 0.6364 - val_loss: 0.6431 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 5.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6189 - sparse_categorical_accuracy: 0.6917 - val_loss: 0.6456 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 5.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6337 - sparse_categorical_accuracy: 0.6367"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.6306 - sparse_categorical_accuracy: 0.6392 - val_loss: 0.6428 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5950 - sparse_categorical_accuracy: 0.6881 - val_loss: 0.6448 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 5.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5763 - sparse_categorical_accuracy: 0.7103"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5775 - sparse_categorical_accuracy: 0.7097 - val_loss: 0.6418 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 5.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5978 - sparse_categorical_accuracy: 0.6691"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6062 - sparse_categorical_accuracy: 0.6654 - val_loss: 0.6373 - val_sparse_categorical_accuracy: 0.6667 - learning_rate: 5.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6049 - sparse_categorical_accuracy: 0.7035 - val_loss: 0.6386 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 5.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6028 - sparse_categorical_accuracy: 0.6642 - val_loss: 0.6411 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6039 - sparse_categorical_accuracy: 0.6888 - val_loss: 0.6475 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 5.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5878 - sparse_categorical_accuracy: 0.7258 - val_loss: 0.6519 - val_sparse_categorical_accuracy: 0.6000 - learning_rate: 5.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6221 - sparse_categorical_accuracy: 0.6592\n",
            "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6224 - sparse_categorical_accuracy: 0.6570 - val_loss: 0.6489 - val_sparse_categorical_accuracy: 0.6667 - learning_rate: 5.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5666 - sparse_categorical_accuracy: 0.7251 - val_loss: 0.6515 - val_sparse_categorical_accuracy: 0.6667 - learning_rate: 2.5000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5613 - sparse_categorical_accuracy: 0.7198 - val_loss: 0.6548 - val_sparse_categorical_accuracy: 0.6667 - learning_rate: 2.5000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5880 - sparse_categorical_accuracy: 0.6893 - val_loss: 0.6567 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 2.5000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5766 - sparse_categorical_accuracy: 0.7303 - val_loss: 0.6610 - val_sparse_categorical_accuracy: 0.6667 - learning_rate: 2.5000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5700 - sparse_categorical_accuracy: 0.7189\n",
            "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5724 - sparse_categorical_accuracy: 0.7139 - val_loss: 0.6634 - val_sparse_categorical_accuracy: 0.6667 - learning_rate: 2.5000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5671 - sparse_categorical_accuracy: 0.7069 - val_loss: 0.6649 - val_sparse_categorical_accuracy: 0.6667 - learning_rate: 1.2500e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5777 - sparse_categorical_accuracy: 0.7320 - val_loss: 0.6599 - val_sparse_categorical_accuracy: 0.6667 - learning_rate: 1.2500e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5899 - sparse_categorical_accuracy: 0.6880 - val_loss: 0.6605 - val_sparse_categorical_accuracy: 0.6667 - learning_rate: 1.2500e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5683 - sparse_categorical_accuracy: 0.7088 - val_loss: 0.6637 - val_sparse_categorical_accuracy: 0.6667 - learning_rate: 1.2500e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5464 - sparse_categorical_accuracy: 0.7314\n",
            "Epoch 69: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5522 - sparse_categorical_accuracy: 0.7155 - val_loss: 0.6618 - val_sparse_categorical_accuracy: 0.6667 - learning_rate: 1.2500e-04\n",
            "Epoch 69: early stopping\n",
            "Restoring model weights from the end of the best epoch: 54.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c9c26a47060> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Test Accuracy: 55.56%\n",
            "  Test Precision (weighted): 35.95%\n",
            "  Test Recall (weighted): 55.56%\n",
            "  Test F1-Score (weighted): 43.65%\n",
            "\n",
            "--- Fold 6/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.7873 - sparse_categorical_accuracy: 0.5027"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 0.7825 - sparse_categorical_accuracy: 0.5057 - val_loss: 0.6776 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6962 - sparse_categorical_accuracy: 0.5917"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6958 - sparse_categorical_accuracy: 0.5803 - val_loss: 0.6775 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.7134 - sparse_categorical_accuracy: 0.5007 - val_loss: 0.6793 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.7009 - sparse_categorical_accuracy: 0.5069 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6681 - sparse_categorical_accuracy: 0.5655"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.6692 - sparse_categorical_accuracy: 0.5689 - val_loss: 0.6752 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6723 - sparse_categorical_accuracy: 0.5663"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.6728 - sparse_categorical_accuracy: 0.5652 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.6824 - sparse_categorical_accuracy: 0.5949 - val_loss: 0.6740 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6833 - sparse_categorical_accuracy: 0.5686"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.6831 - sparse_categorical_accuracy: 0.5683 - val_loss: 0.6716 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6846 - sparse_categorical_accuracy: 0.5713 - val_loss: 0.6725 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6675 - sparse_categorical_accuracy: 0.6196 - val_loss: 0.6748 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6732 - sparse_categorical_accuracy: 0.6085 - val_loss: 0.6742 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6604 - sparse_categorical_accuracy: 0.6305 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6728 - sparse_categorical_accuracy: 0.5957\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6675 - sparse_categorical_accuracy: 0.5951 - val_loss: 0.6733 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6618 - sparse_categorical_accuracy: 0.5903 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6548 - sparse_categorical_accuracy: 0.6210 - val_loss: 0.6725 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6709 - sparse_categorical_accuracy: 0.5966 - val_loss: 0.6724 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6658 - sparse_categorical_accuracy: 0.6162 - val_loss: 0.6729 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6657 - sparse_categorical_accuracy: 0.6453\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6661 - sparse_categorical_accuracy: 0.6436 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6445 - sparse_categorical_accuracy: 0.6407 - val_loss: 0.6742 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6822 - sparse_categorical_accuracy: 0.5713 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6345 - sparse_categorical_accuracy: 0.6468 - val_loss: 0.6728 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6525 - sparse_categorical_accuracy: 0.6314 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6420 - sparse_categorical_accuracy: 0.6399"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6433 - sparse_categorical_accuracy: 0.6389 - val_loss: 0.6716 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6663 - sparse_categorical_accuracy: 0.6279"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6640 - sparse_categorical_accuracy: 0.6244 - val_loss: 0.6714 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6547 - sparse_categorical_accuracy: 0.6274"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6546 - sparse_categorical_accuracy: 0.6265 - val_loss: 0.6712 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6315 - sparse_categorical_accuracy: 0.6452"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6323 - sparse_categorical_accuracy: 0.6438 - val_loss: 0.6707 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6628 - sparse_categorical_accuracy: 0.6066"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6608 - sparse_categorical_accuracy: 0.6084 - val_loss: 0.6695 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6731 - sparse_categorical_accuracy: 0.6127"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6722 - sparse_categorical_accuracy: 0.6085 - val_loss: 0.6691 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6561 - sparse_categorical_accuracy: 0.6094"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6531 - sparse_categorical_accuracy: 0.6120 - val_loss: 0.6690 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6596 - sparse_categorical_accuracy: 0.6378"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6560 - sparse_categorical_accuracy: 0.6412 - val_loss: 0.6689 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6367 - sparse_categorical_accuracy: 0.6168"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6367 - sparse_categorical_accuracy: 0.6160 - val_loss: 0.6681 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6613 - sparse_categorical_accuracy: 0.6251"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6608 - sparse_categorical_accuracy: 0.6238 - val_loss: 0.6668 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6707 - sparse_categorical_accuracy: 0.6049"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6674 - sparse_categorical_accuracy: 0.6089 - val_loss: 0.6660 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6497 - sparse_categorical_accuracy: 0.6146"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6485 - sparse_categorical_accuracy: 0.6164 - val_loss: 0.6653 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6587 - sparse_categorical_accuracy: 0.6204"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6582 - sparse_categorical_accuracy: 0.6169 - val_loss: 0.6651 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6569 - sparse_categorical_accuracy: 0.6212"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.6546 - sparse_categorical_accuracy: 0.6204 - val_loss: 0.6650 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6448 - sparse_categorical_accuracy: 0.6370"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6476 - sparse_categorical_accuracy: 0.6365 - val_loss: 0.6650 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6439 - sparse_categorical_accuracy: 0.5995"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6470 - sparse_categorical_accuracy: 0.5971 - val_loss: 0.6648 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6359 - sparse_categorical_accuracy: 0.6688"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6367 - sparse_categorical_accuracy: 0.6627 - val_loss: 0.6645 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6468 - sparse_categorical_accuracy: 0.6135 - val_loss: 0.6645 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6625 - sparse_categorical_accuracy: 0.6070"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6589 - sparse_categorical_accuracy: 0.6115 - val_loss: 0.6640 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6592 - sparse_categorical_accuracy: 0.6373"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.6590 - sparse_categorical_accuracy: 0.6337 - val_loss: 0.6635 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6374 - sparse_categorical_accuracy: 0.6387"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.6374 - sparse_categorical_accuracy: 0.6371 - val_loss: 0.6635 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.6571 - sparse_categorical_accuracy: 0.6127 - val_loss: 0.6635 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6436 - sparse_categorical_accuracy: 0.6535"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.6426 - sparse_categorical_accuracy: 0.6527 - val_loss: 0.6633 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6418 - sparse_categorical_accuracy: 0.6097"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.6420 - sparse_categorical_accuracy: 0.6098 - val_loss: 0.6628 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6235 - sparse_categorical_accuracy: 0.6515 - val_loss: 0.6628 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6598 - sparse_categorical_accuracy: 0.6261 - val_loss: 0.6632 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6256 - sparse_categorical_accuracy: 0.6292 - val_loss: 0.6631 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6457 - sparse_categorical_accuracy: 0.6396 - val_loss: 0.6633 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6549 - sparse_categorical_accuracy: 0.6228\n",
            "Epoch 51: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6540 - sparse_categorical_accuracy: 0.6232 - val_loss: 0.6641 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6515 - sparse_categorical_accuracy: 0.6726 - val_loss: 0.6640 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6396 - sparse_categorical_accuracy: 0.6255 - val_loss: 0.6638 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6311 - sparse_categorical_accuracy: 0.6625 - val_loss: 0.6642 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6335 - sparse_categorical_accuracy: 0.6288 - val_loss: 0.6647 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6341 - sparse_categorical_accuracy: 0.6420\n",
            "Epoch 56: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6375 - sparse_categorical_accuracy: 0.6367 - val_loss: 0.6650 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6333 - sparse_categorical_accuracy: 0.6517 - val_loss: 0.6652 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6293 - sparse_categorical_accuracy: 0.6300 - val_loss: 0.6655 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6404 - sparse_categorical_accuracy: 0.6212 - val_loss: 0.6656 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6516 - sparse_categorical_accuracy: 0.6374 - val_loss: 0.6655 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6474 - sparse_categorical_accuracy: 0.6454\n",
            "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6466 - sparse_categorical_accuracy: 0.6452 - val_loss: 0.6657 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 61: early stopping\n",
            "Restoring model weights from the end of the best epoch: 46.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c9c258dd120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Test Accuracy: 66.67%\n",
            "  Test Precision (weighted): 44.44%\n",
            "  Test Recall (weighted): 66.67%\n",
            "  Test F1-Score (weighted): 53.33%\n",
            "\n",
            "--- Fold 7/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8477 - sparse_categorical_accuracy: 0.4035"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.8360 - sparse_categorical_accuracy: 0.4107 - val_loss: 0.6825 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7000 - sparse_categorical_accuracy: 0.5484"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.7002 - sparse_categorical_accuracy: 0.5507 - val_loss: 0.6770 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6675 - sparse_categorical_accuracy: 0.6197"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.6717 - sparse_categorical_accuracy: 0.6097 - val_loss: 0.6759 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6359 - sparse_categorical_accuracy: 0.6528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6413 - sparse_categorical_accuracy: 0.6461 - val_loss: 0.6745 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6738 - sparse_categorical_accuracy: 0.5969"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6751 - sparse_categorical_accuracy: 0.5994 - val_loss: 0.6720 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6436 - sparse_categorical_accuracy: 0.6376"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6474 - sparse_categorical_accuracy: 0.6335 - val_loss: 0.6684 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6635 - sparse_categorical_accuracy: 0.6196 - val_loss: 0.6684 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6547 - sparse_categorical_accuracy: 0.6092"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.6549 - sparse_categorical_accuracy: 0.6078 - val_loss: 0.6667 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6559 - sparse_categorical_accuracy: 0.6032"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.6591 - sparse_categorical_accuracy: 0.6009 - val_loss: 0.6658 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6639 - sparse_categorical_accuracy: 0.6277 - val_loss: 0.6681 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6522 - sparse_categorical_accuracy: 0.6095 - val_loss: 0.6665 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6689 - sparse_categorical_accuracy: 0.6486 - val_loss: 0.6668 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6741 - sparse_categorical_accuracy: 0.5873 - val_loss: 0.6661 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6536 - sparse_categorical_accuracy: 0.6414"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6536 - sparse_categorical_accuracy: 0.6398 - val_loss: 0.6620 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6610 - sparse_categorical_accuracy: 0.6119"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6617 - sparse_categorical_accuracy: 0.6115 - val_loss: 0.6583 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6481 - sparse_categorical_accuracy: 0.6402 - val_loss: 0.6606 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6521 - sparse_categorical_accuracy: 0.6356 - val_loss: 0.6637 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6443 - sparse_categorical_accuracy: 0.6620 - val_loss: 0.6661 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6626 - sparse_categorical_accuracy: 0.6255 - val_loss: 0.6637 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6598 - sparse_categorical_accuracy: 0.6360\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6606 - sparse_categorical_accuracy: 0.6349 - val_loss: 0.6645 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6316 - sparse_categorical_accuracy: 0.6649 - val_loss: 0.6657 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6485 - sparse_categorical_accuracy: 0.6604 - val_loss: 0.6654 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6378 - sparse_categorical_accuracy: 0.6480 - val_loss: 0.6629 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6345 - sparse_categorical_accuracy: 0.6571 - val_loss: 0.6609 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6271 - sparse_categorical_accuracy: 0.6567\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6292 - sparse_categorical_accuracy: 0.6549 - val_loss: 0.6585 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6238 - sparse_categorical_accuracy: 0.6662"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6281 - sparse_categorical_accuracy: 0.6589 - val_loss: 0.6581 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6335 - sparse_categorical_accuracy: 0.6667"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6345 - sparse_categorical_accuracy: 0.6632 - val_loss: 0.6574 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6452 - sparse_categorical_accuracy: 0.6607 - val_loss: 0.6578 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6387 - sparse_categorical_accuracy: 0.6572 - val_loss: 0.6584 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6046 - sparse_categorical_accuracy: 0.6862 - val_loss: 0.6579 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6076 - sparse_categorical_accuracy: 0.7124"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6120 - sparse_categorical_accuracy: 0.7033 - val_loss: 0.6570 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6419 - sparse_categorical_accuracy: 0.6345"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6422 - sparse_categorical_accuracy: 0.6329 - val_loss: 0.6564 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6396 - sparse_categorical_accuracy: 0.6458"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6430 - sparse_categorical_accuracy: 0.6429 - val_loss: 0.6563 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6310 - sparse_categorical_accuracy: 0.6355 - val_loss: 0.6569 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6301 - sparse_categorical_accuracy: 0.6681 - val_loss: 0.6565 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6274 - sparse_categorical_accuracy: 0.6609"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6293 - sparse_categorical_accuracy: 0.6592 - val_loss: 0.6559 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6217 - sparse_categorical_accuracy: 0.6637 - val_loss: 0.6565 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6348 - sparse_categorical_accuracy: 0.6499 - val_loss: 0.6566 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6262 - sparse_categorical_accuracy: 0.6312 - val_loss: 0.6560 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6222 - sparse_categorical_accuracy: 0.6921"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6239 - sparse_categorical_accuracy: 0.6882 - val_loss: 0.6555 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6401 - sparse_categorical_accuracy: 0.6477"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6410 - sparse_categorical_accuracy: 0.6470 - val_loss: 0.6540 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6240 - sparse_categorical_accuracy: 0.6720"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6255 - sparse_categorical_accuracy: 0.6695 - val_loss: 0.6523 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6169 - sparse_categorical_accuracy: 0.6972"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6198 - sparse_categorical_accuracy: 0.6916 - val_loss: 0.6517 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6252 - sparse_categorical_accuracy: 0.7190"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6264 - sparse_categorical_accuracy: 0.7112 - val_loss: 0.6513 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6036 - sparse_categorical_accuracy: 0.6836"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6064 - sparse_categorical_accuracy: 0.6803 - val_loss: 0.6503 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6291 - sparse_categorical_accuracy: 0.6795"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6293 - sparse_categorical_accuracy: 0.6769 - val_loss: 0.6499 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6299 - sparse_categorical_accuracy: 0.6605"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6325 - sparse_categorical_accuracy: 0.6571 - val_loss: 0.6496 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6042 - sparse_categorical_accuracy: 0.7129"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6051 - sparse_categorical_accuracy: 0.7106 - val_loss: 0.6492 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6292 - sparse_categorical_accuracy: 0.6432"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6289 - sparse_categorical_accuracy: 0.6434 - val_loss: 0.6488 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6285 - sparse_categorical_accuracy: 0.6776 - val_loss: 0.6490 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6080 - sparse_categorical_accuracy: 0.7110 - val_loss: 0.6503 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6036 - sparse_categorical_accuracy: 0.7185 - val_loss: 0.6504 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6059 - sparse_categorical_accuracy: 0.6749 - val_loss: 0.6515 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6154 - sparse_categorical_accuracy: 0.6705\n",
            "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6152 - sparse_categorical_accuracy: 0.6674 - val_loss: 0.6522 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5943 - sparse_categorical_accuracy: 0.6884 - val_loss: 0.6521 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6087 - sparse_categorical_accuracy: 0.7064 - val_loss: 0.6521 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6186 - sparse_categorical_accuracy: 0.6552 - val_loss: 0.6520 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6104 - sparse_categorical_accuracy: 0.7070 - val_loss: 0.6518 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6121 - sparse_categorical_accuracy: 0.6683\n",
            "Epoch 59: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6141 - sparse_categorical_accuracy: 0.6646 - val_loss: 0.6515 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5977 - sparse_categorical_accuracy: 0.7167 - val_loss: 0.6512 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6167 - sparse_categorical_accuracy: 0.7153 - val_loss: 0.6511 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5971 - sparse_categorical_accuracy: 0.7178 - val_loss: 0.6516 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6100 - sparse_categorical_accuracy: 0.7147 - val_loss: 0.6517 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6182 - sparse_categorical_accuracy: 0.7231\n",
            "Epoch 64: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6193 - sparse_categorical_accuracy: 0.7204 - val_loss: 0.6519 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 64: early stopping\n",
            "Restoring model weights from the end of the best epoch: 49.\n",
            "  Test Accuracy: 38.89%\n",
            "  Test Precision (weighted): 18.30%\n",
            "  Test Recall (weighted): 38.89%\n",
            "  Test F1-Score (weighted): 24.89%\n",
            "\n",
            "--- Fold 8/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7194 - sparse_categorical_accuracy: 0.5515"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 0.7199 - sparse_categorical_accuracy: 0.5517 - val_loss: 0.6767 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6600 - sparse_categorical_accuracy: 0.5904 - val_loss: 0.6803 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6798 - sparse_categorical_accuracy: 0.5504 - val_loss: 0.6829 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6859 - sparse_categorical_accuracy: 0.5496 - val_loss: 0.6860 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6834 - sparse_categorical_accuracy: 0.5732 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6767 - sparse_categorical_accuracy: 0.6100\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6765 - sparse_categorical_accuracy: 0.6047 - val_loss: 0.6817 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6656 - sparse_categorical_accuracy: 0.6321 - val_loss: 0.6793 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6676 - sparse_categorical_accuracy: 0.5766 - val_loss: 0.6768 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6706 - sparse_categorical_accuracy: 0.5924"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6715 - sparse_categorical_accuracy: 0.5924 - val_loss: 0.6751 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6760 - sparse_categorical_accuracy: 0.5899"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6771 - sparse_categorical_accuracy: 0.5879 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6534 - sparse_categorical_accuracy: 0.6133 - val_loss: 0.6758 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6864 - sparse_categorical_accuracy: 0.5978 - val_loss: 0.6747 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6662 - sparse_categorical_accuracy: 0.6336"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6669 - sparse_categorical_accuracy: 0.6277 - val_loss: 0.6727 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6682 - sparse_categorical_accuracy: 0.6359 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6651 - sparse_categorical_accuracy: 0.6256 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6652 - sparse_categorical_accuracy: 0.6196"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6665 - sparse_categorical_accuracy: 0.6186 - val_loss: 0.6700 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6653 - sparse_categorical_accuracy: 0.5687"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6658 - sparse_categorical_accuracy: 0.5675 - val_loss: 0.6677 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6950 - sparse_categorical_accuracy: 0.5984 - val_loss: 0.6717 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6765 - sparse_categorical_accuracy: 0.5660 - val_loss: 0.6744 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6599 - sparse_categorical_accuracy: 0.6201 - val_loss: 0.6744 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6600 - sparse_categorical_accuracy: 0.6173 - val_loss: 0.6720 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6490 - sparse_categorical_accuracy: 0.6312\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6503 - sparse_categorical_accuracy: 0.6282 - val_loss: 0.6697 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6571 - sparse_categorical_accuracy: 0.6321 - val_loss: 0.6693 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6693 - sparse_categorical_accuracy: 0.6117 - val_loss: 0.6700 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.6657 - sparse_categorical_accuracy: 0.6130 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6426 - sparse_categorical_accuracy: 0.5833 - val_loss: 0.6697 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6476 - sparse_categorical_accuracy: 0.5986\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.6484 - sparse_categorical_accuracy: 0.5961 - val_loss: 0.6679 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6533 - sparse_categorical_accuracy: 0.5898"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.6562 - sparse_categorical_accuracy: 0.5878 - val_loss: 0.6669 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6373 - sparse_categorical_accuracy: 0.6317"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6436 - sparse_categorical_accuracy: 0.6260 - val_loss: 0.6663 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6481 - sparse_categorical_accuracy: 0.6502"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6518 - sparse_categorical_accuracy: 0.6411 - val_loss: 0.6659 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6479 - sparse_categorical_accuracy: 0.6049"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6482 - sparse_categorical_accuracy: 0.6031 - val_loss: 0.6653 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6525 - sparse_categorical_accuracy: 0.6165"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6534 - sparse_categorical_accuracy: 0.6143 - val_loss: 0.6645 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6640 - sparse_categorical_accuracy: 0.6095"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6647 - sparse_categorical_accuracy: 0.6076 - val_loss: 0.6642 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6549 - sparse_categorical_accuracy: 0.6124 - val_loss: 0.6644 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6672 - sparse_categorical_accuracy: 0.5985 - val_loss: 0.6645 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6469 - sparse_categorical_accuracy: 0.6171"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6485 - sparse_categorical_accuracy: 0.6110 - val_loss: 0.6631 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6496 - sparse_categorical_accuracy: 0.6449"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6502 - sparse_categorical_accuracy: 0.6415 - val_loss: 0.6623 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6685 - sparse_categorical_accuracy: 0.6351"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6683 - sparse_categorical_accuracy: 0.6319 - val_loss: 0.6620 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6549 - sparse_categorical_accuracy: 0.6397"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6558 - sparse_categorical_accuracy: 0.6378 - val_loss: 0.6619 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6439 - sparse_categorical_accuracy: 0.6771"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6446 - sparse_categorical_accuracy: 0.6745 - val_loss: 0.6619 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6514 - sparse_categorical_accuracy: 0.6365"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6523 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6611 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6703 - sparse_categorical_accuracy: 0.6250 - val_loss: 0.6613 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6500 - sparse_categorical_accuracy: 0.6595 - val_loss: 0.6617 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6432 - sparse_categorical_accuracy: 0.6196 - val_loss: 0.6615 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6624 - sparse_categorical_accuracy: 0.6320"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6629 - sparse_categorical_accuracy: 0.6297 - val_loss: 0.6606 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6461 - sparse_categorical_accuracy: 0.6268"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6477 - sparse_categorical_accuracy: 0.6221 - val_loss: 0.6601 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6603 - sparse_categorical_accuracy: 0.6522 - val_loss: 0.6604 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6553 - sparse_categorical_accuracy: 0.6196"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6566 - sparse_categorical_accuracy: 0.6170 - val_loss: 0.6587 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6490 - sparse_categorical_accuracy: 0.6449"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6491 - sparse_categorical_accuracy: 0.6435 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6579 - sparse_categorical_accuracy: 0.6730"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6581 - sparse_categorical_accuracy: 0.6655 - val_loss: 0.6548 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6570 - sparse_categorical_accuracy: 0.6231"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6584 - sparse_categorical_accuracy: 0.6195 - val_loss: 0.6544 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6731 - sparse_categorical_accuracy: 0.6537"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6702 - sparse_categorical_accuracy: 0.6428 - val_loss: 0.6542 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6400 - sparse_categorical_accuracy: 0.6276 - val_loss: 0.6545 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6273 - sparse_categorical_accuracy: 0.6765 - val_loss: 0.6549 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6496 - sparse_categorical_accuracy: 0.5906 - val_loss: 0.6551 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6553 - sparse_categorical_accuracy: 0.6239 - val_loss: 0.6545 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6508 - sparse_categorical_accuracy: 0.6539\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6509 - sparse_categorical_accuracy: 0.6520 - val_loss: 0.6549 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6563 - sparse_categorical_accuracy: 0.6084 - val_loss: 0.6548 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6400 - sparse_categorical_accuracy: 0.6325 - val_loss: 0.6545 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6278 - sparse_categorical_accuracy: 0.6377"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6287 - sparse_categorical_accuracy: 0.6374 - val_loss: 0.6540 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6491 - sparse_categorical_accuracy: 0.6483"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6505 - sparse_categorical_accuracy: 0.6424 - val_loss: 0.6539 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6633 - sparse_categorical_accuracy: 0.6425 - val_loss: 0.6539 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6487 - sparse_categorical_accuracy: 0.6379 - val_loss: 0.6539 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6646 - sparse_categorical_accuracy: 0.5971 - val_loss: 0.6542 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6343 - sparse_categorical_accuracy: 0.6537\n",
            "Epoch 65: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6363 - sparse_categorical_accuracy: 0.6499 - val_loss: 0.6541 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6314 - sparse_categorical_accuracy: 0.6636"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6344 - sparse_categorical_accuracy: 0.6575 - val_loss: 0.6537 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6489 - sparse_categorical_accuracy: 0.5949"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6492 - sparse_categorical_accuracy: 0.5957 - val_loss: 0.6533 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6525 - sparse_categorical_accuracy: 0.6300"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6533 - sparse_categorical_accuracy: 0.6288 - val_loss: 0.6529 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6574 - sparse_categorical_accuracy: 0.6167"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6575 - sparse_categorical_accuracy: 0.6161 - val_loss: 0.6527 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6412 - sparse_categorical_accuracy: 0.6163"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6398 - sparse_categorical_accuracy: 0.6182 - val_loss: 0.6525 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6553 - sparse_categorical_accuracy: 0.6301"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.6543 - sparse_categorical_accuracy: 0.6278 - val_loss: 0.6524 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6434 - sparse_categorical_accuracy: 0.6380"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.6448 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6522 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6573 - sparse_categorical_accuracy: 0.5872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.6583 - sparse_categorical_accuracy: 0.5870 - val_loss: 0.6519 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6532 - sparse_categorical_accuracy: 0.6292"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.6529 - sparse_categorical_accuracy: 0.6280 - val_loss: 0.6516 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6443 - sparse_categorical_accuracy: 0.6105"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6446 - sparse_categorical_accuracy: 0.6110 - val_loss: 0.6515 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6535 - sparse_categorical_accuracy: 0.6468"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.6526 - sparse_categorical_accuracy: 0.6470 - val_loss: 0.6514 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6537 - sparse_categorical_accuracy: 0.6091"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6536 - sparse_categorical_accuracy: 0.6089 - val_loss: 0.6513 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6339 - sparse_categorical_accuracy: 0.6462 - val_loss: 0.6514 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6538 - sparse_categorical_accuracy: 0.6107 - val_loss: 0.6515 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6408 - sparse_categorical_accuracy: 0.6252 - val_loss: 0.6514 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6230 - sparse_categorical_accuracy: 0.6615"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6252 - sparse_categorical_accuracy: 0.6609 - val_loss: 0.6510 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6364 - sparse_categorical_accuracy: 0.6431"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6379 - sparse_categorical_accuracy: 0.6381 - val_loss: 0.6509 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6332 - sparse_categorical_accuracy: 0.6336"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6343 - sparse_categorical_accuracy: 0.6321 - val_loss: 0.6507 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6405 - sparse_categorical_accuracy: 0.6541"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6415 - sparse_categorical_accuracy: 0.6507 - val_loss: 0.6506 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6486 - sparse_categorical_accuracy: 0.6128 - val_loss: 0.6507 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6671 - sparse_categorical_accuracy: 0.6434 - val_loss: 0.6509 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6383 - sparse_categorical_accuracy: 0.6747 - val_loss: 0.6509 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6280 - sparse_categorical_accuracy: 0.6657\n",
            "Epoch 88: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6310 - sparse_categorical_accuracy: 0.6579 - val_loss: 0.6508 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6424 - sparse_categorical_accuracy: 0.5944 - val_loss: 0.6508 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.5625e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6456 - sparse_categorical_accuracy: 0.6598 - val_loss: 0.6507 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.5625e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6305 - sparse_categorical_accuracy: 0.6382"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6334 - sparse_categorical_accuracy: 0.6342 - val_loss: 0.6506 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.5625e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6366 - sparse_categorical_accuracy: 0.6696"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6390 - sparse_categorical_accuracy: 0.6647 - val_loss: 0.6505 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.5625e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6322 - sparse_categorical_accuracy: 0.6481"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6323 - sparse_categorical_accuracy: 0.6472 - val_loss: 0.6505 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.5625e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6284 - sparse_categorical_accuracy: 0.6272"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6291 - sparse_categorical_accuracy: 0.6277 - val_loss: 0.6504 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.5625e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6554 - sparse_categorical_accuracy: 0.6209"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6546 - sparse_categorical_accuracy: 0.6196 - val_loss: 0.6504 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.5625e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6531 - sparse_categorical_accuracy: 0.6459 - val_loss: 0.6504 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.5625e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6428 - sparse_categorical_accuracy: 0.6099 - val_loss: 0.6505 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.5625e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6418 - sparse_categorical_accuracy: 0.6382 - val_loss: 0.6504 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.5625e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6198 - sparse_categorical_accuracy: 0.6948\n",
            "Epoch 99: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6211 - sparse_categorical_accuracy: 0.6910 - val_loss: 0.6505 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.5625e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6651 - sparse_categorical_accuracy: 0.5972 - val_loss: 0.6505 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 7.8125e-06\n",
            "Restoring model weights from the end of the best epoch: 95.\n",
            "  Test Accuracy: 77.78%\n",
            "  Test Precision (weighted): 60.49%\n",
            "  Test Recall (weighted): 77.78%\n",
            "  Test F1-Score (weighted): 68.06%\n",
            "\n",
            "--- Fold 9/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6894 - sparse_categorical_accuracy: 0.5916"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.6922 - sparse_categorical_accuracy: 0.5914 - val_loss: 0.6745 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7035 - sparse_categorical_accuracy: 0.5875 - val_loss: 0.6754 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6872 - sparse_categorical_accuracy: 0.5911 - val_loss: 0.6860 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6754 - sparse_categorical_accuracy: 0.6177 - val_loss: 0.6872 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6809 - sparse_categorical_accuracy: 0.5811 - val_loss: 0.6841 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6534 - sparse_categorical_accuracy: 0.6130\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6571 - sparse_categorical_accuracy: 0.6086 - val_loss: 0.6827 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6907 - sparse_categorical_accuracy: 0.5549 - val_loss: 0.6801 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6752 - sparse_categorical_accuracy: 0.6347 - val_loss: 0.6787 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6623 - sparse_categorical_accuracy: 0.6158 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6434 - sparse_categorical_accuracy: 0.6262 - val_loss: 0.6759 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6837 - sparse_categorical_accuracy: 0.5803\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6821 - sparse_categorical_accuracy: 0.5823 - val_loss: 0.6756 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6692 - sparse_categorical_accuracy: 0.5945 - val_loss: 0.6761 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6643 - sparse_categorical_accuracy: 0.6326 - val_loss: 0.6762 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6679 - sparse_categorical_accuracy: 0.6146 - val_loss: 0.6769 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6646 - sparse_categorical_accuracy: 0.6008 - val_loss: 0.6759 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6628 - sparse_categorical_accuracy: 0.5927\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6635 - sparse_categorical_accuracy: 0.5914 - val_loss: 0.6760 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "  Test Accuracy: 72.22%\n",
            "  Test Precision (weighted): 52.16%\n",
            "  Test Recall (weighted): 72.22%\n",
            "  Test F1-Score (weighted): 60.57%\n",
            "\n",
            "--- Fold 10/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7226 - sparse_categorical_accuracy: 0.5756"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.7284 - sparse_categorical_accuracy: 0.5688 - val_loss: 0.6794 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6877 - sparse_categorical_accuracy: 0.5704"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6882 - sparse_categorical_accuracy: 0.5702 - val_loss: 0.6787 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6958 - sparse_categorical_accuracy: 0.5782"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6954 - sparse_categorical_accuracy: 0.5764 - val_loss: 0.6774 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6928 - sparse_categorical_accuracy: 0.5278"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6939 - sparse_categorical_accuracy: 0.5275 - val_loss: 0.6754 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6961 - sparse_categorical_accuracy: 0.5509 - val_loss: 0.6768 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6529 - sparse_categorical_accuracy: 0.6134"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6538 - sparse_categorical_accuracy: 0.6112 - val_loss: 0.6748 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6658 - sparse_categorical_accuracy: 0.6327"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6671 - sparse_categorical_accuracy: 0.6258 - val_loss: 0.6715 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6673 - sparse_categorical_accuracy: 0.6148"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6675 - sparse_categorical_accuracy: 0.6128 - val_loss: 0.6703 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6555 - sparse_categorical_accuracy: 0.5995"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6618 - sparse_categorical_accuracy: 0.5877 - val_loss: 0.6688 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6560 - sparse_categorical_accuracy: 0.6341"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6575 - sparse_categorical_accuracy: 0.6309 - val_loss: 0.6677 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6712 - sparse_categorical_accuracy: 0.6317 - val_loss: 0.6689 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6557 - sparse_categorical_accuracy: 0.5998"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6562 - sparse_categorical_accuracy: 0.5984 - val_loss: 0.6675 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6513 - sparse_categorical_accuracy: 0.6244"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6546 - sparse_categorical_accuracy: 0.6182 - val_loss: 0.6670 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6386 - sparse_categorical_accuracy: 0.6380 - val_loss: 0.6706 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6528 - sparse_categorical_accuracy: 0.6232 - val_loss: 0.6743 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6497 - sparse_categorical_accuracy: 0.6344 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6517 - sparse_categorical_accuracy: 0.6094 - val_loss: 0.6711 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6520 - sparse_categorical_accuracy: 0.6066\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6533 - sparse_categorical_accuracy: 0.6047 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6501 - sparse_categorical_accuracy: 0.6156 - val_loss: 0.6727 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6272 - sparse_categorical_accuracy: 0.6792 - val_loss: 0.6714 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6636 - sparse_categorical_accuracy: 0.6255 - val_loss: 0.6702 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6405 - sparse_categorical_accuracy: 0.6316 - val_loss: 0.6699 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6383 - sparse_categorical_accuracy: 0.6822\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6434 - sparse_categorical_accuracy: 0.6635 - val_loss: 0.6720 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6347 - sparse_categorical_accuracy: 0.6636 - val_loss: 0.6733 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6473 - sparse_categorical_accuracy: 0.6623 - val_loss: 0.6757 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6259 - sparse_categorical_accuracy: 0.6549 - val_loss: 0.6757 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6371 - sparse_categorical_accuracy: 0.6604 - val_loss: 0.6749 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6196 - sparse_categorical_accuracy: 0.6637\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6241 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6745 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 2.5000e-04\n",
            "Epoch 28: early stopping\n",
            "Restoring model weights from the end of the best epoch: 13.\n",
            "  Test Accuracy: 77.78%\n",
            "  Test Precision (weighted): 60.49%\n",
            "  Test Recall (weighted): 77.78%\n",
            "  Test F1-Score (weighted): 68.06%\n",
            "\n",
            "--- Fold 11/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6841 - sparse_categorical_accuracy: 0.5892"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.6868 - sparse_categorical_accuracy: 0.5867 - val_loss: 0.6814 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6709 - sparse_categorical_accuracy: 0.5894 - val_loss: 0.6821 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6664 - sparse_categorical_accuracy: 0.6119"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6672 - sparse_categorical_accuracy: 0.6088 - val_loss: 0.6729 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6712 - sparse_categorical_accuracy: 0.5973 - val_loss: 0.6748 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6510 - sparse_categorical_accuracy: 0.6287 - val_loss: 0.6745 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6584 - sparse_categorical_accuracy: 0.6201 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6533 - sparse_categorical_accuracy: 0.6251 - val_loss: 0.6750 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6592 - sparse_categorical_accuracy: 0.6325\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6600 - sparse_categorical_accuracy: 0.6312 - val_loss: 0.6763 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6420 - sparse_categorical_accuracy: 0.6641 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6755 - sparse_categorical_accuracy: 0.6345 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6687 - sparse_categorical_accuracy: 0.6417 - val_loss: 0.6783 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6556 - sparse_categorical_accuracy: 0.5995 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6502 - sparse_categorical_accuracy: 0.6478\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6562 - sparse_categorical_accuracy: 0.6356 - val_loss: 0.6785 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6475 - sparse_categorical_accuracy: 0.6330 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6443 - sparse_categorical_accuracy: 0.6324 - val_loss: 0.6795 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6472 - sparse_categorical_accuracy: 0.5959 - val_loss: 0.6799 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6603 - sparse_categorical_accuracy: 0.6444 - val_loss: 0.6804 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6367 - sparse_categorical_accuracy: 0.6266\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6379 - sparse_categorical_accuracy: 0.6222 - val_loss: 0.6812 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "  Test Accuracy: 50.00%\n",
            "  Test Precision (weighted): 25.00%\n",
            "  Test Recall (weighted): 50.00%\n",
            "  Test F1-Score (weighted): 33.33%\n",
            "\n",
            "--- Fold 12/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.7228 - sparse_categorical_accuracy: 0.4860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 0.7236 - sparse_categorical_accuracy: 0.4961 - val_loss: 0.6788 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6861 - sparse_categorical_accuracy: 0.6056"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6883 - sparse_categorical_accuracy: 0.5966 - val_loss: 0.6771 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6678 - sparse_categorical_accuracy: 0.6051"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6725 - sparse_categorical_accuracy: 0.5974 - val_loss: 0.6742 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6930 - sparse_categorical_accuracy: 0.5292 - val_loss: 0.6774 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6698 - sparse_categorical_accuracy: 0.5784"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6709 - sparse_categorical_accuracy: 0.5787 - val_loss: 0.6740 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6674 - sparse_categorical_accuracy: 0.6032"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6691 - sparse_categorical_accuracy: 0.5958 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6817 - sparse_categorical_accuracy: 0.5978 - val_loss: 0.6772 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6515 - sparse_categorical_accuracy: 0.6269 - val_loss: 0.6790 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6728 - sparse_categorical_accuracy: 0.5909 - val_loss: 0.6821 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6667 - sparse_categorical_accuracy: 0.6422 - val_loss: 0.6795 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6528 - sparse_categorical_accuracy: 0.6607\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6567 - sparse_categorical_accuracy: 0.6460 - val_loss: 0.6774 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6738 - sparse_categorical_accuracy: 0.6070 - val_loss: 0.6801 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6661 - sparse_categorical_accuracy: 0.6005 - val_loss: 0.6815 - val_sparse_categorical_accuracy: 0.6000 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6439 - sparse_categorical_accuracy: 0.6025 - val_loss: 0.6837 - val_sparse_categorical_accuracy: 0.5833 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6807 - sparse_categorical_accuracy: 0.6333 - val_loss: 0.6882 - val_sparse_categorical_accuracy: 0.4500 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6538 - sparse_categorical_accuracy: 0.6363\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6537 - sparse_categorical_accuracy: 0.6304 - val_loss: 0.6912 - val_sparse_categorical_accuracy: 0.4500 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6360 - sparse_categorical_accuracy: 0.6652 - val_loss: 0.6913 - val_sparse_categorical_accuracy: 0.4333 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6602 - sparse_categorical_accuracy: 0.5969 - val_loss: 0.6891 - val_sparse_categorical_accuracy: 0.4500 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6401 - sparse_categorical_accuracy: 0.6194 - val_loss: 0.6863 - val_sparse_categorical_accuracy: 0.4667 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6449 - sparse_categorical_accuracy: 0.6401 - val_loss: 0.6850 - val_sparse_categorical_accuracy: 0.5167 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6414 - sparse_categorical_accuracy: 0.6608\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6482 - sparse_categorical_accuracy: 0.6528 - val_loss: 0.6848 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 2.5000e-04\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "  Test Accuracy: 72.22%\n",
            "  Test Precision (weighted): 52.16%\n",
            "  Test Recall (weighted): 72.22%\n",
            "  Test F1-Score (weighted): 60.57%\n",
            "\n",
            "--- Fold 13/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.7684 - sparse_categorical_accuracy: 0.4004"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - loss: 0.7622 - sparse_categorical_accuracy: 0.4110 - val_loss: 0.6836 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6724 - sparse_categorical_accuracy: 0.6232"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6749 - sparse_categorical_accuracy: 0.6161 - val_loss: 0.6745 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6787 - sparse_categorical_accuracy: 0.6177"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6792 - sparse_categorical_accuracy: 0.6154 - val_loss: 0.6708 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6654 - sparse_categorical_accuracy: 0.6165"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6662 - sparse_categorical_accuracy: 0.6142 - val_loss: 0.6699 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6739 - sparse_categorical_accuracy: 0.6268 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6715 - sparse_categorical_accuracy: 0.6400 - val_loss: 0.6756 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6745 - sparse_categorical_accuracy: 0.6090 - val_loss: 0.6745 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6752 - sparse_categorical_accuracy: 0.5997 - val_loss: 0.6742 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6599 - sparse_categorical_accuracy: 0.6343\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6625 - sparse_categorical_accuracy: 0.6257 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6531 - sparse_categorical_accuracy: 0.6417 - val_loss: 0.6743 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.6483 - sparse_categorical_accuracy: 0.6422 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6717 - sparse_categorical_accuracy: 0.6197 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m 6/11\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6341 - sparse_categorical_accuracy: 0.6622"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6492 - sparse_categorical_accuracy: 0.6327 - val_loss: 0.6678 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6340 - sparse_categorical_accuracy: 0.6413 - val_loss: 0.6679 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6707 - sparse_categorical_accuracy: 0.6147 - val_loss: 0.6696 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6676 - sparse_categorical_accuracy: 0.6104 - val_loss: 0.6690 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6534 - sparse_categorical_accuracy: 0.6460 - val_loss: 0.6689 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6663 - sparse_categorical_accuracy: 0.6226\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6660 - sparse_categorical_accuracy: 0.6184 - val_loss: 0.6691 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6658 - sparse_categorical_accuracy: 0.5997 - val_loss: 0.6701 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6502 - sparse_categorical_accuracy: 0.6467 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6505 - sparse_categorical_accuracy: 0.6172 - val_loss: 0.6703 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6649 - sparse_categorical_accuracy: 0.6349 - val_loss: 0.6693 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6548 - sparse_categorical_accuracy: 0.6260\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6554 - sparse_categorical_accuracy: 0.6230 - val_loss: 0.6689 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6419 - sparse_categorical_accuracy: 0.6300"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6483 - sparse_categorical_accuracy: 0.6217 - val_loss: 0.6678 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6512 - sparse_categorical_accuracy: 0.6072"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6538 - sparse_categorical_accuracy: 0.6043 - val_loss: 0.6673 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6508 - sparse_categorical_accuracy: 0.6459"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6516 - sparse_categorical_accuracy: 0.6379 - val_loss: 0.6667 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6603 - sparse_categorical_accuracy: 0.6112"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6634 - sparse_categorical_accuracy: 0.6076 - val_loss: 0.6662 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6487 - sparse_categorical_accuracy: 0.6183"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6532 - sparse_categorical_accuracy: 0.6114 - val_loss: 0.6657 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6462 - sparse_categorical_accuracy: 0.6338"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6452 - sparse_categorical_accuracy: 0.6329 - val_loss: 0.6649 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6401 - sparse_categorical_accuracy: 0.6222"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6451 - sparse_categorical_accuracy: 0.6201 - val_loss: 0.6641 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6417 - sparse_categorical_accuracy: 0.6471"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.6449 - sparse_categorical_accuracy: 0.6393 - val_loss: 0.6627 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6412 - sparse_categorical_accuracy: 0.6513"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6418 - sparse_categorical_accuracy: 0.6444 - val_loss: 0.6615 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6590 - sparse_categorical_accuracy: 0.6247"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6585 - sparse_categorical_accuracy: 0.6232 - val_loss: 0.6609 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6544 - sparse_categorical_accuracy: 0.6448"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6545 - sparse_categorical_accuracy: 0.6415 - val_loss: 0.6597 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6560 - sparse_categorical_accuracy: 0.6370"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6590 - sparse_categorical_accuracy: 0.6234 - val_loss: 0.6581 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6472 - sparse_categorical_accuracy: 0.6192"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.6468 - sparse_categorical_accuracy: 0.6189 - val_loss: 0.6569 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6405 - sparse_categorical_accuracy: 0.6378"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.6419 - sparse_categorical_accuracy: 0.6327 - val_loss: 0.6553 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6393 - sparse_categorical_accuracy: 0.6210"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.6406 - sparse_categorical_accuracy: 0.6205 - val_loss: 0.6535 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6269 - sparse_categorical_accuracy: 0.6433"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6301 - sparse_categorical_accuracy: 0.6410 - val_loss: 0.6517 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6482 - sparse_categorical_accuracy: 0.6448"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6510 - sparse_categorical_accuracy: 0.6358 - val_loss: 0.6508 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6400 - sparse_categorical_accuracy: 0.6634"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.6418 - sparse_categorical_accuracy: 0.6561 - val_loss: 0.6504 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6327 - sparse_categorical_accuracy: 0.6380"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6353 - sparse_categorical_accuracy: 0.6312 - val_loss: 0.6494 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6397 - sparse_categorical_accuracy: 0.6718"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6418 - sparse_categorical_accuracy: 0.6629 - val_loss: 0.6488 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6596 - sparse_categorical_accuracy: 0.6286"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6561 - sparse_categorical_accuracy: 0.6270 - val_loss: 0.6485 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6663 - sparse_categorical_accuracy: 0.6468"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6643 - sparse_categorical_accuracy: 0.6386 - val_loss: 0.6483 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6612 - sparse_categorical_accuracy: 0.6353"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6585 - sparse_categorical_accuracy: 0.6340 - val_loss: 0.6479 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6673 - sparse_categorical_accuracy: 0.6552"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.6659 - sparse_categorical_accuracy: 0.6530 - val_loss: 0.6475 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6341 - sparse_categorical_accuracy: 0.6402"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6341 - sparse_categorical_accuracy: 0.6436 - val_loss: 0.6465 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6629 - sparse_categorical_accuracy: 0.6299"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6612 - sparse_categorical_accuracy: 0.6281 - val_loss: 0.6460 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6429 - sparse_categorical_accuracy: 0.6143"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6443 - sparse_categorical_accuracy: 0.6132 - val_loss: 0.6456 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6653 - sparse_categorical_accuracy: 0.6347"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6637 - sparse_categorical_accuracy: 0.6327 - val_loss: 0.6450 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6167 - sparse_categorical_accuracy: 0.6496"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6207 - sparse_categorical_accuracy: 0.6442 - val_loss: 0.6446 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6362 - sparse_categorical_accuracy: 0.6148 - val_loss: 0.6448 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6143 - sparse_categorical_accuracy: 0.6752 - val_loss: 0.6450 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6478 - sparse_categorical_accuracy: 0.6463 - val_loss: 0.6450 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6237 - sparse_categorical_accuracy: 0.6251 - val_loss: 0.6449 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6488 - sparse_categorical_accuracy: 0.6536\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6510 - sparse_categorical_accuracy: 0.6474 - val_loss: 0.6457 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6460 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6456 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6400 - sparse_categorical_accuracy: 0.6555 - val_loss: 0.6452 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6496 - sparse_categorical_accuracy: 0.6236 - val_loss: 0.6450 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6263 - sparse_categorical_accuracy: 0.6425"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6276 - sparse_categorical_accuracy: 0.6349 - val_loss: 0.6446 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6348 - sparse_categorical_accuracy: 0.6470"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.6346 - sparse_categorical_accuracy: 0.6475 - val_loss: 0.6442 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6439 - sparse_categorical_accuracy: 0.6289"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6440 - sparse_categorical_accuracy: 0.6290 - val_loss: 0.6439 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6479 - sparse_categorical_accuracy: 0.6568 - val_loss: 0.6439 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6295 - sparse_categorical_accuracy: 0.6584"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6324 - sparse_categorical_accuracy: 0.6518 - val_loss: 0.6437 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6244 - sparse_categorical_accuracy: 0.5954"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6285 - sparse_categorical_accuracy: 0.6001 - val_loss: 0.6435 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6114 - sparse_categorical_accuracy: 0.6609"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.6143 - sparse_categorical_accuracy: 0.6591 - val_loss: 0.6433 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6417 - sparse_categorical_accuracy: 0.6233"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.6420 - sparse_categorical_accuracy: 0.6236 - val_loss: 0.6429 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6343 - sparse_categorical_accuracy: 0.6375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.6342 - sparse_categorical_accuracy: 0.6339 - val_loss: 0.6426 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6410 - sparse_categorical_accuracy: 0.5972"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.6409 - sparse_categorical_accuracy: 0.6003 - val_loss: 0.6421 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6308 - sparse_categorical_accuracy: 0.6368"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.6314 - sparse_categorical_accuracy: 0.6354 - val_loss: 0.6417 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6311 - sparse_categorical_accuracy: 0.6200"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.6317 - sparse_categorical_accuracy: 0.6150 - val_loss: 0.6415 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6420 - sparse_categorical_accuracy: 0.6291"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6429 - sparse_categorical_accuracy: 0.6294 - val_loss: 0.6412 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6450 - sparse_categorical_accuracy: 0.6334"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6435 - sparse_categorical_accuracy: 0.6331 - val_loss: 0.6411 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6551 - sparse_categorical_accuracy: 0.6402"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6537 - sparse_categorical_accuracy: 0.6362 - val_loss: 0.6411 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6408 - sparse_categorical_accuracy: 0.6466 - val_loss: 0.6412 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6355 - sparse_categorical_accuracy: 0.6470"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6340 - sparse_categorical_accuracy: 0.6468 - val_loss: 0.6411 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6099 - sparse_categorical_accuracy: 0.6589 - val_loss: 0.6412 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6593 - sparse_categorical_accuracy: 0.6206\n",
            "Epoch 79: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6577 - sparse_categorical_accuracy: 0.6220 - val_loss: 0.6411 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6229 - sparse_categorical_accuracy: 0.6497 - val_loss: 0.6411 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6389 - sparse_categorical_accuracy: 0.6731 - val_loss: 0.6411 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6206 - sparse_categorical_accuracy: 0.6799"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6215 - sparse_categorical_accuracy: 0.6752 - val_loss: 0.6410 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6358 - sparse_categorical_accuracy: 0.6168 - val_loss: 0.6415 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6355 - sparse_categorical_accuracy: 0.6601\n",
            "Epoch 84: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6350 - sparse_categorical_accuracy: 0.6596 - val_loss: 0.6418 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.1250e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6184 - sparse_categorical_accuracy: 0.6354 - val_loss: 0.6418 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.5625e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6300 - sparse_categorical_accuracy: 0.6406 - val_loss: 0.6418 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.5625e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5778 - sparse_categorical_accuracy: 0.7037 - val_loss: 0.6418 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.5625e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6454 - sparse_categorical_accuracy: 0.6225 - val_loss: 0.6418 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.5625e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6445 - sparse_categorical_accuracy: 0.6247\n",
            "Epoch 89: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6414 - sparse_categorical_accuracy: 0.6253 - val_loss: 0.6419 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.5625e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6317 - sparse_categorical_accuracy: 0.6399 - val_loss: 0.6419 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 7.8125e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6250 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6418 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 7.8125e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6076 - sparse_categorical_accuracy: 0.6862 - val_loss: 0.6418 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 7.8125e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6293 - sparse_categorical_accuracy: 0.6568 - val_loss: 0.6418 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 7.8125e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5963 - sparse_categorical_accuracy: 0.6728\n",
            "Epoch 94: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5984 - sparse_categorical_accuracy: 0.6713 - val_loss: 0.6418 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 7.8125e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6215 - sparse_categorical_accuracy: 0.6548 - val_loss: 0.6418 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.9063e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6407 - sparse_categorical_accuracy: 0.6043 - val_loss: 0.6417 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.9063e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6369 - sparse_categorical_accuracy: 0.6460 - val_loss: 0.6417 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 3.9063e-06\n",
            "Epoch 97: early stopping\n",
            "Restoring model weights from the end of the best epoch: 82.\n",
            "  Test Accuracy: 55.56%\n",
            "  Test Precision (weighted): 60.46%\n",
            "  Test Recall (weighted): 55.56%\n",
            "  Test F1-Score (weighted): 57.41%\n",
            "\n",
            "--- Fold 14/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7201 - sparse_categorical_accuracy: 0.5508"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.7206 - sparse_categorical_accuracy: 0.5523 - val_loss: 0.6790 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6658 - sparse_categorical_accuracy: 0.5939 - val_loss: 0.6796 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6915 - sparse_categorical_accuracy: 0.6159 - val_loss: 0.6802 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6788 - sparse_categorical_accuracy: 0.5795"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.6797 - sparse_categorical_accuracy: 0.5808 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6586 - sparse_categorical_accuracy: 0.6093"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.6625 - sparse_categorical_accuracy: 0.6024 - val_loss: 0.6764 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.6855 - sparse_categorical_accuracy: 0.6225 - val_loss: 0.6774 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.6782 - sparse_categorical_accuracy: 0.6259 - val_loss: 0.6773 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6730 - sparse_categorical_accuracy: 0.6180 - val_loss: 0.6765 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6757 - sparse_categorical_accuracy: 0.5732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6751 - sparse_categorical_accuracy: 0.5733 - val_loss: 0.6759 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6514 - sparse_categorical_accuracy: 0.6367"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6595 - sparse_categorical_accuracy: 0.6225 - val_loss: 0.6756 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6674 - sparse_categorical_accuracy: 0.6321 - val_loss: 0.6775 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6707 - sparse_categorical_accuracy: 0.6306 - val_loss: 0.6773 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6626 - sparse_categorical_accuracy: 0.6374 - val_loss: 0.6776 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6543 - sparse_categorical_accuracy: 0.6406 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6401 - sparse_categorical_accuracy: 0.6592\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6430 - sparse_categorical_accuracy: 0.6484 - val_loss: 0.6771 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6329 - sparse_categorical_accuracy: 0.6430 - val_loss: 0.6784 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6376 - sparse_categorical_accuracy: 0.6256 - val_loss: 0.6810 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6397 - sparse_categorical_accuracy: 0.6193 - val_loss: 0.6829 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6508 - sparse_categorical_accuracy: 0.5976 - val_loss: 0.6839 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6497 - sparse_categorical_accuracy: 0.6444\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6496 - sparse_categorical_accuracy: 0.6428 - val_loss: 0.6846 - val_sparse_categorical_accuracy: 0.6000 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6381 - sparse_categorical_accuracy: 0.6461 - val_loss: 0.6849 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 2.5000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6457 - sparse_categorical_accuracy: 0.6383 - val_loss: 0.6851 - val_sparse_categorical_accuracy: 0.5833 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6515 - sparse_categorical_accuracy: 0.6257 - val_loss: 0.6852 - val_sparse_categorical_accuracy: 0.5833 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6392 - sparse_categorical_accuracy: 0.6413 - val_loss: 0.6849 - val_sparse_categorical_accuracy: 0.5833 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6335 - sparse_categorical_accuracy: 0.6616\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6354 - sparse_categorical_accuracy: 0.6510 - val_loss: 0.6849 - val_sparse_categorical_accuracy: 0.5833 - learning_rate: 2.5000e-04\n",
            "Epoch 25: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "  Test Accuracy: 72.22%\n",
            "  Test Precision (weighted): 52.16%\n",
            "  Test Recall (weighted): 72.22%\n",
            "  Test F1-Score (weighted): 60.57%\n",
            "\n",
            "--- Fold 15/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6873 - sparse_categorical_accuracy: 0.6005"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - loss: 0.6929 - sparse_categorical_accuracy: 0.5943 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6585 - sparse_categorical_accuracy: 0.6055"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6633 - sparse_categorical_accuracy: 0.5965 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6722 - sparse_categorical_accuracy: 0.6102"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.6738 - sparse_categorical_accuracy: 0.6077 - val_loss: 0.6725 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6489 - sparse_categorical_accuracy: 0.6358"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6559 - sparse_categorical_accuracy: 0.6263 - val_loss: 0.6715 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.6425 - sparse_categorical_accuracy: 0.6418 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6619 - sparse_categorical_accuracy: 0.6084 - val_loss: 0.6726 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.6568 - sparse_categorical_accuracy: 0.6143 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6613 - sparse_categorical_accuracy: 0.6317 - val_loss: 0.6766 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6385 - sparse_categorical_accuracy: 0.6454\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6447 - sparse_categorical_accuracy: 0.6395 - val_loss: 0.6803 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6457 - sparse_categorical_accuracy: 0.6180 - val_loss: 0.6812 - val_sparse_categorical_accuracy: 0.6667 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6527 - sparse_categorical_accuracy: 0.6384 - val_loss: 0.6808 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6517 - sparse_categorical_accuracy: 0.6166 - val_loss: 0.6801 - val_sparse_categorical_accuracy: 0.6667 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6482 - sparse_categorical_accuracy: 0.6197 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6392 - sparse_categorical_accuracy: 0.6579\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6451 - sparse_categorical_accuracy: 0.6459 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6481 - sparse_categorical_accuracy: 0.6376 - val_loss: 0.6723 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6410 - sparse_categorical_accuracy: 0.6632 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 2.5000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6376 - sparse_categorical_accuracy: 0.6306 - val_loss: 0.6742 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6368 - sparse_categorical_accuracy: 0.6461 - val_loss: 0.6750 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6604 - sparse_categorical_accuracy: 0.6494\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6654 - sparse_categorical_accuracy: 0.6390 - val_loss: 0.6747 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "  Test Accuracy: 50.00%\n",
            "  Test Precision (weighted): 25.00%\n",
            "  Test Recall (weighted): 50.00%\n",
            "  Test F1-Score (weighted): 33.33%\n",
            "\n",
            "--- Fold 16/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6885 - sparse_categorical_accuracy: 0.5948"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 0.6936 - sparse_categorical_accuracy: 0.5906 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6545 - sparse_categorical_accuracy: 0.5883 - val_loss: 0.6809 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6610 - sparse_categorical_accuracy: 0.6260 - val_loss: 0.6798 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6528 - sparse_categorical_accuracy: 0.6496 - val_loss: 0.6797 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6719 - sparse_categorical_accuracy: 0.6283 - val_loss: 0.6831 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6600 - sparse_categorical_accuracy: 0.6285\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6651 - sparse_categorical_accuracy: 0.6186 - val_loss: 0.6856 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6209 - sparse_categorical_accuracy: 0.6670 - val_loss: 0.6876 - val_sparse_categorical_accuracy: 0.5000 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6511 - sparse_categorical_accuracy: 0.6324 - val_loss: 0.6886 - val_sparse_categorical_accuracy: 0.5833 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6723 - sparse_categorical_accuracy: 0.6362 - val_loss: 0.6877 - val_sparse_categorical_accuracy: 0.6000 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6392 - sparse_categorical_accuracy: 0.6263 - val_loss: 0.6891 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6454 - sparse_categorical_accuracy: 0.6184\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6492 - sparse_categorical_accuracy: 0.6141 - val_loss: 0.6896 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6431 - sparse_categorical_accuracy: 0.6358 - val_loss: 0.6900 - val_sparse_categorical_accuracy: 0.5000 - learning_rate: 2.5000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6487 - sparse_categorical_accuracy: 0.6542 - val_loss: 0.6895 - val_sparse_categorical_accuracy: 0.5333 - learning_rate: 2.5000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6462 - sparse_categorical_accuracy: 0.6586 - val_loss: 0.6892 - val_sparse_categorical_accuracy: 0.5833 - learning_rate: 2.5000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6581 - sparse_categorical_accuracy: 0.6668 - val_loss: 0.6918 - val_sparse_categorical_accuracy: 0.4500 - learning_rate: 2.5000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6422 - sparse_categorical_accuracy: 0.6268\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.6459 - sparse_categorical_accuracy: 0.6256 - val_loss: 0.6921 - val_sparse_categorical_accuracy: 0.4333 - learning_rate: 2.5000e-04\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "  Test Accuracy: 38.89%\n",
            "  Test Precision (weighted): 15.12%\n",
            "  Test Recall (weighted): 38.89%\n",
            "  Test F1-Score (weighted): 21.78%\n",
            "\n",
            "--- Fold 17/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7910 - sparse_categorical_accuracy: 0.4545"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - loss: 0.7743 - sparse_categorical_accuracy: 0.4791 - val_loss: 0.6763 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.7476 - sparse_categorical_accuracy: 0.5103"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.7340 - sparse_categorical_accuracy: 0.5190 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6675 - sparse_categorical_accuracy: 0.6358"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6706 - sparse_categorical_accuracy: 0.6253 - val_loss: 0.6690 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6642 - sparse_categorical_accuracy: 0.6127 - val_loss: 0.6699 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6799 - sparse_categorical_accuracy: 0.6211 - val_loss: 0.6694 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6586 - sparse_categorical_accuracy: 0.6012"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6600 - sparse_categorical_accuracy: 0.5993 - val_loss: 0.6674 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6955 - sparse_categorical_accuracy: 0.5826 - val_loss: 0.6728 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6599 - sparse_categorical_accuracy: 0.6419 - val_loss: 0.6782 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6501 - sparse_categorical_accuracy: 0.6204 - val_loss: 0.6751 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6585 - sparse_categorical_accuracy: 0.6149 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6561 - sparse_categorical_accuracy: 0.6139\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6581 - sparse_categorical_accuracy: 0.6112 - val_loss: 0.6755 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6687 - sparse_categorical_accuracy: 0.6166 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6742 - sparse_categorical_accuracy: 0.6050 - val_loss: 0.6728 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6590 - sparse_categorical_accuracy: 0.6426 - val_loss: 0.6702 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6680 - sparse_categorical_accuracy: 0.5853 - val_loss: 0.6688 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6420 - sparse_categorical_accuracy: 0.6404"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6455 - sparse_categorical_accuracy: 0.6331 - val_loss: 0.6653 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6546 - sparse_categorical_accuracy: 0.6105"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6554 - sparse_categorical_accuracy: 0.6144 - val_loss: 0.6640 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6507 - sparse_categorical_accuracy: 0.6084 - val_loss: 0.6651 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6368 - sparse_categorical_accuracy: 0.6409 - val_loss: 0.6658 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6253 - sparse_categorical_accuracy: 0.6635 - val_loss: 0.6651 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6456 - sparse_categorical_accuracy: 0.6366 - val_loss: 0.6650 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6458 - sparse_categorical_accuracy: 0.6417\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6497 - sparse_categorical_accuracy: 0.6357 - val_loss: 0.6679 - val_sparse_categorical_accuracy: 0.6000 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6431 - sparse_categorical_accuracy: 0.6147 - val_loss: 0.6668 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6124 - sparse_categorical_accuracy: 0.6750 - val_loss: 0.6656 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6252 - sparse_categorical_accuracy: 0.6825"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6303 - sparse_categorical_accuracy: 0.6686 - val_loss: 0.6633 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6243 - sparse_categorical_accuracy: 0.7006"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6252 - sparse_categorical_accuracy: 0.6982 - val_loss: 0.6617 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6211 - sparse_categorical_accuracy: 0.6422"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.6225 - sparse_categorical_accuracy: 0.6374 - val_loss: 0.6593 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6184 - sparse_categorical_accuracy: 0.6554 - val_loss: 0.6594 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6668 - sparse_categorical_accuracy: 0.5925 - val_loss: 0.6622 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 2.5000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.6127 - sparse_categorical_accuracy: 0.6728 - val_loss: 0.6612 - val_sparse_categorical_accuracy: 0.6000 - learning_rate: 2.5000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6417 - sparse_categorical_accuracy: 0.5820"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.6430 - sparse_categorical_accuracy: 0.5813 - val_loss: 0.6587 - val_sparse_categorical_accuracy: 0.6000 - learning_rate: 2.5000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6508 - sparse_categorical_accuracy: 0.6052"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6511 - sparse_categorical_accuracy: 0.6024 - val_loss: 0.6560 - val_sparse_categorical_accuracy: 0.6000 - learning_rate: 2.5000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6247 - sparse_categorical_accuracy: 0.6635"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6299 - sparse_categorical_accuracy: 0.6547 - val_loss: 0.6536 - val_sparse_categorical_accuracy: 0.6000 - learning_rate: 2.5000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6145 - sparse_categorical_accuracy: 0.6512 - val_loss: 0.6545 - val_sparse_categorical_accuracy: 0.6000 - learning_rate: 2.5000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6277 - sparse_categorical_accuracy: 0.6428 - val_loss: 0.6538 - val_sparse_categorical_accuracy: 0.6000 - learning_rate: 2.5000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6472 - sparse_categorical_accuracy: 0.6306"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6488 - sparse_categorical_accuracy: 0.6264 - val_loss: 0.6527 - val_sparse_categorical_accuracy: 0.6000 - learning_rate: 2.5000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6224 - sparse_categorical_accuracy: 0.6534"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6285 - sparse_categorical_accuracy: 0.6440 - val_loss: 0.6523 - val_sparse_categorical_accuracy: 0.6000 - learning_rate: 2.5000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6134 - sparse_categorical_accuracy: 0.6283"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6249 - sparse_categorical_accuracy: 0.6280 - val_loss: 0.6523 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 2.5000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6204 - sparse_categorical_accuracy: 0.6646"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.6233 - sparse_categorical_accuracy: 0.6607 - val_loss: 0.6512 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.6396 - sparse_categorical_accuracy: 0.6556 - val_loss: 0.6519 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6026 - sparse_categorical_accuracy: 0.6882 - val_loss: 0.6512 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6338 - sparse_categorical_accuracy: 0.6646"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6373 - sparse_categorical_accuracy: 0.6556 - val_loss: 0.6498 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 2.5000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.6404 - sparse_categorical_accuracy: 0.6114 - val_loss: 0.6499 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 2.5000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6483 - sparse_categorical_accuracy: 0.5904 - val_loss: 0.6512 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 2.5000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6343 - sparse_categorical_accuracy: 0.6425 - val_loss: 0.6524 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 2.5000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6384 - sparse_categorical_accuracy: 0.6917 - val_loss: 0.6515 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 2.5000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5991 - sparse_categorical_accuracy: 0.6882\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6039 - sparse_categorical_accuracy: 0.6803 - val_loss: 0.6519 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 2.5000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6453 - sparse_categorical_accuracy: 0.6587 - val_loss: 0.6523 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 1.2500e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6098 - sparse_categorical_accuracy: 0.6681 - val_loss: 0.6525 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 1.2500e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6285 - sparse_categorical_accuracy: 0.6503 - val_loss: 0.6528 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6320 - sparse_categorical_accuracy: 0.6682 - val_loss: 0.6531 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 1.2500e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6203 - sparse_categorical_accuracy: 0.6593\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6219 - sparse_categorical_accuracy: 0.6596 - val_loss: 0.6538 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 1.2500e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6329 - sparse_categorical_accuracy: 0.6440 - val_loss: 0.6543 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 6.2500e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6053 - sparse_categorical_accuracy: 0.6686 - val_loss: 0.6550 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 6.2500e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6193 - sparse_categorical_accuracy: 0.6860 - val_loss: 0.6555 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 6.2500e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6257 - sparse_categorical_accuracy: 0.6559 - val_loss: 0.6557 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 6.2500e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6167 - sparse_categorical_accuracy: 0.6652\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6206 - sparse_categorical_accuracy: 0.6579 - val_loss: 0.6562 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 6.2500e-05\n",
            "Epoch 57: early stopping\n",
            "Restoring model weights from the end of the best epoch: 42.\n",
            "  Test Accuracy: 61.11%\n",
            "  Test Precision (weighted): 63.92%\n",
            "  Test Recall (weighted): 61.11%\n",
            "  Test F1-Score (weighted): 60.75%\n",
            "\n",
            "--- Fold 18/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.7756 - sparse_categorical_accuracy: 0.4744"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - loss: 0.7732 - sparse_categorical_accuracy: 0.4737 - val_loss: 0.6769 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6826 - sparse_categorical_accuracy: 0.6110"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6855 - sparse_categorical_accuracy: 0.6039 - val_loss: 0.6757 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6781 - sparse_categorical_accuracy: 0.5612"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6797 - sparse_categorical_accuracy: 0.5659 - val_loss: 0.6728 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6641 - sparse_categorical_accuracy: 0.6247"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6647 - sparse_categorical_accuracy: 0.6187 - val_loss: 0.6697 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6852 - sparse_categorical_accuracy: 0.6132"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6861 - sparse_categorical_accuracy: 0.6097 - val_loss: 0.6689 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6522 - sparse_categorical_accuracy: 0.6147 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6633 - sparse_categorical_accuracy: 0.5978 - val_loss: 0.6743 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6680 - sparse_categorical_accuracy: 0.5871 - val_loss: 0.6760 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6626 - sparse_categorical_accuracy: 0.6127 - val_loss: 0.6745 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6725 - sparse_categorical_accuracy: 0.6061\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6725 - sparse_categorical_accuracy: 0.6044 - val_loss: 0.6724 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6703 - sparse_categorical_accuracy: 0.6164 - val_loss: 0.6713 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6621 - sparse_categorical_accuracy: 0.6267 - val_loss: 0.6719 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6558 - sparse_categorical_accuracy: 0.6259 - val_loss: 0.6713 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6570 - sparse_categorical_accuracy: 0.6299 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6619 - sparse_categorical_accuracy: 0.6055\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6620 - sparse_categorical_accuracy: 0.6052 - val_loss: 0.6693 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6456 - sparse_categorical_accuracy: 0.6334"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6506 - sparse_categorical_accuracy: 0.6257 - val_loss: 0.6683 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6382 - sparse_categorical_accuracy: 0.6626"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6405 - sparse_categorical_accuracy: 0.6562 - val_loss: 0.6675 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6662 - sparse_categorical_accuracy: 0.5890"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6698 - sparse_categorical_accuracy: 0.5849 - val_loss: 0.6671 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6421 - sparse_categorical_accuracy: 0.6426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6462 - sparse_categorical_accuracy: 0.6377 - val_loss: 0.6669 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6527 - sparse_categorical_accuracy: 0.6568 - val_loss: 0.6678 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6610 - sparse_categorical_accuracy: 0.6225 - val_loss: 0.6675 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6569 - sparse_categorical_accuracy: 0.6381 - val_loss: 0.6671 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6348 - sparse_categorical_accuracy: 0.6688 - val_loss: 0.6670 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6474 - sparse_categorical_accuracy: 0.6259"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6504 - sparse_categorical_accuracy: 0.6237 - val_loss: 0.6667 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6349 - sparse_categorical_accuracy: 0.6332"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6413 - sparse_categorical_accuracy: 0.6264 - val_loss: 0.6650 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.6606 - sparse_categorical_accuracy: 0.6194 - val_loss: 0.6652 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6320 - sparse_categorical_accuracy: 0.6740"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6369 - sparse_categorical_accuracy: 0.6656 - val_loss: 0.6647 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6490 - sparse_categorical_accuracy: 0.6475"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.6514 - sparse_categorical_accuracy: 0.6389 - val_loss: 0.6644 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6546 - sparse_categorical_accuracy: 0.6518 - val_loss: 0.6654 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.6351 - sparse_categorical_accuracy: 0.6644 - val_loss: 0.6664 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.6510 - sparse_categorical_accuracy: 0.6278 - val_loss: 0.6667 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.6413 - sparse_categorical_accuracy: 0.6367 - val_loss: 0.6654 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6418 - sparse_categorical_accuracy: 0.6453"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.6427 - sparse_categorical_accuracy: 0.6434 - val_loss: 0.6638 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6370 - sparse_categorical_accuracy: 0.6472"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6418 - sparse_categorical_accuracy: 0.6398 - val_loss: 0.6608 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6294 - sparse_categorical_accuracy: 0.6618"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6356 - sparse_categorical_accuracy: 0.6509 - val_loss: 0.6595 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6455 - sparse_categorical_accuracy: 0.6519"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6498 - sparse_categorical_accuracy: 0.6437 - val_loss: 0.6591 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6272 - sparse_categorical_accuracy: 0.6442"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6329 - sparse_categorical_accuracy: 0.6377 - val_loss: 0.6586 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6271 - sparse_categorical_accuracy: 0.6591"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6328 - sparse_categorical_accuracy: 0.6524 - val_loss: 0.6581 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6313 - sparse_categorical_accuracy: 0.6497"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6356 - sparse_categorical_accuracy: 0.6445 - val_loss: 0.6569 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6216 - sparse_categorical_accuracy: 0.6509"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6250 - sparse_categorical_accuracy: 0.6424 - val_loss: 0.6551 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6496 - sparse_categorical_accuracy: 0.6772"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6513 - sparse_categorical_accuracy: 0.6671 - val_loss: 0.6541 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6543 - sparse_categorical_accuracy: 0.6674"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6570 - sparse_categorical_accuracy: 0.6518 - val_loss: 0.6530 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.6052 - sparse_categorical_accuracy: 0.6743 - val_loss: 0.6536 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6293 - sparse_categorical_accuracy: 0.6395 - val_loss: 0.6550 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6417 - sparse_categorical_accuracy: 0.6311 - val_loss: 0.6552 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6292 - sparse_categorical_accuracy: 0.6447 - val_loss: 0.6548 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6228 - sparse_categorical_accuracy: 0.6586\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6271 - sparse_categorical_accuracy: 0.6530 - val_loss: 0.6555 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6216 - sparse_categorical_accuracy: 0.6475 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6323 - sparse_categorical_accuracy: 0.6537 - val_loss: 0.6559 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6252 - sparse_categorical_accuracy: 0.6306 - val_loss: 0.6553 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6196 - sparse_categorical_accuracy: 0.6752 - val_loss: 0.6548 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6228 - sparse_categorical_accuracy: 0.6402\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6329 - sparse_categorical_accuracy: 0.6293 - val_loss: 0.6546 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6342 - sparse_categorical_accuracy: 0.6479 - val_loss: 0.6549 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6294 - sparse_categorical_accuracy: 0.6321 - val_loss: 0.6548 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5876 - sparse_categorical_accuracy: 0.6743 - val_loss: 0.6546 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6390 - sparse_categorical_accuracy: 0.6556 - val_loss: 0.6543 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6206 - sparse_categorical_accuracy: 0.6147\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6262 - sparse_categorical_accuracy: 0.6127 - val_loss: 0.6541 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 6.2500e-05\n",
            "Epoch 57: early stopping\n",
            "Restoring model weights from the end of the best epoch: 42.\n",
            "  Test Accuracy: 44.44%\n",
            "  Test Precision (weighted): 19.75%\n",
            "  Test Recall (weighted): 44.44%\n",
            "  Test F1-Score (weighted): 27.35%\n",
            "\n",
            "--- Fold 19/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.7357 - sparse_categorical_accuracy: 0.5641"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 92ms/step - loss: 0.7349 - sparse_categorical_accuracy: 0.5652 - val_loss: 0.6767 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6845 - sparse_categorical_accuracy: 0.5668 - val_loss: 0.6774 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.7149 - sparse_categorical_accuracy: 0.5291 - val_loss: 0.6788 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6802 - sparse_categorical_accuracy: 0.5120 - val_loss: 0.6794 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6722 - sparse_categorical_accuracy: 0.6397 - val_loss: 0.6787 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6739 - sparse_categorical_accuracy: 0.6010\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6751 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6774 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6461 - sparse_categorical_accuracy: 0.6253 - val_loss: 0.6775 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6678 - sparse_categorical_accuracy: 0.5923 - val_loss: 0.6775 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6589 - sparse_categorical_accuracy: 0.5818 - val_loss: 0.6771 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6797 - sparse_categorical_accuracy: 0.6260 - val_loss: 0.6773 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6584 - sparse_categorical_accuracy: 0.6315\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6603 - sparse_categorical_accuracy: 0.6275 - val_loss: 0.6767 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6614 - sparse_categorical_accuracy: 0.6574 - val_loss: 0.6768 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6654 - sparse_categorical_accuracy: 0.5769 - val_loss: 0.6770 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6559 - sparse_categorical_accuracy: 0.6328 - val_loss: 0.6768 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6767 - sparse_categorical_accuracy: 0.6097 - val_loss: 0.6771 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6815 - sparse_categorical_accuracy: 0.6220\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6824 - sparse_categorical_accuracy: 0.6119 - val_loss: 0.6773 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "  Test Accuracy: 72.22%\n",
            "  Test Precision (weighted): 52.16%\n",
            "  Test Recall (weighted): 72.22%\n",
            "  Test F1-Score (weighted): 60.57%\n",
            "\n",
            "--- Fold 20/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6787 - sparse_categorical_accuracy: 0.5791"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 0.6877 - sparse_categorical_accuracy: 0.5805 - val_loss: 0.6789 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6831 - sparse_categorical_accuracy: 0.6050 - val_loss: 0.6830 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6858 - sparse_categorical_accuracy: 0.5734"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6860 - sparse_categorical_accuracy: 0.5674 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6494 - sparse_categorical_accuracy: 0.6021"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6537 - sparse_categorical_accuracy: 0.5970 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.6505 - sparse_categorical_accuracy: 0.6263 - val_loss: 0.6813 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6663 - sparse_categorical_accuracy: 0.6611 - val_loss: 0.6906 - val_sparse_categorical_accuracy: 0.4500 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6744 - sparse_categorical_accuracy: 0.5630 - val_loss: 0.6926 - val_sparse_categorical_accuracy: 0.5000 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6767 - sparse_categorical_accuracy: 0.5841 - val_loss: 0.6890 - val_sparse_categorical_accuracy: 0.5000 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6686 - sparse_categorical_accuracy: 0.6146\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.6707 - sparse_categorical_accuracy: 0.6109 - val_loss: 0.6910 - val_sparse_categorical_accuracy: 0.5000 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.6688 - sparse_categorical_accuracy: 0.6185 - val_loss: 0.6922 - val_sparse_categorical_accuracy: 0.5167 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.6549 - sparse_categorical_accuracy: 0.5931 - val_loss: 0.6898 - val_sparse_categorical_accuracy: 0.5333 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6598 - sparse_categorical_accuracy: 0.6452 - val_loss: 0.6877 - val_sparse_categorical_accuracy: 0.5667 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6459 - sparse_categorical_accuracy: 0.6145 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.5000 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6366 - sparse_categorical_accuracy: 0.6521\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6384 - sparse_categorical_accuracy: 0.6483 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.5333 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6608 - sparse_categorical_accuracy: 0.6365 - val_loss: 0.6889 - val_sparse_categorical_accuracy: 0.6000 - learning_rate: 2.5000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6461 - sparse_categorical_accuracy: 0.6504 - val_loss: 0.6907 - val_sparse_categorical_accuracy: 0.5333 - learning_rate: 2.5000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6367 - sparse_categorical_accuracy: 0.6533 - val_loss: 0.6938 - val_sparse_categorical_accuracy: 0.5167 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6577 - sparse_categorical_accuracy: 0.6477 - val_loss: 0.6942 - val_sparse_categorical_accuracy: 0.5333 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6376 - sparse_categorical_accuracy: 0.6332\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6422 - sparse_categorical_accuracy: 0.6294 - val_loss: 0.6922 - val_sparse_categorical_accuracy: 0.4833 - learning_rate: 2.5000e-04\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "  Test Accuracy: 55.56%\n",
            "  Test Precision (weighted): 30.86%\n",
            "  Test Recall (weighted): 55.56%\n",
            "  Test F1-Score (weighted): 39.68%\n",
            "\n",
            "--- Fold 21/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6576 - sparse_categorical_accuracy: 0.6339"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.6678 - sparse_categorical_accuracy: 0.6264 - val_loss: 0.6755 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.7043 - sparse_categorical_accuracy: 0.6091 - val_loss: 0.6780 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6867 - sparse_categorical_accuracy: 0.5819 - val_loss: 0.6768 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6625 - sparse_categorical_accuracy: 0.5942 - val_loss: 0.6763 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6720 - sparse_categorical_accuracy: 0.5778 - val_loss: 0.6769 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6896 - sparse_categorical_accuracy: 0.5977\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6894 - sparse_categorical_accuracy: 0.5950 - val_loss: 0.6786 - val_sparse_categorical_accuracy: 0.6000 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6786 - sparse_categorical_accuracy: 0.5476 - val_loss: 0.6802 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6624 - sparse_categorical_accuracy: 0.6345 - val_loss: 0.6776 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6582 - sparse_categorical_accuracy: 0.6064 - val_loss: 0.6766 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6761 - sparse_categorical_accuracy: 0.6139 - val_loss: 0.6774 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6470 - sparse_categorical_accuracy: 0.6493\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6488 - sparse_categorical_accuracy: 0.6412 - val_loss: 0.6797 - val_sparse_categorical_accuracy: 0.5333 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6760 - sparse_categorical_accuracy: 0.5475 - val_loss: 0.6799 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 2.5000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6493 - sparse_categorical_accuracy: 0.6326 - val_loss: 0.6810 - val_sparse_categorical_accuracy: 0.5167 - learning_rate: 2.5000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6844 - sparse_categorical_accuracy: 0.5646 - val_loss: 0.6814 - val_sparse_categorical_accuracy: 0.5167 - learning_rate: 2.5000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6491 - sparse_categorical_accuracy: 0.6181 - val_loss: 0.6815 - val_sparse_categorical_accuracy: 0.5667 - learning_rate: 2.5000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6363 - sparse_categorical_accuracy: 0.5969\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6375 - sparse_categorical_accuracy: 0.5958 - val_loss: 0.6801 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 2.5000e-04\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "  Test Accuracy: 55.56%\n",
            "  Test Precision (weighted): 30.86%\n",
            "  Test Recall (weighted): 55.56%\n",
            "  Test F1-Score (weighted): 39.68%\n",
            "\n",
            "--- Fold 22/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.7251 - sparse_categorical_accuracy: 0.5517"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.7249 - sparse_categorical_accuracy: 0.5522 - val_loss: 0.6854 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6638 - sparse_categorical_accuracy: 0.6104"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6698 - sparse_categorical_accuracy: 0.5944 - val_loss: 0.6853 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6804 - sparse_categorical_accuracy: 0.5659"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6818 - sparse_categorical_accuracy: 0.5643 - val_loss: 0.6834 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6959 - sparse_categorical_accuracy: 0.5834"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6930 - sparse_categorical_accuracy: 0.5837 - val_loss: 0.6822 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6755 - sparse_categorical_accuracy: 0.6161"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6756 - sparse_categorical_accuracy: 0.6112 - val_loss: 0.6810 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6766 - sparse_categorical_accuracy: 0.6343"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6770 - sparse_categorical_accuracy: 0.6271 - val_loss: 0.6805 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6333 - sparse_categorical_accuracy: 0.6403"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6405 - sparse_categorical_accuracy: 0.6325 - val_loss: 0.6803 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.6729 - sparse_categorical_accuracy: 0.6318 - val_loss: 0.6832 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6611 - sparse_categorical_accuracy: 0.6054 - val_loss: 0.6845 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6741 - sparse_categorical_accuracy: 0.6181 - val_loss: 0.6838 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6723 - sparse_categorical_accuracy: 0.5890 - val_loss: 0.6837 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6715 - sparse_categorical_accuracy: 0.6118\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6697 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6826 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6483 - sparse_categorical_accuracy: 0.6461 - val_loss: 0.6817 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6704 - sparse_categorical_accuracy: 0.6134 - val_loss: 0.6812 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6650 - sparse_categorical_accuracy: 0.6360 - val_loss: 0.6804 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6430 - sparse_categorical_accuracy: 0.6538"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6452 - sparse_categorical_accuracy: 0.6466 - val_loss: 0.6793 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6591 - sparse_categorical_accuracy: 0.6217"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6585 - sparse_categorical_accuracy: 0.6138 - val_loss: 0.6787 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6383 - sparse_categorical_accuracy: 0.6354"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.6396 - sparse_categorical_accuracy: 0.6336 - val_loss: 0.6780 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6428 - sparse_categorical_accuracy: 0.6452 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.5500 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6227 - sparse_categorical_accuracy: 0.6809"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6298 - sparse_categorical_accuracy: 0.6644 - val_loss: 0.6767 - val_sparse_categorical_accuracy: 0.5333 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6258 - sparse_categorical_accuracy: 0.6407"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6314 - sparse_categorical_accuracy: 0.6343 - val_loss: 0.6741 - val_sparse_categorical_accuracy: 0.6667 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6320 - sparse_categorical_accuracy: 0.6637"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6353 - sparse_categorical_accuracy: 0.6598 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6000 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6530 - sparse_categorical_accuracy: 0.6419"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6505 - sparse_categorical_accuracy: 0.6399 - val_loss: 0.6710 - val_sparse_categorical_accuracy: 0.5833 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6497 - sparse_categorical_accuracy: 0.6378"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6506 - sparse_categorical_accuracy: 0.6356 - val_loss: 0.6696 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6378 - sparse_categorical_accuracy: 0.6360 - val_loss: 0.6706 - val_sparse_categorical_accuracy: 0.5667 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6375 - sparse_categorical_accuracy: 0.5994"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.6386 - sparse_categorical_accuracy: 0.5997 - val_loss: 0.6652 - val_sparse_categorical_accuracy: 0.5833 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6313 - sparse_categorical_accuracy: 0.6497"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.6302 - sparse_categorical_accuracy: 0.6473 - val_loss: 0.6640 - val_sparse_categorical_accuracy: 0.5667 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6716 - sparse_categorical_accuracy: 0.6261"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.6719 - sparse_categorical_accuracy: 0.6254 - val_loss: 0.6632 - val_sparse_categorical_accuracy: 0.5833 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6301 - sparse_categorical_accuracy: 0.6389 - val_loss: 0.6632 - val_sparse_categorical_accuracy: 0.5833 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6561 - sparse_categorical_accuracy: 0.6488 - val_loss: 0.6662 - val_sparse_categorical_accuracy: 0.5667 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6285 - sparse_categorical_accuracy: 0.6719 - val_loss: 0.6652 - val_sparse_categorical_accuracy: 0.5833 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6116 - sparse_categorical_accuracy: 0.6716"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6143 - sparse_categorical_accuracy: 0.6693 - val_loss: 0.6631 - val_sparse_categorical_accuracy: 0.5667 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6379 - sparse_categorical_accuracy: 0.6672\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6394 - sparse_categorical_accuracy: 0.6622 - val_loss: 0.6638 - val_sparse_categorical_accuracy: 0.5667 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6314 - sparse_categorical_accuracy: 0.6509 - val_loss: 0.6638 - val_sparse_categorical_accuracy: 0.6000 - learning_rate: 2.5000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6425 - sparse_categorical_accuracy: 0.6377"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6383 - sparse_categorical_accuracy: 0.6365 - val_loss: 0.6617 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 2.5000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6045 - sparse_categorical_accuracy: 0.6792"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6106 - sparse_categorical_accuracy: 0.6690 - val_loss: 0.6610 - val_sparse_categorical_accuracy: 0.6500 - learning_rate: 2.5000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6045 - sparse_categorical_accuracy: 0.6862"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6099 - sparse_categorical_accuracy: 0.6787 - val_loss: 0.6606 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6368 - sparse_categorical_accuracy: 0.6030"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.6405 - sparse_categorical_accuracy: 0.6032 - val_loss: 0.6602 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 2.5000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6319 - sparse_categorical_accuracy: 0.6458 - val_loss: 0.6604 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 2.5000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6020 - sparse_categorical_accuracy: 0.6883"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6058 - sparse_categorical_accuracy: 0.6812 - val_loss: 0.6598 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 2.5000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6022 - sparse_categorical_accuracy: 0.6954 - val_loss: 0.6602 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 2.5000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6068 - sparse_categorical_accuracy: 0.6888"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6089 - sparse_categorical_accuracy: 0.6850 - val_loss: 0.6597 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6067 - sparse_categorical_accuracy: 0.6827 - val_loss: 0.6606 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6117 - sparse_categorical_accuracy: 0.6771 - val_loss: 0.6615 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 2.5000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5832 - sparse_categorical_accuracy: 0.6671\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5923 - sparse_categorical_accuracy: 0.6636 - val_loss: 0.6652 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 2.5000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5903 - sparse_categorical_accuracy: 0.6931 - val_loss: 0.6674 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5945 - sparse_categorical_accuracy: 0.7175 - val_loss: 0.6678 - val_sparse_categorical_accuracy: 0.6333 - learning_rate: 1.2500e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5883 - sparse_categorical_accuracy: 0.6616 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.6000 - learning_rate: 1.2500e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6090 - sparse_categorical_accuracy: 0.6747 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.5833 - learning_rate: 1.2500e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5977 - sparse_categorical_accuracy: 0.6889\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5993 - sparse_categorical_accuracy: 0.6875 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.5667 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6083 - sparse_categorical_accuracy: 0.6768 - val_loss: 0.6786 - val_sparse_categorical_accuracy: 0.5667 - learning_rate: 6.2500e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6100 - sparse_categorical_accuracy: 0.6734 - val_loss: 0.6790 - val_sparse_categorical_accuracy: 0.5667 - learning_rate: 6.2500e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6041 - sparse_categorical_accuracy: 0.6855 - val_loss: 0.6786 - val_sparse_categorical_accuracy: 0.5667 - learning_rate: 6.2500e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5762 - sparse_categorical_accuracy: 0.7048 - val_loss: 0.6782 - val_sparse_categorical_accuracy: 0.5667 - learning_rate: 6.2500e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5975 - sparse_categorical_accuracy: 0.7108\n",
            "Epoch 55: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5950 - sparse_categorical_accuracy: 0.7040 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.5667 - learning_rate: 6.2500e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5986 - sparse_categorical_accuracy: 0.6776 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.5667 - learning_rate: 3.1250e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5971 - sparse_categorical_accuracy: 0.6643 - val_loss: 0.6816 - val_sparse_categorical_accuracy: 0.5667 - learning_rate: 3.1250e-05\n",
            "Epoch 57: early stopping\n",
            "Restoring model weights from the end of the best epoch: 42.\n",
            "  Test Accuracy: 72.22%\n",
            "  Test Precision (weighted): 59.48%\n",
            "  Test Recall (weighted): 72.22%\n",
            "  Test F1-Score (weighted): 65.23%\n",
            "\n",
            "--- Fold 23/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.7734 - sparse_categorical_accuracy: 0.5178"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - loss: 0.7699 - sparse_categorical_accuracy: 0.5239 - val_loss: 0.6718 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6571 - sparse_categorical_accuracy: 0.5987 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.7144 - sparse_categorical_accuracy: 0.5461 - val_loss: 0.6791 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6563 - sparse_categorical_accuracy: 0.6124 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6776 - sparse_categorical_accuracy: 0.6082 - val_loss: 0.6771 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6751 - sparse_categorical_accuracy: 0.6051\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6773 - sparse_categorical_accuracy: 0.5980 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6652 - sparse_categorical_accuracy: 0.6046 - val_loss: 0.6795 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6738 - sparse_categorical_accuracy: 0.5860 - val_loss: 0.6800 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6474 - sparse_categorical_accuracy: 0.6147 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6545 - sparse_categorical_accuracy: 0.6393 - val_loss: 0.6790 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6709 - sparse_categorical_accuracy: 0.6376\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6682 - sparse_categorical_accuracy: 0.6276 - val_loss: 0.6799 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6558 - sparse_categorical_accuracy: 0.6087 - val_loss: 0.6804 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 2.5000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6382 - sparse_categorical_accuracy: 0.6570 - val_loss: 0.6807 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 2.5000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6271 - sparse_categorical_accuracy: 0.6789 - val_loss: 0.6810 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 2.5000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6485 - sparse_categorical_accuracy: 0.6190 - val_loss: 0.6821 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 2.5000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6394 - sparse_categorical_accuracy: 0.6384\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6458 - sparse_categorical_accuracy: 0.6310 - val_loss: 0.6825 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 2.5000e-04\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "  Test Accuracy: 55.56%\n",
            "  Test Precision (weighted): 30.86%\n",
            "  Test Recall (weighted): 55.56%\n",
            "  Test F1-Score (weighted): 39.68%\n",
            "\n",
            "======================================================================\n",
            "  VALENCE SONUÇLARI\n",
            "======================================================================\n",
            "Ortalama Accuracy: 60.39% ± 12.83%\n",
            "Ortalama Precision: 41.23% ± 16.52%\n",
            "Ortalama Recall: 60.39% ± 12.83%\n",
            "Ortalama F1-Score: 48.20% ± 15.65%\n",
            "\n",
            "======================================================================\n",
            "  AROUSAL İÇİN LOSO ÇAPRAZ DOĞRULAMA EĞİTİMİ\n",
            "======================================================================\n",
            "\n",
            "\n",
            "--- Fold 1/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6314 - sparse_categorical_accuracy: 0.7041"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.6336 - sparse_categorical_accuracy: 0.7052 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6167 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6167 - sparse_categorical_accuracy: 0.7281"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6152 - sparse_categorical_accuracy: 0.7253 - val_loss: 0.6619 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5691 - sparse_categorical_accuracy: 0.7363"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5715 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.6427 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5963 - sparse_categorical_accuracy: 0.7523"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5960 - sparse_categorical_accuracy: 0.7470 - val_loss: 0.6329 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5587 - sparse_categorical_accuracy: 0.7525"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5596 - sparse_categorical_accuracy: 0.7508 - val_loss: 0.6327 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5532 - sparse_categorical_accuracy: 0.7668 - val_loss: 0.6341 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5801 - sparse_categorical_accuracy: 0.7579 - val_loss: 0.6334 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5594 - sparse_categorical_accuracy: 0.7322 - val_loss: 0.6377 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5596 - sparse_categorical_accuracy: 0.7535 - val_loss: 0.6460 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5684 - sparse_categorical_accuracy: 0.7441\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5688 - sparse_categorical_accuracy: 0.7428 - val_loss: 0.6531 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5437 - sparse_categorical_accuracy: 0.7516 - val_loss: 0.6606 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5606 - sparse_categorical_accuracy: 0.7637 - val_loss: 0.6678 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.5488 - sparse_categorical_accuracy: 0.7466 - val_loss: 0.6700 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5631 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.6747 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5454 - sparse_categorical_accuracy: 0.7664\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5501 - sparse_categorical_accuracy: 0.7595 - val_loss: 0.6833 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5351 - sparse_categorical_accuracy: 0.7514 - val_loss: 0.6880 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5310 - sparse_categorical_accuracy: 0.7595 - val_loss: 0.6923 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5299 - sparse_categorical_accuracy: 0.7618 - val_loss: 0.6951 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5469 - sparse_categorical_accuracy: 0.7467 - val_loss: 0.6970 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5330 - sparse_categorical_accuracy: 0.7554\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5411 - sparse_categorical_accuracy: 0.7493 - val_loss: 0.6991 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "  Test Accuracy: 61.11%\n",
            "  Test Precision (weighted): 37.35%\n",
            "  Test Recall (weighted): 61.11%\n",
            "  Test F1-Score (weighted): 46.36%\n",
            "\n",
            "--- Fold 2/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.7123 - sparse_categorical_accuracy: 0.6331"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 0.7122 - sparse_categorical_accuracy: 0.6351 - val_loss: 0.6537 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6411 - sparse_categorical_accuracy: 0.7090 - val_loss: 0.6559 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6262 - sparse_categorical_accuracy: 0.7029"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6242 - sparse_categorical_accuracy: 0.7023 - val_loss: 0.6440 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5918 - sparse_categorical_accuracy: 0.7143"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5917 - sparse_categorical_accuracy: 0.7116 - val_loss: 0.6347 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5777 - sparse_categorical_accuracy: 0.7400"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5836 - sparse_categorical_accuracy: 0.7382 - val_loss: 0.6322 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6019 - sparse_categorical_accuracy: 0.7073"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6024 - sparse_categorical_accuracy: 0.7077 - val_loss: 0.6308 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5761 - sparse_categorical_accuracy: 0.7040 - val_loss: 0.6310 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5854 - sparse_categorical_accuracy: 0.7355 - val_loss: 0.6375 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5960 - sparse_categorical_accuracy: 0.7240 - val_loss: 0.6403 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5916 - sparse_categorical_accuracy: 0.7250 - val_loss: 0.6451 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5748 - sparse_categorical_accuracy: 0.7394\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5742 - sparse_categorical_accuracy: 0.7372 - val_loss: 0.6549 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5611 - sparse_categorical_accuracy: 0.7347 - val_loss: 0.6626 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5691 - sparse_categorical_accuracy: 0.7300 - val_loss: 0.6719 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5820 - sparse_categorical_accuracy: 0.7108 - val_loss: 0.6791 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5729 - sparse_categorical_accuracy: 0.7416 - val_loss: 0.6893 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5466 - sparse_categorical_accuracy: 0.7448\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5478 - sparse_categorical_accuracy: 0.7422 - val_loss: 0.6988 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5728 - sparse_categorical_accuracy: 0.7475 - val_loss: 0.7051 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5653 - sparse_categorical_accuracy: 0.7359 - val_loss: 0.7088 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5656 - sparse_categorical_accuracy: 0.7274 - val_loss: 0.7156 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5602 - sparse_categorical_accuracy: 0.7427 - val_loss: 0.7211 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5466 - sparse_categorical_accuracy: 0.7201\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5458 - sparse_categorical_accuracy: 0.7186 - val_loss: 0.7274 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "  Test Accuracy: 77.78%\n",
            "  Test Precision (weighted): 60.49%\n",
            "  Test Recall (weighted): 77.78%\n",
            "  Test F1-Score (weighted): 68.06%\n",
            "\n",
            "--- Fold 3/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7565 - sparse_categorical_accuracy: 0.4532"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.7390 - sparse_categorical_accuracy: 0.4846 - val_loss: 0.6578 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6209 - sparse_categorical_accuracy: 0.7158"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6225 - sparse_categorical_accuracy: 0.7140 - val_loss: 0.6436 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5871 - sparse_categorical_accuracy: 0.7350"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5860 - sparse_categorical_accuracy: 0.7340 - val_loss: 0.6401 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5901 - sparse_categorical_accuracy: 0.7501"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5912 - sparse_categorical_accuracy: 0.7453 - val_loss: 0.6377 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5759 - sparse_categorical_accuracy: 0.7196"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5745 - sparse_categorical_accuracy: 0.7202 - val_loss: 0.6335 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6101 - sparse_categorical_accuracy: 0.7303 - val_loss: 0.6355 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5831 - sparse_categorical_accuracy: 0.7371 - val_loss: 0.6364 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6110 - sparse_categorical_accuracy: 0.7325 - val_loss: 0.6430 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5792 - sparse_categorical_accuracy: 0.7434 - val_loss: 0.6497 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5782 - sparse_categorical_accuracy: 0.7412\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5762 - sparse_categorical_accuracy: 0.7386 - val_loss: 0.6577 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5729 - sparse_categorical_accuracy: 0.7478 - val_loss: 0.6657 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5793 - sparse_categorical_accuracy: 0.7435 - val_loss: 0.6714 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5681 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.6758 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5548 - sparse_categorical_accuracy: 0.7485 - val_loss: 0.6806 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6053 - sparse_categorical_accuracy: 0.7389\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5987 - sparse_categorical_accuracy: 0.7379 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5503 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.6948 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5604 - sparse_categorical_accuracy: 0.7394 - val_loss: 0.7038 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5621 - sparse_categorical_accuracy: 0.7436 - val_loss: 0.7028 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5508 - sparse_categorical_accuracy: 0.7338 - val_loss: 0.7073 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5646 - sparse_categorical_accuracy: 0.7494\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5626 - sparse_categorical_accuracy: 0.7485 - val_loss: 0.7129 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "  Test Accuracy: 61.11%\n",
            "  Test Precision (weighted): 37.35%\n",
            "  Test Recall (weighted): 61.11%\n",
            "  Test F1-Score (weighted): 46.36%\n",
            "\n",
            "--- Fold 4/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7111 - sparse_categorical_accuracy: 0.5658"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - loss: 0.7050 - sparse_categorical_accuracy: 0.5841 - val_loss: 0.6450 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6658 - sparse_categorical_accuracy: 0.7123 - val_loss: 0.6470 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5903 - sparse_categorical_accuracy: 0.7268"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5918 - sparse_categorical_accuracy: 0.7255 - val_loss: 0.6447 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5793 - sparse_categorical_accuracy: 0.7381"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5792 - sparse_categorical_accuracy: 0.7351 - val_loss: 0.6327 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5725 - sparse_categorical_accuracy: 0.7494"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5788 - sparse_categorical_accuracy: 0.7455 - val_loss: 0.6250 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5731 - sparse_categorical_accuracy: 0.7284"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5750 - sparse_categorical_accuracy: 0.7277 - val_loss: 0.6236 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5850 - sparse_categorical_accuracy: 0.7256"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5843 - sparse_categorical_accuracy: 0.7257 - val_loss: 0.6214 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5635 - sparse_categorical_accuracy: 0.7282"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5680 - sparse_categorical_accuracy: 0.7259 - val_loss: 0.6209 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5804 - sparse_categorical_accuracy: 0.7305 - val_loss: 0.6243 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5789 - sparse_categorical_accuracy: 0.7242 - val_loss: 0.6271 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5909 - sparse_categorical_accuracy: 0.7270 - val_loss: 0.6270 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5786 - sparse_categorical_accuracy: 0.7430 - val_loss: 0.6283 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5585 - sparse_categorical_accuracy: 0.7507\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5598 - sparse_categorical_accuracy: 0.7501 - val_loss: 0.6327 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5885 - sparse_categorical_accuracy: 0.7418 - val_loss: 0.6358 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.5704 - sparse_categorical_accuracy: 0.7377 - val_loss: 0.6446 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5946 - sparse_categorical_accuracy: 0.7417 - val_loss: 0.6451 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5561 - sparse_categorical_accuracy: 0.7442 - val_loss: 0.6475 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5363 - sparse_categorical_accuracy: 0.7568\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5390 - sparse_categorical_accuracy: 0.7551 - val_loss: 0.6544 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5569 - sparse_categorical_accuracy: 0.7439 - val_loss: 0.6534 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5991 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.6467 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5371 - sparse_categorical_accuracy: 0.7440 - val_loss: 0.6460 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5522 - sparse_categorical_accuracy: 0.7561 - val_loss: 0.6511 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5606 - sparse_categorical_accuracy: 0.7546\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.5604 - sparse_categorical_accuracy: 0.7537 - val_loss: 0.6536 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 23: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "  Test Accuracy: 66.67%\n",
            "  Test Precision (weighted): 44.44%\n",
            "  Test Recall (weighted): 66.67%\n",
            "  Test F1-Score (weighted): 53.33%\n",
            "\n",
            "--- Fold 5/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.7734 - sparse_categorical_accuracy: 0.4414"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.7624 - sparse_categorical_accuracy: 0.4586 - val_loss: 0.6612 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6188 - sparse_categorical_accuracy: 0.7341"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6187 - sparse_categorical_accuracy: 0.7327 - val_loss: 0.6439 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5637 - sparse_categorical_accuracy: 0.7454"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5664 - sparse_categorical_accuracy: 0.7413 - val_loss: 0.6355 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5675 - sparse_categorical_accuracy: 0.7334"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5696 - sparse_categorical_accuracy: 0.7333 - val_loss: 0.6283 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5754 - sparse_categorical_accuracy: 0.7505"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5779 - sparse_categorical_accuracy: 0.7469 - val_loss: 0.6256 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5940 - sparse_categorical_accuracy: 0.7310 - val_loss: 0.6279 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5824 - sparse_categorical_accuracy: 0.7366 - val_loss: 0.6333 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5734 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.6492 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5802 - sparse_categorical_accuracy: 0.7247 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5567 - sparse_categorical_accuracy: 0.7345\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5566 - sparse_categorical_accuracy: 0.7326 - val_loss: 0.6921 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5755 - sparse_categorical_accuracy: 0.7449 - val_loss: 0.6980 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5664 - sparse_categorical_accuracy: 0.7485 - val_loss: 0.7037 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5675 - sparse_categorical_accuracy: 0.7399 - val_loss: 0.7020 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5570 - sparse_categorical_accuracy: 0.7423 - val_loss: 0.7103 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5649 - sparse_categorical_accuracy: 0.7378\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5667 - sparse_categorical_accuracy: 0.7375 - val_loss: 0.7116 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5587 - sparse_categorical_accuracy: 0.7448 - val_loss: 0.7192 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5578 - sparse_categorical_accuracy: 0.7512 - val_loss: 0.7306 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5503 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.7380 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5958 - sparse_categorical_accuracy: 0.7298 - val_loss: 0.7409 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5529 - sparse_categorical_accuracy: 0.7482\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5532 - sparse_categorical_accuracy: 0.7459 - val_loss: 0.7468 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "  Test Accuracy: 72.22%\n",
            "  Test Precision (weighted): 52.16%\n",
            "  Test Recall (weighted): 72.22%\n",
            "  Test F1-Score (weighted): 60.57%\n",
            "\n",
            "--- Fold 6/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6349 - sparse_categorical_accuracy: 0.6748"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - loss: 0.6400 - sparse_categorical_accuracy: 0.6754 - val_loss: 0.6402 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6027 - sparse_categorical_accuracy: 0.7103 - val_loss: 0.6510 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6085 - sparse_categorical_accuracy: 0.7199 - val_loss: 0.6455 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6040 - sparse_categorical_accuracy: 0.7234"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6046 - sparse_categorical_accuracy: 0.7163 - val_loss: 0.6364 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5922 - sparse_categorical_accuracy: 0.7174"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5927 - sparse_categorical_accuracy: 0.7159 - val_loss: 0.6321 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6149 - sparse_categorical_accuracy: 0.7280"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.6152 - sparse_categorical_accuracy: 0.7262 - val_loss: 0.6291 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6117 - sparse_categorical_accuracy: 0.7338"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.6123 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.6286 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6067 - sparse_categorical_accuracy: 0.7195"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.6060 - sparse_categorical_accuracy: 0.7196 - val_loss: 0.6269 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5780 - sparse_categorical_accuracy: 0.7413"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.5807 - sparse_categorical_accuracy: 0.7377 - val_loss: 0.6262 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5762 - sparse_categorical_accuracy: 0.7477 - val_loss: 0.6279 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5729 - sparse_categorical_accuracy: 0.7189 - val_loss: 0.6292 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5853 - sparse_categorical_accuracy: 0.7256 - val_loss: 0.6342 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5643 - sparse_categorical_accuracy: 0.7419 - val_loss: 0.6334 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5555 - sparse_categorical_accuracy: 0.7333\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5626 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.6349 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5669 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.6359 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5842 - sparse_categorical_accuracy: 0.7322 - val_loss: 0.6381 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5526 - sparse_categorical_accuracy: 0.7341 - val_loss: 0.6385 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5856 - sparse_categorical_accuracy: 0.7217 - val_loss: 0.6376 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5577 - sparse_categorical_accuracy: 0.7180\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5570 - sparse_categorical_accuracy: 0.7142 - val_loss: 0.6355 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5663 - sparse_categorical_accuracy: 0.7521 - val_loss: 0.6371 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5694 - sparse_categorical_accuracy: 0.7336 - val_loss: 0.6367 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5502 - sparse_categorical_accuracy: 0.7428 - val_loss: 0.6356 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5761 - sparse_categorical_accuracy: 0.7381 - val_loss: 0.6386 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5777 - sparse_categorical_accuracy: 0.7350\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5769 - sparse_categorical_accuracy: 0.7301 - val_loss: 0.6380 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 24: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "  Test Accuracy: 94.44%\n",
            "  Test Precision (weighted): 89.20%\n",
            "  Test Recall (weighted): 94.44%\n",
            "  Test F1-Score (weighted): 91.75%\n",
            "\n",
            "--- Fold 7/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6960 - sparse_categorical_accuracy: 0.6038"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.6945 - sparse_categorical_accuracy: 0.6108 - val_loss: 0.6420 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6051 - sparse_categorical_accuracy: 0.7316"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6063 - sparse_categorical_accuracy: 0.7297 - val_loss: 0.6384 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5788 - sparse_categorical_accuracy: 0.7422"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5893 - sparse_categorical_accuracy: 0.7321 - val_loss: 0.6362 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6076 - sparse_categorical_accuracy: 0.7133"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6089 - sparse_categorical_accuracy: 0.7122 - val_loss: 0.6310 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5708 - sparse_categorical_accuracy: 0.7351"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5729 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.6280 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5921 - sparse_categorical_accuracy: 0.7378"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5962 - sparse_categorical_accuracy: 0.7318 - val_loss: 0.6269 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5711 - sparse_categorical_accuracy: 0.7314 - val_loss: 0.6296 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5920 - sparse_categorical_accuracy: 0.7416 - val_loss: 0.6331 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.5778 - sparse_categorical_accuracy: 0.7245 - val_loss: 0.6343 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5874 - sparse_categorical_accuracy: 0.7422 - val_loss: 0.6403 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5634 - sparse_categorical_accuracy: 0.7477\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5644 - sparse_categorical_accuracy: 0.7455 - val_loss: 0.6431 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5816 - sparse_categorical_accuracy: 0.7466 - val_loss: 0.6451 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5644 - sparse_categorical_accuracy: 0.7427 - val_loss: 0.6437 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5707 - sparse_categorical_accuracy: 0.7420 - val_loss: 0.6461 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5688 - sparse_categorical_accuracy: 0.7443 - val_loss: 0.6494 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5327 - sparse_categorical_accuracy: 0.7482\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5369 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6569 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5577 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.6593 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5800 - sparse_categorical_accuracy: 0.7427 - val_loss: 0.6585 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5767 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.6570 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5878 - sparse_categorical_accuracy: 0.7356 - val_loss: 0.6580 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5381 - sparse_categorical_accuracy: 0.7454\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5453 - sparse_categorical_accuracy: 0.7379 - val_loss: 0.6611 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "  Test Accuracy: 88.89%\n",
            "  Test Precision (weighted): 79.01%\n",
            "  Test Recall (weighted): 88.89%\n",
            "  Test F1-Score (weighted): 83.66%\n",
            "\n",
            "--- Fold 8/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.7157 - sparse_categorical_accuracy: 0.5348"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.6961 - sparse_categorical_accuracy: 0.5651 - val_loss: 0.6385 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5653 - sparse_categorical_accuracy: 0.7541"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.5715 - sparse_categorical_accuracy: 0.7494 - val_loss: 0.6358 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6037 - sparse_categorical_accuracy: 0.7255 - val_loss: 0.6375 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5984 - sparse_categorical_accuracy: 0.7475"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6050 - sparse_categorical_accuracy: 0.7385 - val_loss: 0.6301 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5676 - sparse_categorical_accuracy: 0.7315"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5697 - sparse_categorical_accuracy: 0.7301 - val_loss: 0.6256 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5781 - sparse_categorical_accuracy: 0.7496"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5805 - sparse_categorical_accuracy: 0.7474 - val_loss: 0.6229 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5720 - sparse_categorical_accuracy: 0.7432 - val_loss: 0.6242 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5634 - sparse_categorical_accuracy: 0.7435 - val_loss: 0.6270 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5631 - sparse_categorical_accuracy: 0.7495 - val_loss: 0.6320 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5705 - sparse_categorical_accuracy: 0.7434 - val_loss: 0.6336 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5689 - sparse_categorical_accuracy: 0.7385\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5739 - sparse_categorical_accuracy: 0.7346 - val_loss: 0.6302 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5680 - sparse_categorical_accuracy: 0.7330 - val_loss: 0.6317 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5537 - sparse_categorical_accuracy: 0.7381 - val_loss: 0.6374 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5590 - sparse_categorical_accuracy: 0.7497 - val_loss: 0.6418 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5714 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.6474 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7535\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5518 - sparse_categorical_accuracy: 0.7484 - val_loss: 0.6527 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.5689 - sparse_categorical_accuracy: 0.7458 - val_loss: 0.6534 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5703 - sparse_categorical_accuracy: 0.7505 - val_loss: 0.6568 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5452 - sparse_categorical_accuracy: 0.7583 - val_loss: 0.6596 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5494 - sparse_categorical_accuracy: 0.7403 - val_loss: 0.6620 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5526 - sparse_categorical_accuracy: 0.7467\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5546 - sparse_categorical_accuracy: 0.7443 - val_loss: 0.6636 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "  Test Accuracy: 66.67%\n",
            "  Test Precision (weighted): 44.44%\n",
            "  Test Recall (weighted): 66.67%\n",
            "  Test F1-Score (weighted): 53.33%\n",
            "\n",
            "--- Fold 9/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6752 - sparse_categorical_accuracy: 0.6239"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.6768 - sparse_categorical_accuracy: 0.6250 - val_loss: 0.6517 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5798 - sparse_categorical_accuracy: 0.7348"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.5860 - sparse_categorical_accuracy: 0.7275 - val_loss: 0.6505 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5999 - sparse_categorical_accuracy: 0.7162"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6079 - sparse_categorical_accuracy: 0.7043 - val_loss: 0.6406 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5916 - sparse_categorical_accuracy: 0.7162"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.5973 - sparse_categorical_accuracy: 0.7151 - val_loss: 0.6328 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.6227 - sparse_categorical_accuracy: 0.7129 - val_loss: 0.6338 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5991 - sparse_categorical_accuracy: 0.7337"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6029 - sparse_categorical_accuracy: 0.7259 - val_loss: 0.6301 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5913 - sparse_categorical_accuracy: 0.7277 - val_loss: 0.6302 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5927 - sparse_categorical_accuracy: 0.7320 - val_loss: 0.6349 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5818 - sparse_categorical_accuracy: 0.7374 - val_loss: 0.6355 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5649 - sparse_categorical_accuracy: 0.7368 - val_loss: 0.6412 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5939 - sparse_categorical_accuracy: 0.7299\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5941 - sparse_categorical_accuracy: 0.7278 - val_loss: 0.6408 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5924 - sparse_categorical_accuracy: 0.7205 - val_loss: 0.6468 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5771 - sparse_categorical_accuracy: 0.7258 - val_loss: 0.6530 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6063 - sparse_categorical_accuracy: 0.7273 - val_loss: 0.6559 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5750 - sparse_categorical_accuracy: 0.7311 - val_loss: 0.6559 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5844 - sparse_categorical_accuracy: 0.7229\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.5853 - sparse_categorical_accuracy: 0.7209 - val_loss: 0.6610 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.5821 - sparse_categorical_accuracy: 0.7296 - val_loss: 0.6649 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5913 - sparse_categorical_accuracy: 0.7209 - val_loss: 0.6669 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5829 - sparse_categorical_accuracy: 0.7287 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6140 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.6727 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5718 - sparse_categorical_accuracy: 0.7367\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5728 - sparse_categorical_accuracy: 0.7305 - val_loss: 0.6782 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "  Test Accuracy: 94.44%\n",
            "  Test Precision (weighted): 89.20%\n",
            "  Test Recall (weighted): 94.44%\n",
            "  Test F1-Score (weighted): 91.75%\n",
            "\n",
            "--- Fold 10/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6445 - sparse_categorical_accuracy: 0.7427"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.6482 - sparse_categorical_accuracy: 0.7392 - val_loss: 0.6457 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5787 - sparse_categorical_accuracy: 0.7518 - val_loss: 0.6494 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5726 - sparse_categorical_accuracy: 0.7399"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5765 - sparse_categorical_accuracy: 0.7371 - val_loss: 0.6385 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5585 - sparse_categorical_accuracy: 0.7381"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5678 - sparse_categorical_accuracy: 0.7328 - val_loss: 0.6310 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5737 - sparse_categorical_accuracy: 0.7537"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5848 - sparse_categorical_accuracy: 0.7460 - val_loss: 0.6291 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5520 - sparse_categorical_accuracy: 0.7616"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5539 - sparse_categorical_accuracy: 0.7575 - val_loss: 0.6224 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5574 - sparse_categorical_accuracy: 0.7620 - val_loss: 0.6248 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5538 - sparse_categorical_accuracy: 0.7670 - val_loss: 0.6261 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5394 - sparse_categorical_accuracy: 0.7642 - val_loss: 0.6342 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5464 - sparse_categorical_accuracy: 0.7571 - val_loss: 0.6507 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5502 - sparse_categorical_accuracy: 0.7751\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5561 - sparse_categorical_accuracy: 0.7653 - val_loss: 0.6660 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5307 - sparse_categorical_accuracy: 0.7641 - val_loss: 0.6755 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5479 - sparse_categorical_accuracy: 0.7576 - val_loss: 0.6765 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5426 - sparse_categorical_accuracy: 0.7624 - val_loss: 0.6771 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5465 - sparse_categorical_accuracy: 0.7596 - val_loss: 0.6799 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5375 - sparse_categorical_accuracy: 0.7608\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5410 - sparse_categorical_accuracy: 0.7558 - val_loss: 0.6940 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5291 - sparse_categorical_accuracy: 0.7651 - val_loss: 0.7049 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5477 - sparse_categorical_accuracy: 0.7609 - val_loss: 0.7090 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5398 - sparse_categorical_accuracy: 0.7699 - val_loss: 0.7089 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5415 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.7084 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5389 - sparse_categorical_accuracy: 0.7636\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5395 - sparse_categorical_accuracy: 0.7617 - val_loss: 0.7136 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "  Test Accuracy: 50.00%\n",
            "  Test Precision (weighted): 25.00%\n",
            "  Test Recall (weighted): 50.00%\n",
            "  Test F1-Score (weighted): 33.33%\n",
            "\n",
            "--- Fold 11/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7758 - sparse_categorical_accuracy: 0.4823"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - loss: 0.7672 - sparse_categorical_accuracy: 0.4917 - val_loss: 0.6619 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6508 - sparse_categorical_accuracy: 0.7265"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.6544 - sparse_categorical_accuracy: 0.7230 - val_loss: 0.6522 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5768 - sparse_categorical_accuracy: 0.7618"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5786 - sparse_categorical_accuracy: 0.7590 - val_loss: 0.6437 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5848 - sparse_categorical_accuracy: 0.7053"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5847 - sparse_categorical_accuracy: 0.7055 - val_loss: 0.6305 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5404 - sparse_categorical_accuracy: 0.7437"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5423 - sparse_categorical_accuracy: 0.7423 - val_loss: 0.6266 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5555 - sparse_categorical_accuracy: 0.7443 - val_loss: 0.6281 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5891 - sparse_categorical_accuracy: 0.7445 - val_loss: 0.6305 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5592 - sparse_categorical_accuracy: 0.7433 - val_loss: 0.6381 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5934 - sparse_categorical_accuracy: 0.7335 - val_loss: 0.6484 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5834 - sparse_categorical_accuracy: 0.7412\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5823 - sparse_categorical_accuracy: 0.7382 - val_loss: 0.6569 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5630 - sparse_categorical_accuracy: 0.7473 - val_loss: 0.6659 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5889 - sparse_categorical_accuracy: 0.7507 - val_loss: 0.6664 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5608 - sparse_categorical_accuracy: 0.7359 - val_loss: 0.6710 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5848 - sparse_categorical_accuracy: 0.7354 - val_loss: 0.6775 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5408 - sparse_categorical_accuracy: 0.7720\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5451 - sparse_categorical_accuracy: 0.7650 - val_loss: 0.6911 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5536 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.6992 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5676 - sparse_categorical_accuracy: 0.7254 - val_loss: 0.7040 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5708 - sparse_categorical_accuracy: 0.7454 - val_loss: 0.7078 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5521 - sparse_categorical_accuracy: 0.7385 - val_loss: 0.7130 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5573 - sparse_categorical_accuracy: 0.7340\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5588 - sparse_categorical_accuracy: 0.7312 - val_loss: 0.7171 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "  Test Accuracy: 66.67%\n",
            "  Test Precision (weighted): 44.44%\n",
            "  Test Recall (weighted): 66.67%\n",
            "  Test F1-Score (weighted): 53.33%\n",
            "\n",
            "--- Fold 12/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6462 - sparse_categorical_accuracy: 0.6687"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - loss: 0.6505 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6502 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5823 - sparse_categorical_accuracy: 0.7411"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5940 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.6416 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5798 - sparse_categorical_accuracy: 0.7559"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5836 - sparse_categorical_accuracy: 0.7524 - val_loss: 0.6301 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5558 - sparse_categorical_accuracy: 0.7349"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5643 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.6242 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5765 - sparse_categorical_accuracy: 0.7618"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5874 - sparse_categorical_accuracy: 0.7491 - val_loss: 0.6215 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5860 - sparse_categorical_accuracy: 0.7421"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5941 - sparse_categorical_accuracy: 0.7352 - val_loss: 0.6199 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5449 - sparse_categorical_accuracy: 0.7481 - val_loss: 0.6217 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5900 - sparse_categorical_accuracy: 0.7453 - val_loss: 0.6245 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5864 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.6279 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5698 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6347 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5422 - sparse_categorical_accuracy: 0.7557\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5528 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.6407 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5671 - sparse_categorical_accuracy: 0.7460 - val_loss: 0.6456 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5574 - sparse_categorical_accuracy: 0.7490 - val_loss: 0.6583 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5895 - sparse_categorical_accuracy: 0.7443 - val_loss: 0.6636 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5955 - sparse_categorical_accuracy: 0.7351 - val_loss: 0.6650 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5644 - sparse_categorical_accuracy: 0.7447\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5656 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.6695 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5811 - sparse_categorical_accuracy: 0.7447 - val_loss: 0.6693 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5669 - sparse_categorical_accuracy: 0.7293 - val_loss: 0.6677 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5432 - sparse_categorical_accuracy: 0.7569 - val_loss: 0.6666 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5756 - sparse_categorical_accuracy: 0.7283 - val_loss: 0.6652 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5488 - sparse_categorical_accuracy: 0.7381\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5547 - sparse_categorical_accuracy: 0.7327 - val_loss: 0.6675 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "  Test Accuracy: 77.78%\n",
            "  Test Precision (weighted): 60.49%\n",
            "  Test Recall (weighted): 77.78%\n",
            "  Test F1-Score (weighted): 68.06%\n",
            "\n",
            "--- Fold 13/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6855 - sparse_categorical_accuracy: 0.6598"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - loss: 0.6841 - sparse_categorical_accuracy: 0.6599 - val_loss: 0.6694 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6070 - sparse_categorical_accuracy: 0.7524"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6097 - sparse_categorical_accuracy: 0.7458 - val_loss: 0.6646 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5901 - sparse_categorical_accuracy: 0.7436"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5952 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.6512 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5747 - sparse_categorical_accuracy: 0.7364"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5849 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.6308 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5920 - sparse_categorical_accuracy: 0.7229"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5976 - sparse_categorical_accuracy: 0.7173 - val_loss: 0.6265 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5603 - sparse_categorical_accuracy: 0.7253"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5623 - sparse_categorical_accuracy: 0.7236 - val_loss: 0.6259 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5442 - sparse_categorical_accuracy: 0.7564 - val_loss: 0.6366 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5781 - sparse_categorical_accuracy: 0.7385 - val_loss: 0.6482 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5647 - sparse_categorical_accuracy: 0.7453 - val_loss: 0.6644 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6009 - sparse_categorical_accuracy: 0.7283 - val_loss: 0.6753 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5743 - sparse_categorical_accuracy: 0.7451\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5810 - sparse_categorical_accuracy: 0.7372 - val_loss: 0.6795 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5725 - sparse_categorical_accuracy: 0.7312 - val_loss: 0.6859 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5499 - sparse_categorical_accuracy: 0.7558 - val_loss: 0.6970 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5618 - sparse_categorical_accuracy: 0.7283 - val_loss: 0.7108 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5293 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.7326 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5525 - sparse_categorical_accuracy: 0.7552\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5539 - sparse_categorical_accuracy: 0.7525 - val_loss: 0.7496 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5603 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.7634 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5278 - sparse_categorical_accuracy: 0.7507 - val_loss: 0.7770 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5675 - sparse_categorical_accuracy: 0.7400 - val_loss: 0.7754 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5489 - sparse_categorical_accuracy: 0.7469 - val_loss: 0.7704 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5442 - sparse_categorical_accuracy: 0.7522\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.7405 - val_loss: 0.7719 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "  Test Accuracy: 88.89%\n",
            "  Test Precision (weighted): 79.01%\n",
            "  Test Recall (weighted): 88.89%\n",
            "  Test F1-Score (weighted): 83.66%\n",
            "\n",
            "--- Fold 14/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7542 - sparse_categorical_accuracy: 0.5111"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 0.7369 - sparse_categorical_accuracy: 0.5388 - val_loss: 0.6422 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6122 - sparse_categorical_accuracy: 0.7278"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6156 - sparse_categorical_accuracy: 0.7250 - val_loss: 0.6413 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5897 - sparse_categorical_accuracy: 0.6996 - val_loss: 0.6416 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6220 - sparse_categorical_accuracy: 0.7165"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.6219 - sparse_categorical_accuracy: 0.7153 - val_loss: 0.6376 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6082 - sparse_categorical_accuracy: 0.7214"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.6078 - sparse_categorical_accuracy: 0.7177 - val_loss: 0.6301 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5785 - sparse_categorical_accuracy: 0.7504"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.5783 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.6257 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5704 - sparse_categorical_accuracy: 0.7417"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.5776 - sparse_categorical_accuracy: 0.7374 - val_loss: 0.6253 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5992 - sparse_categorical_accuracy: 0.7407 - val_loss: 0.6262 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5551 - sparse_categorical_accuracy: 0.7557 - val_loss: 0.6269 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5421 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6291 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5622 - sparse_categorical_accuracy: 0.7373 - val_loss: 0.6314 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5936 - sparse_categorical_accuracy: 0.7643\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5931 - sparse_categorical_accuracy: 0.7624 - val_loss: 0.6317 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5558 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.6327 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5451 - sparse_categorical_accuracy: 0.7654 - val_loss: 0.6352 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5353 - sparse_categorical_accuracy: 0.7550 - val_loss: 0.6408 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5559 - sparse_categorical_accuracy: 0.7507 - val_loss: 0.6494 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5187 - sparse_categorical_accuracy: 0.7760\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5209 - sparse_categorical_accuracy: 0.7734 - val_loss: 0.6536 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5651 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.6474 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5476 - sparse_categorical_accuracy: 0.7619 - val_loss: 0.6485 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5464 - sparse_categorical_accuracy: 0.7416 - val_loss: 0.6524 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5477 - sparse_categorical_accuracy: 0.7653 - val_loss: 0.6545 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5188 - sparse_categorical_accuracy: 0.7537\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5256 - sparse_categorical_accuracy: 0.7473 - val_loss: 0.6582 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 22: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "  Test Accuracy: 55.56%\n",
            "  Test Precision (weighted): 30.86%\n",
            "  Test Recall (weighted): 55.56%\n",
            "  Test F1-Score (weighted): 39.68%\n",
            "\n",
            "--- Fold 15/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7187 - sparse_categorical_accuracy: 0.5236"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - loss: 0.7114 - sparse_categorical_accuracy: 0.5441 - val_loss: 0.6557 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6339 - sparse_categorical_accuracy: 0.6899"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6348 - sparse_categorical_accuracy: 0.6890 - val_loss: 0.6455 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5912 - sparse_categorical_accuracy: 0.7156"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5956 - sparse_categorical_accuracy: 0.7212 - val_loss: 0.6389 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5808 - sparse_categorical_accuracy: 0.7453"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5855 - sparse_categorical_accuracy: 0.7389 - val_loss: 0.6299 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5752 - sparse_categorical_accuracy: 0.7207"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5812 - sparse_categorical_accuracy: 0.7179 - val_loss: 0.6264 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5640 - sparse_categorical_accuracy: 0.7308"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5657 - sparse_categorical_accuracy: 0.7297 - val_loss: 0.6263 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.5904 - sparse_categorical_accuracy: 0.7557 - val_loss: 0.6273 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5877 - sparse_categorical_accuracy: 0.7493 - val_loss: 0.6310 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5776 - sparse_categorical_accuracy: 0.7376 - val_loss: 0.6375 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5479 - sparse_categorical_accuracy: 0.7486\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.5498 - sparse_categorical_accuracy: 0.7468 - val_loss: 0.6461 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.5381 - sparse_categorical_accuracy: 0.7517 - val_loss: 0.6590 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5693 - sparse_categorical_accuracy: 0.7368 - val_loss: 0.6675 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5629 - sparse_categorical_accuracy: 0.7489 - val_loss: 0.6729 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5638 - sparse_categorical_accuracy: 0.7456 - val_loss: 0.6700 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5627 - sparse_categorical_accuracy: 0.7544\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5692 - sparse_categorical_accuracy: 0.7435 - val_loss: 0.6698 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5531 - sparse_categorical_accuracy: 0.7394 - val_loss: 0.6741 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5463 - sparse_categorical_accuracy: 0.7672 - val_loss: 0.6801 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5461 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.6869 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5326 - sparse_categorical_accuracy: 0.7494 - val_loss: 0.6913 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5410 - sparse_categorical_accuracy: 0.7570\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5475 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6936 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5504 - sparse_categorical_accuracy: 0.7391 - val_loss: 0.6965 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 1.2500e-04\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "  Test Accuracy: 72.22%\n",
            "  Test Precision (weighted): 52.16%\n",
            "  Test Recall (weighted): 72.22%\n",
            "  Test F1-Score (weighted): 60.57%\n",
            "\n",
            "--- Fold 16/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6413 - sparse_categorical_accuracy: 0.6878"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.6433 - sparse_categorical_accuracy: 0.6915 - val_loss: 0.6726 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5712 - sparse_categorical_accuracy: 0.7496"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5793 - sparse_categorical_accuracy: 0.7439 - val_loss: 0.6597 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5575 - sparse_categorical_accuracy: 0.7530"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5675 - sparse_categorical_accuracy: 0.7424 - val_loss: 0.6356 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5520 - sparse_categorical_accuracy: 0.7754"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5672 - sparse_categorical_accuracy: 0.7643 - val_loss: 0.6284 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5595 - sparse_categorical_accuracy: 0.7406"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5674 - sparse_categorical_accuracy: 0.7336 - val_loss: 0.6241 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5689 - sparse_categorical_accuracy: 0.7546 - val_loss: 0.6249 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5341 - sparse_categorical_accuracy: 0.7406 - val_loss: 0.6315 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5681 - sparse_categorical_accuracy: 0.7376 - val_loss: 0.6404 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5762 - sparse_categorical_accuracy: 0.7469 - val_loss: 0.6431 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5554 - sparse_categorical_accuracy: 0.7620\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5602 - sparse_categorical_accuracy: 0.7557 - val_loss: 0.6440 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5479 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.6486 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5815 - sparse_categorical_accuracy: 0.7569 - val_loss: 0.6551 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5603 - sparse_categorical_accuracy: 0.7569 - val_loss: 0.6610 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5628 - sparse_categorical_accuracy: 0.7550 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5516 - sparse_categorical_accuracy: 0.7653\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5520 - sparse_categorical_accuracy: 0.7633 - val_loss: 0.6890 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5470 - sparse_categorical_accuracy: 0.7616 - val_loss: 0.6941 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5397 - sparse_categorical_accuracy: 0.7443 - val_loss: 0.6935 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.5271 - sparse_categorical_accuracy: 0.7510 - val_loss: 0.6950 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.5245 - sparse_categorical_accuracy: 0.7599 - val_loss: 0.6935 - val_sparse_categorical_accuracy: 0.6667 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5392 - sparse_categorical_accuracy: 0.7594\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5394 - sparse_categorical_accuracy: 0.7537 - val_loss: 0.6946 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "  Test Accuracy: 61.11%\n",
            "  Test Precision (weighted): 37.35%\n",
            "  Test Recall (weighted): 61.11%\n",
            "  Test F1-Score (weighted): 46.36%\n",
            "\n",
            "--- Fold 17/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6530 - sparse_categorical_accuracy: 0.6741"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 0.6588 - sparse_categorical_accuracy: 0.6721 - val_loss: 0.6695 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6080 - sparse_categorical_accuracy: 0.6998"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6109 - sparse_categorical_accuracy: 0.7007 - val_loss: 0.6687 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5590 - sparse_categorical_accuracy: 0.7747"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5607 - sparse_categorical_accuracy: 0.7729 - val_loss: 0.6480 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5890 - sparse_categorical_accuracy: 0.7153"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5956 - sparse_categorical_accuracy: 0.7143 - val_loss: 0.6416 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5535 - sparse_categorical_accuracy: 0.7299"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5617 - sparse_categorical_accuracy: 0.7259 - val_loss: 0.6319 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5896 - sparse_categorical_accuracy: 0.7452"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5912 - sparse_categorical_accuracy: 0.7380 - val_loss: 0.6266 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5642 - sparse_categorical_accuracy: 0.7523"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5695 - sparse_categorical_accuracy: 0.7474 - val_loss: 0.6266 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.6025 - sparse_categorical_accuracy: 0.7341 - val_loss: 0.6317 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5837 - sparse_categorical_accuracy: 0.7373 - val_loss: 0.6439 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5268 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6544 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5553 - sparse_categorical_accuracy: 0.7587\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5668 - sparse_categorical_accuracy: 0.7501 - val_loss: 0.6515 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5465 - sparse_categorical_accuracy: 0.7478 - val_loss: 0.6549 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5442 - sparse_categorical_accuracy: 0.7453 - val_loss: 0.6661 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5644 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.5568 - sparse_categorical_accuracy: 0.7386 - val_loss: 0.6834 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5456 - sparse_categorical_accuracy: 0.7544\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5479 - sparse_categorical_accuracy: 0.7528 - val_loss: 0.6901 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5411 - sparse_categorical_accuracy: 0.7495 - val_loss: 0.6966 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5503 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6992 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5486 - sparse_categorical_accuracy: 0.7444 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.5549 - sparse_categorical_accuracy: 0.7527 - val_loss: 0.6975 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5218 - sparse_categorical_accuracy: 0.7560\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5260 - sparse_categorical_accuracy: 0.7535 - val_loss: 0.6999 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5521 - sparse_categorical_accuracy: 0.7477 - val_loss: 0.6987 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 1.2500e-04\n",
            "Epoch 22: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "  Test Accuracy: 55.56%\n",
            "  Test Precision (weighted): 30.86%\n",
            "  Test Recall (weighted): 55.56%\n",
            "  Test F1-Score (weighted): 39.68%\n",
            "\n",
            "--- Fold 18/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5964 - sparse_categorical_accuracy: 0.7214"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.6023 - sparse_categorical_accuracy: 0.7150 - val_loss: 0.6546 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6027 - sparse_categorical_accuracy: 0.7396"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6050 - sparse_categorical_accuracy: 0.7326 - val_loss: 0.6431 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5755 - sparse_categorical_accuracy: 0.7297"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.5841 - sparse_categorical_accuracy: 0.7234 - val_loss: 0.6289 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5926 - sparse_categorical_accuracy: 0.7331"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5941 - sparse_categorical_accuracy: 0.7285 - val_loss: 0.6223 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5898 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.6241 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5911 - sparse_categorical_accuracy: 0.7301 - val_loss: 0.6261 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5853 - sparse_categorical_accuracy: 0.7158 - val_loss: 0.6293 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5791 - sparse_categorical_accuracy: 0.7395 - val_loss: 0.6321 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6078 - sparse_categorical_accuracy: 0.7091\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6122 - sparse_categorical_accuracy: 0.7079 - val_loss: 0.6379 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5913 - sparse_categorical_accuracy: 0.7358 - val_loss: 0.6428 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5866 - sparse_categorical_accuracy: 0.7406 - val_loss: 0.6451 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5872 - sparse_categorical_accuracy: 0.7451 - val_loss: 0.6392 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5898 - sparse_categorical_accuracy: 0.7262 - val_loss: 0.6446 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5647 - sparse_categorical_accuracy: 0.7336\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5683 - sparse_categorical_accuracy: 0.7296 - val_loss: 0.6603 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5573 - sparse_categorical_accuracy: 0.7321 - val_loss: 0.6644 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5674 - sparse_categorical_accuracy: 0.7464 - val_loss: 0.6644 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5796 - sparse_categorical_accuracy: 0.7293 - val_loss: 0.6597 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5742 - sparse_categorical_accuracy: 0.7347 - val_loss: 0.6575 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5568 - sparse_categorical_accuracy: 0.7405\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5580 - sparse_categorical_accuracy: 0.7370 - val_loss: 0.6598 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "  Test Accuracy: 83.33%\n",
            "  Test Precision (weighted): 69.44%\n",
            "  Test Recall (weighted): 83.33%\n",
            "  Test F1-Score (weighted): 75.76%\n",
            "\n",
            "--- Fold 19/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7392 - sparse_categorical_accuracy: 0.5334"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - loss: 0.7251 - sparse_categorical_accuracy: 0.5576 - val_loss: 0.6576 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6214 - sparse_categorical_accuracy: 0.7247"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6222 - sparse_categorical_accuracy: 0.7199 - val_loss: 0.6495 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5733 - sparse_categorical_accuracy: 0.7328"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5862 - sparse_categorical_accuracy: 0.7276 - val_loss: 0.6420 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5981 - sparse_categorical_accuracy: 0.7330"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5997 - sparse_categorical_accuracy: 0.7320 - val_loss: 0.6326 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5839 - sparse_categorical_accuracy: 0.7391"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5850 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.6249 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5977 - sparse_categorical_accuracy: 0.7177"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5984 - sparse_categorical_accuracy: 0.7156 - val_loss: 0.6205 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5898 - sparse_categorical_accuracy: 0.7336"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5944 - sparse_categorical_accuracy: 0.7260 - val_loss: 0.6181 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5980 - sparse_categorical_accuracy: 0.7304 - val_loss: 0.6189 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5888 - sparse_categorical_accuracy: 0.7356 - val_loss: 0.6185 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5968 - sparse_categorical_accuracy: 0.7443"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5982 - sparse_categorical_accuracy: 0.7423 - val_loss: 0.6166 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6035 - sparse_categorical_accuracy: 0.7125 - val_loss: 0.6232 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5706 - sparse_categorical_accuracy: 0.7307 - val_loss: 0.6331 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5856 - sparse_categorical_accuracy: 0.7144 - val_loss: 0.6383 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5701 - sparse_categorical_accuracy: 0.7268 - val_loss: 0.6388 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5886 - sparse_categorical_accuracy: 0.7297\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5903 - sparse_categorical_accuracy: 0.7244 - val_loss: 0.6408 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5805 - sparse_categorical_accuracy: 0.7323 - val_loss: 0.6466 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5725 - sparse_categorical_accuracy: 0.7343 - val_loss: 0.6466 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5567 - sparse_categorical_accuracy: 0.7372 - val_loss: 0.6483 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5534 - sparse_categorical_accuracy: 0.7451 - val_loss: 0.6575 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.7516\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5486 - sparse_categorical_accuracy: 0.7439 - val_loss: 0.6641 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5319 - sparse_categorical_accuracy: 0.7318 - val_loss: 0.6652 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5532 - sparse_categorical_accuracy: 0.7333 - val_loss: 0.6658 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5442 - sparse_categorical_accuracy: 0.7442 - val_loss: 0.6649 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5537 - sparse_categorical_accuracy: 0.7324 - val_loss: 0.6648 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5345 - sparse_categorical_accuracy: 0.7485\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5459 - sparse_categorical_accuracy: 0.7381 - val_loss: 0.6632 - val_sparse_categorical_accuracy: 0.6833 - learning_rate: 2.5000e-04\n",
            "Epoch 25: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "  Test Accuracy: 94.44%\n",
            "  Test Precision (weighted): 89.20%\n",
            "  Test Recall (weighted): 94.44%\n",
            "  Test F1-Score (weighted): 91.75%\n",
            "\n",
            "--- Fold 20/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.7849 - sparse_categorical_accuracy: 0.4931"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - loss: 0.7771 - sparse_categorical_accuracy: 0.5024 - val_loss: 0.6576 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6072 - sparse_categorical_accuracy: 0.7074"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6084 - sparse_categorical_accuracy: 0.7061 - val_loss: 0.6399 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5658 - sparse_categorical_accuracy: 0.7243"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5670 - sparse_categorical_accuracy: 0.7237 - val_loss: 0.6335 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6186 - sparse_categorical_accuracy: 0.7415"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6180 - sparse_categorical_accuracy: 0.7371 - val_loss: 0.6275 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5846 - sparse_categorical_accuracy: 0.7496"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5893 - sparse_categorical_accuracy: 0.7439 - val_loss: 0.6194 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5932 - sparse_categorical_accuracy: 0.7523"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5981 - sparse_categorical_accuracy: 0.7423 - val_loss: 0.6127 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6011 - sparse_categorical_accuracy: 0.7245"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6062 - sparse_categorical_accuracy: 0.7205 - val_loss: 0.6103 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5817 - sparse_categorical_accuracy: 0.7420"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5836 - sparse_categorical_accuracy: 0.7386 - val_loss: 0.6096 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5856 - sparse_categorical_accuracy: 0.7334"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5865 - sparse_categorical_accuracy: 0.7323 - val_loss: 0.6092 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5915 - sparse_categorical_accuracy: 0.7378 - val_loss: 0.6100 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5827 - sparse_categorical_accuracy: 0.7361 - val_loss: 0.6102 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5836 - sparse_categorical_accuracy: 0.7340 - val_loss: 0.6133 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5900 - sparse_categorical_accuracy: 0.7378 - val_loss: 0.6124 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5735 - sparse_categorical_accuracy: 0.7354\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5791 - sparse_categorical_accuracy: 0.7311 - val_loss: 0.6134 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5859 - sparse_categorical_accuracy: 0.7331 - val_loss: 0.6185 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5773 - sparse_categorical_accuracy: 0.7239 - val_loss: 0.6219 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5802 - sparse_categorical_accuracy: 0.7213 - val_loss: 0.6262 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5590 - sparse_categorical_accuracy: 0.7161 - val_loss: 0.6363 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5621 - sparse_categorical_accuracy: 0.7343\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5616 - sparse_categorical_accuracy: 0.7336 - val_loss: 0.6417 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5516 - sparse_categorical_accuracy: 0.7383 - val_loss: 0.6455 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5665 - sparse_categorical_accuracy: 0.7315 - val_loss: 0.6456 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 2.5000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5804 - sparse_categorical_accuracy: 0.7243 - val_loss: 0.6431 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5562 - sparse_categorical_accuracy: 0.7255 - val_loss: 0.6453 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5564 - sparse_categorical_accuracy: 0.7349\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5571 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.6454 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 2.5000e-04\n",
            "Epoch 24: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "  Test Accuracy: 77.78%\n",
            "  Test Precision (weighted): 60.49%\n",
            "  Test Recall (weighted): 77.78%\n",
            "  Test F1-Score (weighted): 68.06%\n",
            "\n",
            "--- Fold 21/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.7366 - sparse_categorical_accuracy: 0.5170"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 0.7199 - sparse_categorical_accuracy: 0.5442 - val_loss: 0.6444 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6236 - sparse_categorical_accuracy: 0.7237"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.6233 - sparse_categorical_accuracy: 0.7234 - val_loss: 0.6325 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6065 - sparse_categorical_accuracy: 0.7233"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.6076 - sparse_categorical_accuracy: 0.7174 - val_loss: 0.6270 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5873 - sparse_categorical_accuracy: 0.7389"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.5888 - sparse_categorical_accuracy: 0.7343 - val_loss: 0.6155 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6198 - sparse_categorical_accuracy: 0.7277"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.6200 - sparse_categorical_accuracy: 0.7255 - val_loss: 0.6134 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5840 - sparse_categorical_accuracy: 0.7313"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.5901 - sparse_categorical_accuracy: 0.7256 - val_loss: 0.6114 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5967 - sparse_categorical_accuracy: 0.7267 - val_loss: 0.6123 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5663 - sparse_categorical_accuracy: 0.7296 - val_loss: 0.6134 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5710 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.6133 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5614 - sparse_categorical_accuracy: 0.7382 - val_loss: 0.6195 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5552 - sparse_categorical_accuracy: 0.7594\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5604 - sparse_categorical_accuracy: 0.7507 - val_loss: 0.6258 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5888 - sparse_categorical_accuracy: 0.7195 - val_loss: 0.6329 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5821 - sparse_categorical_accuracy: 0.7168 - val_loss: 0.6389 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6001 - sparse_categorical_accuracy: 0.7115 - val_loss: 0.6417 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5993 - sparse_categorical_accuracy: 0.7353 - val_loss: 0.6397 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5587 - sparse_categorical_accuracy: 0.7424\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5639 - sparse_categorical_accuracy: 0.7347 - val_loss: 0.6468 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5580 - sparse_categorical_accuracy: 0.7383 - val_loss: 0.6535 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5570 - sparse_categorical_accuracy: 0.7316 - val_loss: 0.6623 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5838 - sparse_categorical_accuracy: 0.7430 - val_loss: 0.6664 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5492 - sparse_categorical_accuracy: 0.7260 - val_loss: 0.6671 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5768 - sparse_categorical_accuracy: 0.7407\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.5810 - sparse_categorical_accuracy: 0.7336 - val_loss: 0.6673 - val_sparse_categorical_accuracy: 0.7000 - learning_rate: 2.5000e-04\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "  Test Accuracy: 77.78%\n",
            "  Test Precision (weighted): 60.49%\n",
            "  Test Recall (weighted): 77.78%\n",
            "  Test F1-Score (weighted): 68.06%\n",
            "\n",
            "--- Fold 22/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6664 - sparse_categorical_accuracy: 0.6269"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - loss: 0.6644 - sparse_categorical_accuracy: 0.6325 - val_loss: 0.6549 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5942 - sparse_categorical_accuracy: 0.7254"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5979 - sparse_categorical_accuracy: 0.7250 - val_loss: 0.6517 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6059 - sparse_categorical_accuracy: 0.7012"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6047 - sparse_categorical_accuracy: 0.7009 - val_loss: 0.6413 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5881 - sparse_categorical_accuracy: 0.7043"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5903 - sparse_categorical_accuracy: 0.7035 - val_loss: 0.6318 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5689 - sparse_categorical_accuracy: 0.7298"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5689 - sparse_categorical_accuracy: 0.7282 - val_loss: 0.6162 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5954 - sparse_categorical_accuracy: 0.7237"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5967 - sparse_categorical_accuracy: 0.7214 - val_loss: 0.6094 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5750 - sparse_categorical_accuracy: 0.7092"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5764 - sparse_categorical_accuracy: 0.7088 - val_loss: 0.5993 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5979 - sparse_categorical_accuracy: 0.7215"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6002 - sparse_categorical_accuracy: 0.7164 - val_loss: 0.5932 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5952 - sparse_categorical_accuracy: 0.7303 - val_loss: 0.5935 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5909 - sparse_categorical_accuracy: 0.7280 - val_loss: 0.5935 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5876 - sparse_categorical_accuracy: 0.7354 - val_loss: 0.5961 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5750 - sparse_categorical_accuracy: 0.7392 - val_loss: 0.6030 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5902 - sparse_categorical_accuracy: 0.7198\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5966 - sparse_categorical_accuracy: 0.7165 - val_loss: 0.6053 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5516 - sparse_categorical_accuracy: 0.7343 - val_loss: 0.6083 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5834 - sparse_categorical_accuracy: 0.7113 - val_loss: 0.6099 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5735 - sparse_categorical_accuracy: 0.7385 - val_loss: 0.6124 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5590 - sparse_categorical_accuracy: 0.7282 - val_loss: 0.6221 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5450 - sparse_categorical_accuracy: 0.7449\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5501 - sparse_categorical_accuracy: 0.7423 - val_loss: 0.6220 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5542 - sparse_categorical_accuracy: 0.7274 - val_loss: 0.6232 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.5484 - sparse_categorical_accuracy: 0.7383 - val_loss: 0.6226 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5536 - sparse_categorical_accuracy: 0.7267 - val_loss: 0.6274 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 2.5000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5331 - sparse_categorical_accuracy: 0.7376 - val_loss: 0.6355 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5382 - sparse_categorical_accuracy: 0.7417\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5459 - sparse_categorical_accuracy: 0.7348 - val_loss: 0.6447 - val_sparse_categorical_accuracy: 0.7167 - learning_rate: 2.5000e-04\n",
            "Epoch 23: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "  Test Accuracy: 72.22%\n",
            "  Test Precision (weighted): 52.16%\n",
            "  Test Recall (weighted): 72.22%\n",
            "  Test F1-Score (weighted): 60.57%\n",
            "\n",
            "--- Fold 23/23 ---\n",
            "Eğitim boyutu: 396, Test boyutu: 18\n",
            "Epoch 1/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7136 - sparse_categorical_accuracy: 0.5305"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.7008 - sparse_categorical_accuracy: 0.5572 - val_loss: 0.6334 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6717 - sparse_categorical_accuracy: 0.6869"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.6723 - sparse_categorical_accuracy: 0.6855 - val_loss: 0.6230 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5922 - sparse_categorical_accuracy: 0.7274"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.5969 - sparse_categorical_accuracy: 0.7207 - val_loss: 0.5956 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5787 - sparse_categorical_accuracy: 0.7456"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5827 - sparse_categorical_accuracy: 0.7423 - val_loss: 0.5545 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5893 - sparse_categorical_accuracy: 0.7235"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5891 - sparse_categorical_accuracy: 0.7235 - val_loss: 0.5361 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6174 - sparse_categorical_accuracy: 0.7066"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6230 - sparse_categorical_accuracy: 0.7046 - val_loss: 0.5272 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6527 - sparse_categorical_accuracy: 0.6948 - val_loss: 0.5299 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5965 - sparse_categorical_accuracy: 0.7052 - val_loss: 0.5283 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5828 - sparse_categorical_accuracy: 0.6988"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5841 - sparse_categorical_accuracy: 0.6990 - val_loss: 0.5244 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6104 - sparse_categorical_accuracy: 0.7368 - val_loss: 0.5247 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5885 - sparse_categorical_accuracy: 0.7155 - val_loss: 0.5256 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.5761 - sparse_categorical_accuracy: 0.7193 - val_loss: 0.5277 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5791 - sparse_categorical_accuracy: 0.7193 - val_loss: 0.5291 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5872 - sparse_categorical_accuracy: 0.7318\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5857 - sparse_categorical_accuracy: 0.7298 - val_loss: 0.5294 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5607 - sparse_categorical_accuracy: 0.7416 - val_loss: 0.5307 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5682 - sparse_categorical_accuracy: 0.7312 - val_loss: 0.5310 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5899 - sparse_categorical_accuracy: 0.7316 - val_loss: 0.5317 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5574 - sparse_categorical_accuracy: 0.7393 - val_loss: 0.5344 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5618 - sparse_categorical_accuracy: 0.7169\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5610 - sparse_categorical_accuracy: 0.7154 - val_loss: 0.5374 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5628 - sparse_categorical_accuracy: 0.7473 - val_loss: 0.5375 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5617 - sparse_categorical_accuracy: 0.7215 - val_loss: 0.5379 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 2.5000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5618 - sparse_categorical_accuracy: 0.7290 - val_loss: 0.5377 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5727 - sparse_categorical_accuracy: 0.7149 - val_loss: 0.5358 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5611 - sparse_categorical_accuracy: 0.7473\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5617 - sparse_categorical_accuracy: 0.7449 - val_loss: 0.5372 - val_sparse_categorical_accuracy: 0.7833 - learning_rate: 2.5000e-04\n",
            "Epoch 24: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "  Test Accuracy: 50.00%\n",
            "  Test Precision (weighted): 25.00%\n",
            "  Test Recall (weighted): 50.00%\n",
            "  Test F1-Score (weighted): 33.33%\n",
            "\n",
            "======================================================================\n",
            "  AROUSAL SONUÇLARI\n",
            "======================================================================\n",
            "Ortalama Accuracy: 72.46% ± 13.66%\n",
            "Ortalama Precision: 54.37% ± 20.04%\n",
            "Ortalama Recall: 72.46% ± 13.66%\n",
            "Ortalama F1-Score: 61.62% ± 18.09%\n",
            "\n",
            "--- Sonuçlar Görselleştiriliyor ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "  VALENCE - SINIFLANDIRMA RAPORU\n",
            "======================================================================\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Negatif     0.4118    0.0435    0.0787       161\n",
            "     Pozitif     0.6121    0.9605    0.7477       253\n",
            "\n",
            "    accuracy                         0.6039       414\n",
            "   macro avg     0.5119    0.5020    0.4132       414\n",
            "weighted avg     0.5342    0.6039    0.4875       414\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "  AROUSAL - SINIFLANDIRMA RAPORU\n",
            "======================================================================\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Düşük     0.0000    0.0000    0.0000       114\n",
            "      Yüksek     0.7246    1.0000    0.8403       300\n",
            "\n",
            "    accuracy                         0.7246       414\n",
            "   macro avg     0.3623    0.5000    0.4202       414\n",
            "weighted avg     0.5251    0.7246    0.6089       414\n",
            "\n",
            "\n",
            "======================================================================\n",
            "  FİNAL SONUÇLAR ÖZETİ\n",
            "======================================================================\n",
            "\n",
            "Duygu Boyutu Ortalama Accuracy (%) Ortalama F1-Score (%)\n",
            "     Valence         60.39 ± 12.83         48.20 ± 15.65\n",
            "     Arousal         72.46 ± 13.66         61.62 ± 18.09\n",
            "\n",
            "======================================================================\n",
            "\n",
            "✓ Notebook tamamlandı!\n",
            "✓ Model ağırlıkları kaydedildi (best_model_*.h5)\n",
            "✓ Sonuç grafikleri oluşturuldu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gMVjjT37UyRm"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}